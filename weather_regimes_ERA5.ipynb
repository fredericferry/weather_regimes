{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etude des régimes de temps de l'Atlantique nord\n",
    "\n",
    "\n",
    "**Auteur : FERRY Frédéric (ENM/C3M) - Novembre 2022.\n",
    "mailto:frederic.ferry@meteo.fr\n",
    "\n",
    "En météorologie, le concept de **régime de temps** a été introduit il y a environ 70 ans (Rex, 1951). Il est basé sur l'idée que la **circulation atmosphérique de grande échelle des moyennes latitudes** peut être décrite par un **nombre fini d'états atmosphériques** possibles qui se manifestent dans des **schémas d'écoulement de grande échelle quasi-stationnaires, persistants et récurrents**. Étant donné que le temps diffère d'un jour à l'autre et évolue continuellement, classer des situations météorologiques en un nombre fini d'états variant lentement n'est pas une tâche simple. Il existe de nombreuses façons de définir les régimes météorologiques. Si l'on se réfère à la propriété de récurrence (**situations les plus fréquentes au cours d'une période climatologique donnée**), la **classification automatique** (\"cluster \"analysis\") est aujourd'hui l'approche la plus courante pour identifier les régimes de temps. En ce qui concerne la quasi-stationnarité et la persistance, les régimes de temps représentent au sens statistique les **états dans lesquels l'écoulement de grande échelle réside pendant une période prolongée (une semaine à un mois)**.\n",
    "\n",
    "**Ainsi, le régime de temps, principale entité physique des fluctuations atmosphériques aux moyennes latitudes, fournit une grille de lecture simplificatrice du climat des latitudes moyennes et de son évolution**. Les changements du temps qu'il fait peuvent se comprendre comme le passage d'un régime à un autre. La variabilité climatique peut, quant à elle, s'interpréter comme la conséquence sur une longue période de transitions privilégiées vers un régime donné.\n",
    "\n",
    "**On s'intéressera ici à l'étude des régimes de temps de l'Atlantique Nord à partir de séries quotidiennes de géopotentiel à 500 hPa et de pression réduite au niveau de la mer**. \n",
    "\n",
    "- Etape 1 : ouverture et traitement des données quotidiennes\n",
    "- Etape 2 : étude des données quotidiennes sur un mois donné\n",
    "- Etape 3 : décomposition des données en temps et en espace (analyse en composantes principales, ACP)\n",
    "- Etape 4 : classification en 4 classes = régimes (méthode k-means)\n",
    "- Etape 5 : obtention des régimes de temps\n",
    "- Etape 6 : temps sensible associé aux régimes de temps (étape à faire uniquement pour les régimes de temps d'hiver sur l'Atlantique nord)\n",
    "- Etape 7 : étude des occurrences saisonnières des régimes de temps\n",
    "- Etape 8 : corrélation régimes/indices océaniques (Nino 3.4, TNA, AMV)\n",
    "- Etape 9 : retour sur une saison particulière\n",
    "\n",
    "**Remarque : la technique d'analyse en composantes principales (ACP) et la méthode de classification de type k-means seront abordés en deuxième année. Ces outils d'analyse de données seront utilisés ici comme des \"boîtes noires\"**.\n",
    "\n",
    "Concepts Python illustrés :\n",
    "\n",
    "- Exploitation de fichiers de données météorologiques au format netcdf (xarray/netCDF4)\n",
    "- Calcul d'anomalies quotidiennes (méthode groupby de xarray)\n",
    "- Création de séries temporelles (pandas)\n",
    "- Tracé de cartes (matplotlib/cartopy)\n",
    "- Régression linéaire (module LinearRegression de sklearn, https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)\n",
    "- Analyse en composantes principales (package eofs, https://ajdawson.github.io/eofs/latest/)\n",
    "- Représentation des données dans un espace des phases (scatterplot 2D ou 3D)\n",
    "- Tracé de densité de points (module gaussian_kde de scipy)\n",
    "- Classification K-means (module KMeans de sklearn, https://scikit-learn.org/stable/modules/clustering.html)\n",
    "- Réalisation de cartes composites (moyenne par classe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>Instructions : </b>\n",
    "<p><b>1) </b>Exécuter les cellules qui suivent de façon séquentielle</p>\n",
    "<p><b>2) </b>Répondre aux questions (celulles de couleur jaune) dans les cadres réponses dédiés (cellules de couleur verte)</p>\n",
    "<p><b>3) </b>Sauvegarder le calepin final au format pdf</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "<b>Attention : l'obtention des régimes de temps nécessite d'utiliser des méthodes statistiques qui seront étudiées en deuxième année (analyse en composantes principales - étape 3, classification automatique - étape 4). On utilisera ici ces méthodes comme des boîtes noires. </b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import calendar\n",
    "from calendar import isleap\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "import IPython.display as IPdisplay, matplotlib.font_manager as fm\n",
    "from PIL import Image\n",
    "import glob\n",
    "\n",
    "import xarray as xr\n",
    "from netCDF4 import Dataset\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import Series\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.patches import Rectangle\n",
    "from matplotlib.collections import PatchCollection\n",
    "from mpl_toolkits.axes_grid1 import AxesGrid\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.path as mpath\n",
    "\n",
    "from cartopy import config\n",
    "import cartopy.feature as cfeature\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.mpl.geoaxes import GeoAxes\n",
    "from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter\n",
    "\n",
    "from eofs.standard import Eof\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Dossiers des données, figures, animations et résultats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dir_data='./data/'\n",
    "dir_res='./result/'\n",
    "dir_figs='./figs/'\n",
    "dir_anim='./anim/'\n",
    "\n",
    "if not os.path.exists(dir_figs):\n",
    "    os.makedirs(dir_figs)\n",
    "if not os.path.exists(dir_anim):\n",
    "    os.makedirs(dir_anim)\n",
    "if not os.path.exists(dir_res):\n",
    "    os.makedirs(dir_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etape 1 : ouverture et traitement des données quotidiennes"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Ouverture (via xarray) du fichier des données :\n",
    "\n",
    "era5_z500_natl_daily_1950-2020_1deg5.nc :\n",
    "Fichier au format netcdf issu des réanalyses quotidiennes ERA5, resolution descendue à 1.5deg\n",
    "Les données sont des valeurs quotidiennes de hauteur géopotentielle à 500hPa (variable z, unité : mgp) sur l'Atlantique nord et pour la période 1979-2020.\n",
    "\n",
    "era5_msl_natl_daily_1950-2020_1deg5.nc :\n",
    "Fichier au format netcdf issu des réanalyses quotidiennes ERA5, resolution descendue à 1.5deg\n",
    "Les données sont des valeurs quotidiennes de pression réduite au niveau de la mer (variable msl, unité : Pa) sur l'Atlantique nord et pour la période 1979-2020."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Choix de la variable, ouverture du fichiers de données quotidiennes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "var_text=input(\"Z500 ou Pmer : Z500/MSLP? \")\n",
    "\n",
    "if var_text=='Z500':\n",
    "    infile = dir_data+'era5_z500_natl_daily_1950-2020_1deg5.nc'\n",
    "    varname='z'\n",
    "    var_div=9.81\n",
    "    units='m'\n",
    "\n",
    "if var_text=='MSLP':\n",
    "    infile = dir_data+'era5_msl_natl_daily_1950-2020_1deg5.nc'\n",
    "    varname='msl'\n",
    "    var_div=100\n",
    "    units='hPa'\n",
    "\n",
    "data    = xr.open_dataset(infile)\n",
    "print(data.variables)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Domaine d'étude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lat  = data.lat.values\n",
    "lon  = data.lon.values\n",
    "\n",
    "domain='North Atlantic'\n",
    "domain_name='natl'\n",
    "latS=lat[0]\n",
    "latN=lat[-1]\n",
    "lonW=lon[0]\n",
    "lonE=lon[-1]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Choix de la saison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "season_name=input(\"Saison hiver ou été : winter/summer ? \")\n",
    "\n",
    "if season_name=='winter':\n",
    "    season='Winter'\n",
    "    if var_text=='MSLP':\n",
    "        startday  = '1957-12-01T09'\n",
    "        endday  = '2020-03-31T09'\n",
    "    if var_text=='Z500':\n",
    "        startday  = '1957-12-01T18'\n",
    "        endday  = '2020-03-31T18'\n",
    "if season_name=='summer':\n",
    "    season='Summer'\n",
    "    if var_text=='MSLP':\n",
    "        startday  = '1958-06-01T09'\n",
    "        endday  = '2020-09-30T09'\n",
    "    if var_text=='Z500':\n",
    "        startday  = '1958-06-01T18'\n",
    "        endday  = '2020-09-30T18'\n",
    "\n",
    "# Date index from startday to endday\n",
    "dates = pd.date_range(startday, endday, freq='D')\n",
    "print(dates)\n",
    "\n",
    "# Remove 29/02\n",
    "#def is_leap_and_29Feb(s):\n",
    "#    return (s.year % 4 == 0) & ((s.year % 100 != 0) | (s.year % 400 == 0)) & (s.month == 2) & (s.day == 29)\n",
    "#mask = is_leap_and_29Feb(dates)\n",
    "#dates=dates[~mask]\n",
    "#print(dates)\n",
    "\n",
    "# Select Season\n",
    "if season_name == 'winter':\n",
    "    months=np.any([dates.month==12,dates.month==1,dates.month==2,dates.month==3],axis=0)\n",
    "if season_name == 'summer':\n",
    "    months=np.any([dates.month==6,dates.month==7,dates.month==8,dates.month==9],axis=0)\n",
    "\n",
    "dates2=dates[months]\n",
    "print(dates2)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Sélection des données pour la saison choisie et création d'un nouveau fichier netcdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_season = data.sel(time=dates2)\n",
    "print(data_season)\n",
    "time  = data_season.time.values\n",
    "\n",
    "if season_name == 'winter':\n",
    "    season1= str(data_season.time.values[130])[0:4]\n",
    "    season2= str(data_season.time.values[-1])[0:4]\n",
    "\n",
    "if season_name == 'summer':\n",
    "    season1= str(data_season.time.values[0])[0:4]\n",
    "    season2= str(data_season.time.values[-1])[0:4]\n",
    "\n",
    "print(' ----- Saving new seasonnal file from '+startday+ ' to '+endday+ ' on new domain  ----- ')\n",
    "infile1 = dir_res+varname+'_'+startday+'_'+endday+'_'+domain_name+'.nc'\n",
    "data_season.to_netcdf(infile1)\n",
    "print(' new daily seasonnal file over subdomain is here : ')\n",
    "print(infile1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Vérification des dates (effacer le contenu de la cellule après vérification)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with np.printoptions(threshold=np.inf):\n",
    "    print(time)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Calcul des anomalies quotidiennes pour les saisons retenues.\n",
    "Sauvegarde du fichier d'anomalies quotidiennes au format netcdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(' ----- Computing daily anomalies ----- ')\n",
    "data_anom = data_season.groupby('time.dayofyear') - data_season.groupby('time.dayofyear').mean('time')\n",
    "print(data_anom)\n",
    "print(' ----- Writing netcdf ----- ')\n",
    "infile2 = dir_res+varname+'_anom_'+startday+'_'+endday+'_'+domain_name+'.nc'\n",
    "data_anom.to_netcdf(infile2)\n",
    "print(' netcdf file of daily anomalies is here : ')\n",
    "print(infile2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etape 2 : étude des données quotidiennes sur un mois donné"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Sélection des données (total et anomalie) pour 30 jours consécutifs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if season_name == 'winter':\n",
    "    date1='20191201'\n",
    "    date2='20201230'\n",
    "    \n",
    "if season_name == 'summer':\n",
    "    date1='20030801'\n",
    "    date2='20030830'\n",
    "    \n",
    "data_month    = data_season.sel(time=slice(date1,date2))\n",
    "data_month_anom    = data_anom.sel(time=slice(date1,date2))\n",
    "\n",
    "z=data_month[varname]/var_div\n",
    "z_anom=data_month_anom[varname]/var_div\n",
    "\n",
    "time  = data_month.time.values\n",
    "\n",
    "time_str=[x for x in range(len(time))]\n",
    "date_str=[x for x in range(len(time))]\n",
    "\n",
    "for i in range(len(time)):\n",
    "\ttime_str[i] = str(time[i])\n",
    "\tdate_str[i] = time_str[i][0:10]\n",
    "    \n",
    "print(data_month)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Définition de la projection, fonction pour la découpe du contour des cartes en projection non rectangulaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "projection = ccrs.Orthographic(central_longitude=(lonW+lonE)/2, central_latitude=(latS+latN)/2)\n",
    "bounds = [(lonW, lonE, latS, latN)]\n",
    "\n",
    "def make_boundary_path(lon,lat):\n",
    "    lons,lats=np.meshgrid(lon,lat)\n",
    "    boundary_path = np.array([lons[-1,:],lats[-1,:]])\n",
    "    boundary_path = np.append(boundary_path,np.array([lons[::-1,-1],lats[::-1,-1]]),axis=1)\n",
    "    boundary_path = np.append(boundary_path,np.array([lons[1,::-1],lats[1,::-1]]),axis=1)\n",
    "    boundary_path = np.append(boundary_path,np.array([lons[:,1],lats[:,1]]),axis=1)\n",
    "    boundary_path = mpath.Path(np.swapaxes(boundary_path, 0, 1))\n",
    "    return boundary_path"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Echelles de valeurs, colormaps, titres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if varname=='z':\n",
    "    levels1 = np.arange(4800,6200,100)\n",
    "    plt_title1 = 'Geopotential height ('+units+') at 500 hPa : '+ str(date1)+'-'+str(date2)\n",
    "    levels2 = np.arange(-500,550,50)\n",
    "    plt_title2 = 'Geopotential height anomaly ('+units+') at 500 hPa : '+ str(date1)+'-'+str(date2)\n",
    "\n",
    "if varname=='msl':\n",
    "    levels1 = np.arange(980,1040,5)\n",
    "    plt_title1 = 'Mean Sea Level Pressure ('+units+') : '+ str(date1)+'-'+str(date2)\n",
    "    levels2 = np.arange(-25,27.5,2.5)\n",
    "    plt_title2 = 'Mean Sea Level Pressure anomaly ('+units+') : '+ str(date1)+'-'+str(date2)\n",
    "\n",
    "cmap1='jet'\n",
    "cmap2='RdBu_r'"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Tracé des vignettes du champ quotidien pour les 30 jours consécutifs choisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "axes_class = (GeoAxes, dict(map_projection=projection))\n",
    "fig = plt.figure(figsize=(17,10))\n",
    "fig.suptitle(plt_title1, fontsize=16)\n",
    "\n",
    "axgr = AxesGrid(fig, 111, axes_class=axes_class,\n",
    "       nrows_ncols=(5, 6),\n",
    "       axes_pad=0.6,\n",
    "       cbar_location='right',\n",
    "       cbar_mode='single', # None/single/each\n",
    "       cbar_pad=0.2,\n",
    "       cbar_size='3%',\n",
    "       label_mode='')  # note the empty label_mode\n",
    "                   \n",
    "for i, ax in enumerate(axgr):\n",
    "    ax.coastlines()\n",
    "    ax.gridlines(crs=ccrs.PlateCarree(), linewidth=0.5, color='gray', alpha=0.5, linestyle='-')\n",
    "    ax.set_extent(*bounds, crs=ccrs.PlateCarree())\n",
    "    boundary_path = make_boundary_path(lon, lat)\n",
    "    ax.set_boundary(boundary_path, transform=ccrs.PlateCarree())\n",
    "    ax.set_title(date_str[i], fontsize=10)\n",
    "    p1 = ax.contourf(lon, lat, z[i,:,:], levels1, transform=ccrs.PlateCarree(), cmap=cmap1, extend='both')\n",
    "    p2 = ax.contour(lon, lat, z[i,:,:], levels1, colors='black', linewidths=0.2, transform=ccrs.PlateCarree())\n",
    "    axgr.cbar_axes[i].colorbar(p1)\n",
    "   \n",
    "plt.show()\n",
    "\n",
    "figname=dir_figs+varname+'_'+domain_name+'_'+season_name+'_'+str(date1)+'-'+str(date2)\n",
    "fig.savefig(figname+'.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Tracé des vignettes de l'anomalie quotidienne pour les 30 jours consécutifs choisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "axes_class = (GeoAxes, dict(map_projection=projection))\n",
    "fig = plt.figure(figsize=(17,10))\n",
    "fig.suptitle(plt_title2, fontsize=16)\n",
    "\n",
    "axgr = AxesGrid(fig, 111, axes_class=axes_class,\n",
    "       nrows_ncols=(5, 6),\n",
    "       axes_pad=0.6,\n",
    "       cbar_location='right',\n",
    "       cbar_mode='single', # None/single/each\n",
    "       cbar_pad=0.2,\n",
    "       cbar_size='3%',\n",
    "       label_mode='')  # note the empty label_mode\n",
    "                   \n",
    "for i, ax in enumerate(axgr):\n",
    "    ax.coastlines()\n",
    "    ax.gridlines(crs=ccrs.PlateCarree(), linewidth=0.5, color='gray', alpha=0.5, linestyle='-')\n",
    "    ax.set_extent(*bounds, crs=ccrs.PlateCarree())\n",
    "    boundary_path = make_boundary_path(lon, lat)\n",
    "    ax.set_boundary(boundary_path, transform=ccrs.PlateCarree())\n",
    "    ax.set_title(date_str[i], fontsize=10)\n",
    "    p1 = ax.contourf(lon, lat, z_anom[i,:,:], levels2, transform=ccrs.PlateCarree(), cmap=cmap2, extend='both')\n",
    "    p2 = ax.contour(lon, lat, z_anom[i,:,:], levels2, colors='black', linewidths=0.2, transform=ccrs.PlateCarree())\n",
    "    axgr.cbar_axes[i].colorbar(p1)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "figname=dir_figs+varname+'_anom_'+domain_name+'_'+season_name+'_'+str(date1)+'-'+str(date2)\n",
    "fig.savefig(figname+'.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Cartes individuelles des anomalies pour la séquence choisie (fichiers png)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(time)):\n",
    "    #print(date_str[i])\n",
    "    fig = plt.figure(figsize=(8., 8.))\n",
    "    fig.suptitle(plt_title2, fontsize=16)\n",
    "    ax = fig.add_subplot(1,1,1, projection=projection)\n",
    "    ax.set_title(date_str[i], loc='center')\n",
    "    ax.coastlines()\n",
    "    ax.gridlines(crs=ccrs.PlateCarree(), linewidth=0.5, color='gray', alpha=0.5, linestyle='-')\n",
    "    ax.set_extent(*bounds, crs=ccrs.PlateCarree())\n",
    "    boundary_path = make_boundary_path(lon, lat)\n",
    "    ax.set_boundary(boundary_path, transform=ccrs.PlateCarree())\n",
    "    p1 = ax.contourf(lon, lat, z_anom[i,:,:], levels2, transform=ccrs.PlateCarree(), cmap=cmap2, extend='both')\n",
    "    p2 = ax.contour(lon, lat, z_anom[i,:,:], levels2, colors='black', linewidths=0.2, transform=ccrs.PlateCarree())\n",
    "    cb = fig.colorbar(p1, orientation='horizontal', aspect=65, shrink=0.5, pad=0.05, extendrect='True')\n",
    "    cb.set_label('Anomaly ('+units+')', fontsize=12)\n",
    "\n",
    "    figname=dir_anim+varname+'_anom_'+domain_name+'_'+season_name+'_'+date_str[i]\n",
    "    fig.savefig(figname+'.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "print('png files are in the animation folder, ready to make the animation')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Fonction de création d'une animation à partir des fichiers png présents dans le dossier anim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def make_animation():\n",
    "    nbimages=len(time)\n",
    "    # create a tuple of display durations, one for each frame\n",
    "    first_last = 1000 #show the first and last frames for 1000 ms\n",
    "    standard_duration = 1000 #show all other frames for 1000 ms\n",
    "    durations = tuple([first_last] + [standard_duration] * (nbimages - 2) + [first_last])\n",
    "    # load all the static images into a list\n",
    "    images = [Image.open(image) for image in sorted(glob.glob('{}/*.png'.format(dir_anim)))]\n",
    "    # save as an animated gif\n",
    "    gif = images[0]\n",
    "    gif.info['duration'] = durations #ms per frame\n",
    "    gif.info['loop'] = 0 #how many times to loop (0=infinite)\n",
    "    gif.save(fp=gif_filepath, format='gif', save_all=True, append_images=images[1:])\n",
    "    # verify that the number of frames in the gif equals the number of image files and durations\n",
    "    Image.open(gif_filepath).n_frames == len(images) == len(durations)\n",
    "    # clean png\n",
    "    os.chdir(dir_anim)\n",
    "    for f in glob.glob(\"*.png\"):\n",
    "        os.remove(f)\n",
    "    os.chdir(\"../\")\n",
    "    return Image"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Animation des anomalies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gif_filepath = dir_anim+varname+'_anom_'+domain_name+'_'+season_name+'_'+str(date1)+'-'+str(date2)+'.gif'\n",
    "make_animation()\n",
    "IPdisplay.Image(url=gif_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>Question : </b>\n",
    "<p><b>1) </b>Pour la séquence mensuelle choisie, peut-on déjà regrouper subjectivement des situations qui se ressemblent ? Combien de groupes pourrait-on faire ?</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Réponse : </b>\n",
    "<p>\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etape 3 : analyse en composantes principales (ACP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "<b>Exécuter l'ensemble des cellules de l'étape 3 ci-dessous pour réduire la dimension du problème en décomposant les données en temps et en espace via la méthode d'analyse en composantes principales (ACP)</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Ouverture (via netcdf4) des données quotidennes, domaine Nord Atlantique, période DJFM 1957-2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "filename = infile1\n",
    "ncin = Dataset(filename, 'r')\n",
    "lons = ncin.variables['lon'][:]\n",
    "lats = ncin.variables['lat'][:]\n",
    "var = ncin.variables[varname][:]/var_div\n",
    "ncin.close()\n",
    "\n",
    "filename = infile2\n",
    "ncin = Dataset(filename, 'r')\n",
    "lons = ncin.variables['lon'][:]\n",
    "lats = ncin.variables['lat'][:]\n",
    "var_anom = ncin.variables[varname][:]/var_div\n",
    "ncin.close()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Réalisation de l'ACP. Avant de réaliser l'ACP on applique une pondération. En effet, sur une grille régulière lat/lon qui ne conserve pas les aires, chaque point de grille n'est pas représentatif de la même surface. Ainsi, si aucune pondération n'est faite avant l'ACP il y aura un problème de distortion aux hautes latitudes. On applique donc en chaque point de grille une pondération consistant à diviser le champ par la racine carrée du cosinus de la latitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "wgts = np.sqrt(np.cos(np.deg2rad(lats)))[:, np.newaxis]\n",
    "solver = Eof(var_anom, weights=wgts, center=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Récupération des 15 premiers vecteurs propres (EOFs, structures spatiales) divisés par la racine carrée de leur valeur propre (i.e écart-type de leur composante principale).\n",
    "Récupération des séries temporelles des composantes principales associées (PCs) non normalisées.\n",
    "Récupération du pourcentage de variance expliqué par chaque composante principale (plus de 80% de la variabilité totale sont expliqués par les 10 premières composantes principales)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n=15\n",
    "eofs = solver.eofs(neofs=n, eofscaling=1)\n",
    "pcs = solver.pcs(npcs=n, pcscaling=0)\n",
    "#pcs_norm = solver.pcs(npcs=n, pcscaling=1)\n",
    "varfrac = solver.varianceFraction()\n",
    "print(\"% de variance expliquée par les 10 premiers EOFs : \", 100*varfrac[0:10].sum())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Tracé des structures spatiales (EOFs) des composantes principales (PCs) et du pourcentage de variance expliqué."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "axes_class = (GeoAxes, dict(map_projection=projection))\n",
    "\n",
    "fig = plt.figure(figsize=(15,6))\n",
    "fig.suptitle('EOFs : '+var_text+' - '+domain+' - '+season+ ' '+season1+'-'+season2, fontsize=16)\n",
    "\n",
    "axgr = AxesGrid(fig, 111, axes_class=axes_class,\n",
    "       nrows_ncols=(3, 5),\n",
    "       axes_pad=0.6,\n",
    "       cbar_location='right',\n",
    "       cbar_mode='each', # None/single/each\n",
    "       cbar_pad=0.2,\n",
    "       cbar_size='3%',\n",
    "       label_mode='')  # note the empty label_mode\n",
    "\n",
    "for i, ax in enumerate(axgr):\n",
    "    ax.coastlines()\n",
    "    ax.set_extent([lonW, lonE, latS, latN], crs=ccrs.PlateCarree())\n",
    "    boundary_path = make_boundary_path(lon, lat)\n",
    "    ax.set_boundary(boundary_path, transform=ccrs.PlateCarree())\n",
    "    ax.set_title('EOF'+str(i+1)+' ('+str(int(varfrac[i]*100))+'%)', fontsize=10, loc='center')\n",
    "    cf = ax.contourf(lons, lats, eofs[i]*1e5, transform=ccrs.PlateCarree(), cmap='bwr', extend='both')\n",
    "    c = ax.contour(lons, lats, eofs[i]*1e5, colors='black', linewidths=1, transform=ccrs.PlateCarree())\n",
    "    axgr.cbar_axes[i].colorbar(cf)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "figname=dir_figs+varname+'_'+domain_name+'_'+season_name+'_eofs'\n",
    "fig.savefig(figname+'.png', bbox_inches='tight')\n",
    "\n",
    "fig = plt.figure(figsize=(15,6))\n",
    "fig.suptitle('PCs : '+var_text+' - '+domain+' - '+season+ ' '+season1+'-'+season2, fontsize=16)\n",
    "\n",
    "plt.subplots_adjust(hspace=0.5, wspace=0.4)\n",
    "\n",
    "for i in range(0, 15):\n",
    "        plt.subplot(3, 5, i+1)\n",
    "        plt.title('PC'+str(i+1)+'(t)')\n",
    "        plt.axhline(0, color='k', linewidth=0.5)\n",
    "        if varname=='z':\n",
    "            plt.ylim(-9000, 9000)\n",
    "        if varname=='msl':\n",
    "            plt.ylim(-400, 400)\n",
    "        plt.plot(pcs[:,i], color='k', linewidth=0.5, alpha=0.7)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "figname=dir_figs+varname+'_'+domain_name+'_'+season_name+'_pcs'\n",
    "fig.savefig(figname+'.png', bbox_inches='tight')\n",
    "             \n",
    "fig = plt.figure(figsize=(15, 8))\n",
    "fig.suptitle('Variance fraction : '+var_text+' - '+domain+' - '+season+ ' '+season1+'-'+season2, fontsize=16)\n",
    "\n",
    "eof_num = range(1, 16)\n",
    "plt.bar(eof_num, varfrac[0:15], width=0.5)\n",
    "plt.axhline(0, color='k')\n",
    "plt.xticks(range(1, 16))\n",
    "plt.xlabel('EOF #')\n",
    "plt.ylabel('Variance Fraction')\n",
    "plt.xlim(1, 15)\n",
    "plt.ylim(np.min(varfrac), np.max(varfrac)+0.01)\n",
    "plt.show()\n",
    "\n",
    "figname=dir_figs+varname+'_'+domain_name+'_'+season_name+'_varfrac'\n",
    "fig.savefig(figname+'.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Tracé des 3 premières structures spatiales (EOFs) et des séries temporelles associées (PCs). On change les signes des EOFs et PCs pour avoir les correspondances suivantes :\n",
    "EOF1 > 0 : NAO+ ; EOF1 < 0 : NAO-\n",
    "EOF2 > 0 : blocage ; EOF2 < 0 : antiblocage\n",
    "EOF3 > 0 : dorsale atlantique ; EOF3 < 0 : minimum atlantique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "eof1=eofs[0]*(-1)\n",
    "eof2=eofs[1]\n",
    "eof3=eofs[2]\n",
    "\n",
    "pc1=pcs[:,0]*(-1)\n",
    "pc2=pcs[:,1]\n",
    "pc3=pcs[:,2]\n",
    "\n",
    "def plot_pc(ax):\n",
    "    plt.xlabel('Time (days)')\n",
    "    plt.axhline(0, color='k')\n",
    "    if varname=='z':\n",
    "        ax.set_ylim(-9000, 9000)\n",
    "    if varname=='msl':\n",
    "        ax.set_ylim(-400, 400)\n",
    "    return ax\n",
    "\n",
    "if varname=='z':\n",
    "    clevs = np.linspace(-3, 3, 11)\n",
    "if varname=='msl':\n",
    "    clevs = np.linspace(-5, 5, 11)\n",
    "\n",
    "fig = plt.figure(figsize=(15, 15))\n",
    "\n",
    "fig.suptitle('EOFs and PCs : '+var_text+' - '+domain+' - '+season+ ' '+season1+'-'+season2, fontsize=16)\n",
    "ax = fig.add_subplot(3, 2, 1, projection=projection)\n",
    "plt.title('EOF1 ('+str(int(varfrac[0]*100))+'%)', fontsize=10, loc='center')\n",
    "ax.coastlines()\n",
    "ax.set_extent([lonW, lonE, latS, latN], crs=ccrs.PlateCarree())\n",
    "boundary_path = make_boundary_path(lon, lat)\n",
    "ax.set_boundary(boundary_path, transform=ccrs.PlateCarree())\n",
    "cf = ax.contourf(lons, lats, eof1*1e5, clevs, cmap='bwr', extend='both', transform=ccrs.PlateCarree())\n",
    "c = ax.contour(lons, lats, eof1*1e5, clevs, colors='black', linewidths=1, transform=ccrs.PlateCarree())\n",
    "cb = fig.colorbar(cf, orientation='horizontal', aspect=70, shrink=0.6, pad=0.1, extendrect='True')\n",
    "cb.set_label('$10^{5}$', fontsize=12)\n",
    "\n",
    "ax = fig.add_subplot(3, 2, 2)\n",
    "plot_pc(ax)\n",
    "plt.title('PC1')\n",
    "plt.plot(pc1, color='k', linewidth=1)\n",
    "\n",
    "ax = fig.add_subplot(3, 2, 3, projection=projection)\n",
    "plt.title('EOF2 ('+str(int(varfrac[1]*100))+'%)', fontsize=10, loc='center')\n",
    "ax.coastlines()\n",
    "ax.set_extent([lonW, lonE, latS, latN], crs=ccrs.PlateCarree())\n",
    "boundary_path = make_boundary_path(lon, lat)\n",
    "ax.set_boundary(boundary_path, transform=ccrs.PlateCarree())\n",
    "cf = ax.contourf(lons, lats, eof2*1e5, clevs, cmap='bwr', extend='both', transform=ccrs.PlateCarree())\n",
    "c = ax.contour(lons, lats, eof2*1e5, clevs, colors='black', linewidths=1, transform=ccrs.PlateCarree())\n",
    "cb = fig.colorbar(cf, orientation='horizontal', aspect=70, shrink=0.6, pad=0.1, extendrect='True')\n",
    "cb.set_label('$10^{5}$', fontsize=12)\n",
    "\n",
    "ax = fig.add_subplot(3, 2, 4)\n",
    "plot_pc(ax)\n",
    "plt.title('PC2')\n",
    "plt.plot(pc2, color='k', linewidth=1)\n",
    "\n",
    "ax = fig.add_subplot(3, 2, 5, projection=projection)\n",
    "plt.title('EOF3 ('+str(int(varfrac[2]*100))+'%)', fontsize=10, loc='center')\n",
    "ax.coastlines()\n",
    "ax.set_extent([lonW, lonE, latS, latN], crs=ccrs.PlateCarree())\n",
    "boundary_path = make_boundary_path(lon, lat)\n",
    "ax.set_boundary(boundary_path, transform=ccrs.PlateCarree())\n",
    "cf = ax.contourf(lons, lats, eof3*1e5, clevs, cmap='bwr', extend='both', transform=ccrs.PlateCarree())\n",
    "c = ax.contour(lons, lats, eof3*1e5, clevs, colors='black', linewidths=1, transform=ccrs.PlateCarree())\n",
    "cb = fig.colorbar(cf, orientation='horizontal', aspect=70, shrink=0.6, pad=0.1, extendrect='True')\n",
    "cb.set_label('$10^{5}$', fontsize=12)\n",
    "\n",
    "ax = fig.add_subplot(3, 2, 6)\n",
    "plot_pc(ax)\n",
    "plt.title('PC3')\n",
    "plt.plot(pc3, color='k', linewidth=1)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "figname=dir_figs+varname+'_'+domain_name+'_'+season_name+'_eofs_pcs'\n",
    "fig.savefig(figname+'.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Reconstruction d'un champ à partir des EOFs et des PCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "day=int(input(\"Entrer un numéro de jour pour la reconstruction du champ : \"))\n",
    "field=var_anom[day]\n",
    "\n",
    "#5 EOFS\n",
    "reconst=eofs[0]*pcs[day,0]*np.std(\n",
    "    pcs[:,0])+eofs[1]*pcs[day,1]*np.std(\n",
    "    pcs[:,1])+eofs[2]*pcs[day,2]*np.std(\n",
    "    pcs[:,2])+eofs[3]*pcs[day,3]*np.std(\n",
    "    pcs[:,3])+eofs[4]*pcs[day,4]*np.std(\n",
    "    pcs[:,4])\n",
    "\n",
    "reconst=reconst/wgts\n",
    "\n",
    "#15 EOFS\n",
    "reconst2=eofs[0]*pcs[day,0]*np.std(\n",
    "    pcs[:,0])+eofs[1]*pcs[day,1]*np.std(\n",
    "    pcs[:,1])+eofs[2]*pcs[day,2]*np.std(\n",
    "    pcs[:,2])+eofs[3]*pcs[day,3]*np.std(\n",
    "    pcs[:,3])+eofs[4]*pcs[day,4]*np.std(\n",
    "    pcs[:,4])+eofs[5]*pcs[day,5]*np.std(    \n",
    "    pcs[:,5])+eofs[6]*pcs[day,6]*np.std(    \n",
    "    pcs[:,6])+eofs[7]*pcs[day,7]*np.std(\n",
    "    pcs[:,7])+eofs[8]*pcs[day,8]*np.std(\n",
    "    pcs[:,8])+eofs[9]*pcs[day,9]*np.std(\n",
    "    pcs[:,9])+eofs[10]*pcs[day,10]*np.std(\n",
    "    pcs[:,10])+eofs[11]*pcs[day,11]*np.std(\n",
    "    pcs[:,11])+eofs[12]*pcs[day,12]*np.std(\n",
    "    pcs[:,12])+eofs[13]*pcs[day,13]*np.std(\n",
    "    pcs[:,13])+eofs[14]*pcs[day,14]*np.std(\n",
    "    pcs[:,14])\n",
    "\n",
    "reconst2=reconst2/wgts\n",
    "\n",
    "fig = plt.figure(figsize=(15, 5))\n",
    "\n",
    "fig.suptitle('Reconstruction from the EOFs and PCs', fontsize=16)\n",
    "ax = fig.add_subplot(131, projection=projection)\n",
    "plt.title('Anomaly field', fontsize=10, loc='center')\n",
    "ax.coastlines()\n",
    "ax.set_extent([lonW, lonE, latS, latN], crs=ccrs.PlateCarree())\n",
    "boundary_path = make_boundary_path(lon, lat)\n",
    "ax.set_boundary(boundary_path, transform=ccrs.PlateCarree())\n",
    "cf = ax.contourf(lons, lats, field, levels2, cmap=cmap2, extend='both', transform=ccrs.PlateCarree())\n",
    "c = ax.contour(lons, lats, field, levels2, colors='black', linewidths=1, transform=ccrs.PlateCarree())\n",
    "cb = fig.colorbar(cf, orientation='horizontal', aspect=65, shrink=1, pad=0.05, extendrect='True')\n",
    "cb.set_label(units, fontsize=12)\n",
    "\n",
    "ax = fig.add_subplot(132, projection=projection)\n",
    "plt.title('Reconstruction with 5 EOFs', fontsize=10, loc='center')\n",
    "ax.coastlines()\n",
    "ax.set_extent([lonW, lonE, latS, latN], crs=ccrs.PlateCarree())\n",
    "boundary_path = make_boundary_path(lon, lat)\n",
    "ax.set_boundary(boundary_path, transform=ccrs.PlateCarree())\n",
    "cf = ax.contourf(lons, lats, reconst, levels2, cmap=cmap2, extend='both', transform=ccrs.PlateCarree())\n",
    "c = ax.contour(lons, lats, reconst, levels2, colors='black', linewidths=1, transform=ccrs.PlateCarree())\n",
    "cb = fig.colorbar(cf, orientation='horizontal', aspect=65, shrink=1, pad=0.05, extendrect='True')\n",
    "cb.set_label(units, fontsize=12)\n",
    "\n",
    "ax = fig.add_subplot(133, projection=projection)\n",
    "plt.title('Reconstruction with 15 EOFs', fontsize=10, loc='center')\n",
    "ax.coastlines()\n",
    "ax.set_extent([lonW, lonE, latS, latN], crs=ccrs.PlateCarree())\n",
    "boundary_path = make_boundary_path(lon, lat)\n",
    "ax.set_boundary(boundary_path, transform=ccrs.PlateCarree())\n",
    "cf = ax.contourf(lons, lats, reconst2, levels2, cmap=cmap2, extend='both', transform=ccrs.PlateCarree())\n",
    "c = ax.contour(lons, lats, reconst2, levels2, colors='black', linewidths=1, transform=ccrs.PlateCarree())\n",
    "cb = fig.colorbar(cf, orientation='horizontal', aspect=65, shrink=1, pad=0.05, extendrect='True')\n",
    "cb.set_label(units, fontsize=12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>Question : </b>\n",
    "<p><b>1) </b>Pour le jour choisi, la reconstruction du champ sur la base des 15 premiers EOFs est-elle satisfaisante ?</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Réponse : </b>\n",
    "<p>\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Fonction de tracé pour l'espace des phases 2D défini par PC1 et PC2 et dans l'espace des phases 3D défini par PC1 PC2 et PC3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_phase_space2d(ax):\n",
    "    plt.title('')\n",
    "    plt.xlabel('PC1')\n",
    "    plt.ylabel('PC2')\n",
    "    if varname=='z':\n",
    "        plt.xlim(-9000, 9000)\n",
    "        plt.ylim(-9000, 9000)\n",
    "    if varname=='msl':\n",
    "        plt.xlim(-200, 200)\n",
    "        plt.ylim(-200, 200)\n",
    "    plt.axvline(0, color='k', linestyle='--')\n",
    "    plt.axhline(0, color='k', linestyle='--')\n",
    "    return ax\n",
    "\n",
    "def plot_phase_space3d(ax):\n",
    "    ax.set_xlabel('PC1')\n",
    "    ax.set_ylabel('PC2')\n",
    "    ax.set_zlabel('PC3')\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Tracé du nuage de points des séries temporelles dans l'espace des phases défini par PC1 et PC2 (+ densité avec la fonction gaussian_kde de scipy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "fig.suptitle('PC1 and PC2 phase space density', fontsize=14)\n",
    "plot_phase_space2d(ax)\n",
    "xy = np.vstack([pc1,pc2])\n",
    "z = gaussian_kde(xy)(xy)\n",
    "#ax.scatter(pc1,pc2, s=10, color = 'r')\n",
    "ax.scatter(pc1, pc2, cmap='jet', c=z, s=10)\n",
    "plt.show()\n",
    "\n",
    "figname=dir_figs+varname+'_'+domain_name+'_'+season_name+'_pc12_density'\n",
    "fig.savefig(figname+'.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Tracé du nuage de points des séries temporelles dans l'espace des phases défini par PC1 PC2 et PC3 (projection=3D, + densité avec la fonction gaussian_kde de scipy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 10))\n",
    "fig.suptitle('PC1 PC2 and PC3 phase space', fontsize=14)\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "plot_phase_space3d(ax)\n",
    "xyz = np.vstack([pc1,pc2,pc3])\n",
    "z = gaussian_kde(xyz)(xyz)\n",
    "#ax.scatter(pc1,pc2,pc3, s=10, color = 'r')\n",
    "ax.scatter(pc1, pc2, pc3, cmap='jet', c=z, s=10)\n",
    "plt.show()\n",
    "\n",
    "figname=dir_figs+varname+'_'+domain_name+'_'+season_name+'_pc123_density'\n",
    "fig.savefig(figname+'.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Les régimes de temps sont des attracteurs dans l'espace climatique. Pour les mettre en évidence on va utiliser une méthode de classification (\"clustering\") de type Kmeans. Cette méthode nécessite un choix a priori d'un nombre de classes que l'on fixe à 4 (4 attracteurs dans l'espace climatique). La classification est faite dans l'espace des phases des PCs issu de l'ACP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etape 4 : classification en 4 classes = régimes (méthode k-means)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "<b>Exécuter l'ensemble des cellules de l'étape 4 ci-dessous pour réaliser la classification automatique en 4 régimes via la méthode k-means.</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Clustering - méthode K-means. L'algorithme est exécuté 100 fois avec différents \"centroid seeds\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pcs = np.array([pc1,pc2,pc3,pcs[:,3],\n",
    "                pcs[:,4],pcs[:,5],pcs[:,6],\n",
    "                pcs[:,7],pcs[:,8],pcs[:,9],\n",
    "                pcs[:,10],pcs[:,11],pcs[:,12],\n",
    "                pcs[:,13],pcs[:,14]],)\n",
    "pcs=pcs.transpose()\n",
    "\n",
    "#Number of time the k-means algorithm will be run with different centroid seeds\n",
    "n_init=100\n",
    "#Maximum number of iterations of the k-means algorithm for a single run\n",
    "max_iter=500\n",
    "\n",
    "# Number of clusters\n",
    "kmeans = KMeans(n_clusters=4, n_init=n_init, max_iter=max_iter, algorithm=\"full\", verbose=1)\n",
    "# Fitting the input data\n",
    "kmeans = kmeans.fit(pcs)\n",
    "# Getting the cluster labels\n",
    "cluster = kmeans.predict(pcs)\n",
    "# Centroid values\n",
    "centroids = kmeans.cluster_centers_\n",
    "\n",
    "print(cluster)\n",
    "print(cluster.shape)\n",
    "print(centroids.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Comptage du nombre de jours par cluster et des fréquences (nombre de jours du cluster divisé par nombre de jours total)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nc1=list(cluster[:]).count(0)\n",
    "nc2=list(cluster[:]).count(1)\n",
    "nc3=list(cluster[:]).count(2)\n",
    "nc4=list(cluster[:]).count(3)\n",
    "\n",
    "f1=round(nc1/cluster.shape[0]*100,2)\n",
    "f2=round(nc2/cluster.shape[0]*100,2)\n",
    "f3=round(nc3/cluster.shape[0]*100,2)\n",
    "f4=round(nc4/cluster.shape[0]*100,2)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Création d'un tableau des couleurs selon le numéro de cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "colors=[\"\"]*len(cluster)\n",
    "couleur=[\"peru\",\"gold\",\"grey\",\"turquoise\"]\n",
    "#couleur=[\"blue\",\"red\",\"green\",\"orange\"]\n",
    "for i in range(len(cluster)):\n",
    "    colors[i]=couleur[cluster[i]]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Tracé du nuage de points des séries temporelles dans l'espace des phases défini par PC1 et PC2 après clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111)\n",
    "fig.suptitle('PC1 and PC2 phase space (4 clusters)', fontsize=14)\n",
    "plot_phase_space2d(ax)\n",
    "plt.scatter(pc1, pc2, c=colors, s=10)\n",
    "plt.scatter(centroids[:, 0], centroids[:, 1], c=couleur, s=2000, alpha=1, marker='+');\n",
    "\n",
    "patch1 = mpatches.Patch(color=couleur[0], label='Cluster 1 : '+str(nc1)+' ('+str(f1)+'%)')\n",
    "patch2 = mpatches.Patch(color=couleur[1], label='Cluster 2 : '+str(nc2)+' ('+str(f2)+'%)')\n",
    "patch3 = mpatches.Patch(color=couleur[2], label='Cluster 3 : '+str(nc3)+' ('+str(f3)+'%)')\n",
    "patch4 = mpatches.Patch(color=couleur[3], label='Cluster 4 : '+str(nc4)+' ('+str(f4)+'%)')\n",
    "all_handles = (patch1, patch2, patch3, patch4)\n",
    "leg = ax.legend(handles=all_handles, loc='upper right')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "figname=dir_figs+varname+'_'+domain_name+'_'+season_name+'_pc12_clustering'\n",
    "fig.savefig(figname+'.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Tracé du nuage de points des séries temporelles dans l'espace des phases défini par PC1 PC2 et PC3 après clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 10))\n",
    "fig.suptitle('PC1 PC2 and PC3 phase space (4 clusters)', fontsize=14)\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "plot_phase_space3d(ax)\n",
    "ax.scatter(pc1, pc2, pc3, c=colors, s=10)\n",
    "ax.scatter(centroids[:, 0], centroids[:, 1], centroids[:, 2], c=couleur, s=2000, alpha=1, marker='+')\n",
    "\n",
    "patch1 = mpatches.Patch(color=couleur[0], label='Cluster 1 : '+str(nc1)+' ('+str(f1)+'%)')\n",
    "patch2 = mpatches.Patch(color=couleur[1], label='Cluster 2 : '+str(nc2)+' ('+str(f2)+'%)')\n",
    "patch3 = mpatches.Patch(color=couleur[2], label='Cluster 3 : '+str(nc3)+' ('+str(f3)+'%)')\n",
    "patch4 = mpatches.Patch(color=couleur[3], label='Cluster 4 : '+str(nc4)+' ('+str(f4)+'%)')\n",
    "all_handles = (patch1, patch2, patch3, patch4)\n",
    "leg = ax.legend(handles=all_handles, loc='upper right')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "figname=dir_figs+varname+'_'+domain_name+'_'+season_name+'_pc123_clustering'\n",
    "fig.savefig(figname+'.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>Question : </b>\n",
    "<p><b>1) </b>Comparer les classes (clusters) avec celles du voisin. Que constate t-on ?</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Réponse : </b>\n",
    "<p>\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etape 5 : obtention des régimes de temps"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Calcul des composites du champ pour chaque cluster. Pour chaque cluster, on fait la moyenne du champ pour tous jours qui sont classés dans ce cluster --> 4 régimes de temps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "id_cluster1=np.any([cluster==0],axis=0)\n",
    "id_cluster2=np.any([cluster==1],axis=0)\n",
    "id_cluster3=np.any([cluster==2],axis=0)\n",
    "id_cluster4=np.any([cluster==3],axis=0)\n",
    "\n",
    "print(id_cluster1)\n",
    "print(id_cluster2)\n",
    "print(id_cluster3)\n",
    "print(id_cluster4)\n",
    "\n",
    "mean_c1 = var[id_cluster1,:,:].mean(axis=0)\n",
    "mean_c2 = var[id_cluster2,:,:].mean(axis=0)\n",
    "mean_c3 = var[id_cluster3,:,:].mean(axis=0)\n",
    "mean_c4 = var[id_cluster4,:,:].mean(axis=0)\n",
    "\n",
    "mean_c1_anom = var_anom[id_cluster1,:,:].mean(axis=0)\n",
    "mean_c2_anom = var_anom[id_cluster2,:,:].mean(axis=0)\n",
    "mean_c3_anom = var_anom[id_cluster3,:,:].mean(axis=0)\n",
    "mean_c4_anom = var_anom[id_cluster4,:,:].mean(axis=0)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Tracé des 4 régimes de temps (anomalie en couleur et champ moyen en isolignes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if varname=='z':\n",
    "    clevs = np.linspace(5000, 6000, 11)\n",
    "    clevs_anom = np.linspace(-150, 150, 11)\n",
    "if varname=='msl':\n",
    "    clevs = np.linspace(990, 1020, 15)\n",
    "    clevs_anom = np.linspace(-8, 8, 17)\n",
    "\n",
    "fig = plt.figure(figsize=(15, 10))\n",
    "fig.suptitle('Weather regimes : '+var_text+' - '+domain+' - '+season+ ' '+season1+'-'+season2, fontsize=16)\n",
    "\n",
    "ax = fig.add_subplot(2, 2, 1, projection=projection)\n",
    "plt.title('Regime 1 (freq = '+str(f1)+'%)', fontsize=10, loc='center', color=couleur[0])\n",
    "ax.coastlines()\n",
    "ax.set_extent(*bounds, crs=ccrs.PlateCarree())\n",
    "boundary_path = make_boundary_path(lons, lats)\n",
    "ax.set_boundary(boundary_path, transform=ccrs.PlateCarree())\n",
    "cf = ax.contourf(lons, lats, mean_c1_anom, levels=clevs_anom, \n",
    "                 cmap=cmap2, extend='both', transform=ccrs.PlateCarree())\n",
    "c = ax.contour(lons, lats, mean_c1, levels=clevs, colors='black', linewidths=1, transform=ccrs.PlateCarree())\n",
    "ax.clabel(c, inline=1, fmt='%4.0f', fontsize=10)\n",
    "cb = fig.colorbar(cf, orientation='horizontal', aspect=65, shrink=1, pad=0.05, extendrect='True')\n",
    "cb.set_label('Anomaly ('+units+')', fontsize=12)\n",
    "\n",
    "ax = fig.add_subplot(2, 2, 2, projection=projection)\n",
    "plt.title('Regime 2 (freq = '+str(f2)+'%)', fontsize=10, loc='center', color=couleur[1])\n",
    "ax.coastlines()\n",
    "ax.set_extent(*bounds, crs=ccrs.PlateCarree())\n",
    "boundary_path = make_boundary_path(lons, lats)\n",
    "ax.set_boundary(boundary_path, transform=ccrs.PlateCarree())\n",
    "cf = ax.contourf(lons, lats, mean_c2_anom, levels=clevs_anom, \n",
    "                 cmap=cmap2, extend='both', transform=ccrs.PlateCarree())\n",
    "c = ax.contour(lons, lats, mean_c2, levels=clevs, colors='black', linewidths=1, transform=ccrs.PlateCarree())\n",
    "ax.clabel(c, inline=1, fmt='%4.0f', fontsize=10)\n",
    "cb = fig.colorbar(cf, orientation='horizontal', aspect=65, shrink=1, pad=0.05, extendrect='True')\n",
    "cb.set_label('Anomaly ('+units+')', fontsize=12)\n",
    "\n",
    "ax = fig.add_subplot(2, 2, 3, projection=projection)\n",
    "plt.title('Regime 3 (freq = '+str(f3)+'%)', fontsize=10, loc='center', color=couleur[2])\n",
    "ax.coastlines()\n",
    "ax.set_extent(*bounds, crs=ccrs.PlateCarree())\n",
    "boundary_path = make_boundary_path(lons, lats)\n",
    "ax.set_boundary(boundary_path, transform=ccrs.PlateCarree())\n",
    "cf = ax.contourf(lons, lats, mean_c3_anom, levels=clevs_anom, \n",
    "                 cmap=cmap2, extend='both', transform=ccrs.PlateCarree())\n",
    "c = ax.contour(lons, lats, mean_c3, levels=clevs, colors='black', linewidths=1, transform=ccrs.PlateCarree())\n",
    "ax.clabel(c, inline=1, fmt='%4.0f', fontsize=10)\n",
    "cb = fig.colorbar(cf, orientation='horizontal', aspect=65, shrink=1, pad=0.05, extendrect='True')\n",
    "cb.set_label('Anomaly ('+units+')', fontsize=12)\n",
    "\n",
    "ax = fig.add_subplot(2, 2, 4, projection=projection)\n",
    "plt.title('Regime 4 (freq = '+str(f4)+'%)', fontsize=10, loc='center', color=couleur[3])\n",
    "ax.coastlines()\n",
    "ax.set_extent(*bounds, crs=ccrs.PlateCarree())\n",
    "boundary_path = make_boundary_path(lons, lats)\n",
    "ax.set_boundary(boundary_path, transform=ccrs.PlateCarree())\n",
    "cf = ax.contourf(lons, lats, mean_c4_anom, levels=clevs_anom, \n",
    "                 cmap=cmap2, extend='both', transform=ccrs.PlateCarree())\n",
    "c = ax.contour(lons, lats, mean_c4, levels=clevs, colors='black', linewidths=1, transform=ccrs.PlateCarree())\n",
    "ax.clabel(c, inline=1, fmt='%4.0f', fontsize=10)\n",
    "cb = fig.colorbar(cf, orientation='horizontal', aspect=65, shrink=1, pad=0.05, extendrect='True')\n",
    "cb.set_label('Anomaly ('+units+')', fontsize=12)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "figname=dir_figs+varname+'_'+domain_name+'_'+season_name+'_'+'regimes'\n",
    "fig.savefig(figname+'.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>Question : </b>\n",
    "<p><b>1) </b>Nommer chacun des 4 régimes de temps\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Réponse en éxécutant la cellule de code ci-dessous </b>\n",
    "<p>\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if domain_name=='natl' and season_name=='winter':\n",
    "    r1=input(\"Parmi les propositions suivantes nommer le régime 1 : NAO+ / NAO- / Dorsale Atl / Blocage : \")\n",
    "    r2=input(\"Parmi les propositions suivantes nommer le régime 2 : NAO+ / NAO- / Dorsale Atl / Blocage : \")\n",
    "    r3=input(\"Parmi les propositions suivantes nommer le régime 3 : NAO+ / NAO- / Dorsale Atl / Blocage : \")\n",
    "    r4=input(\"Parmi les propositions suivantes nommer le régime 4 : NAO+ / NAO- / Dorsale Atl / Blocage : \")\n",
    "\n",
    "if domain_name=='natl' and season_name=='summer':\n",
    "    r1=input(\"Parmi les propositions suivantes nommer le régime 1 : Zonal / Anticyclone Gro / Blocage été / Thalweg Atl : \")\n",
    "    r2=input(\"Parmi les propositions suivantes nommer le régime 2 : Zonal / Anticyclone Gro / Blocage été / Thalweg Atl : \")\n",
    "    r3=input(\"Parmi les propositions suivantes nommer le régime 3 : Zonal / Anticyclone Gro / Blocage été / Thalweg Atl : \")\n",
    "    r4=input(\"Parmi les propositions suivantes nommer le régime 4 : Zonal / Anticyclone Gro / Blocage été / Thalweg Atl : \")\n",
    "\n",
    "regime=[r1, r2, r3, r4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>Question : Modifier le tableau \"couleur\" associé au tableau \"regime\" pour avoir la correspondance suivante : </b>\n",
    "<p>\n",
    "<b>NAO+ : rouge</b>\n",
    "<br>\n",
    "<b>NAO- : vert</b>\n",
    "<br>\n",
    "<b>Dorsale Atlantique : orange</b>\n",
    "<br>\n",
    "<b> Blocage Scandinave: bleu</b>\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Réponse en modifiant la cellule de code ci-dessous </b>\n",
    "<p>\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(regime)\n",
    "couleur=[\"blue\",\"orange\",\"red\",\"green\"]\n",
    "print(couleur)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Création d'un tableau des couleurs selon le numéro de cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "colors=[\"\"]*len(cluster)\n",
    "for i in range(len(cluster)):\n",
    "    colors[i]=couleur[cluster[i]]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Tracé des 4 régimes de temps avec le bon code couleur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 10))\n",
    "fig.suptitle('Weather regimes : '+var_text+' - '+domain+' - '+season+ ' '+season1+'-'+season2, fontsize=16)\n",
    "\n",
    "ax = fig.add_subplot(2, 2, 1, projection=projection)\n",
    "plt.title(r1+' (freq = '+str(f1)+'%)', fontsize=10, loc='center', color=couleur[0])\n",
    "ax.coastlines()\n",
    "ax.set_extent(*bounds, crs=ccrs.PlateCarree())\n",
    "boundary_path = make_boundary_path(lons, lats)\n",
    "ax.set_boundary(boundary_path, transform=ccrs.PlateCarree())\n",
    "cf = ax.contourf(lons, lats, mean_c1_anom, levels=clevs_anom, \n",
    "                 cmap=cmap2, extend='both', transform=ccrs.PlateCarree())\n",
    "c = ax.contour(lons, lats, mean_c1, levels=clevs, colors='black', linewidths=1, transform=ccrs.PlateCarree())\n",
    "ax.clabel(c, inline=1, fmt='%4.0f', fontsize=10)\n",
    "cb = fig.colorbar(cf, orientation='horizontal', aspect=65, shrink=1, pad=0.05, extendrect='True')\n",
    "cb.set_label('Anomaly ('+units+')', fontsize=12)\n",
    "\n",
    "ax = fig.add_subplot(2, 2, 2, projection=projection)\n",
    "plt.title(r2+' (freq = '+str(f2)+'%)', fontsize=10, loc='center', color=couleur[1])\n",
    "ax.coastlines()\n",
    "ax.set_extent(*bounds, crs=ccrs.PlateCarree())\n",
    "boundary_path = make_boundary_path(lons, lats)\n",
    "ax.set_boundary(boundary_path, transform=ccrs.PlateCarree())\n",
    "cf = ax.contourf(lons, lats, mean_c2_anom, levels=clevs_anom, \n",
    "                 cmap=cmap2, extend='both', transform=ccrs.PlateCarree())\n",
    "c = ax.contour(lons, lats, mean_c2, levels=clevs, colors='black', linewidths=1, transform=ccrs.PlateCarree())\n",
    "ax.clabel(c, inline=1, fmt='%4.0f', fontsize=10)\n",
    "cb = fig.colorbar(cf, orientation='horizontal', aspect=65, shrink=1, pad=0.05, extendrect='True')\n",
    "cb.set_label('Anomaly ('+units+')', fontsize=12)\n",
    "\n",
    "ax = fig.add_subplot(2, 2, 3, projection=projection)\n",
    "plt.title(r3+' (freq = '+str(f3)+'%)', fontsize=10, loc='center', color=couleur[2])\n",
    "ax.coastlines()\n",
    "ax.set_extent(*bounds, crs=ccrs.PlateCarree())\n",
    "boundary_path = make_boundary_path(lons, lats)\n",
    "ax.set_boundary(boundary_path, transform=ccrs.PlateCarree())\n",
    "cf = ax.contourf(lons, lats, mean_c3_anom, levels=clevs_anom, \n",
    "                 cmap=cmap2, extend='both', transform=ccrs.PlateCarree())\n",
    "c = ax.contour(lons, lats, mean_c3, levels=clevs, colors='black', linewidths=1, transform=ccrs.PlateCarree())\n",
    "ax.clabel(c, inline=1, fmt='%4.0f', fontsize=10)\n",
    "cb = fig.colorbar(cf, orientation='horizontal', aspect=65, shrink=1, pad=0.05, extendrect='True')\n",
    "cb.set_label('Anomaly ('+units+')', fontsize=12)\n",
    "\n",
    "ax = fig.add_subplot(2, 2, 4, projection=projection)\n",
    "plt.title(r4' (freq = '+str(f4)+'%)', fontsize=10, loc='center', color=couleur[3])\n",
    "ax.coastlines()\n",
    "ax.set_extent(*bounds, crs=ccrs.PlateCarree())\n",
    "boundary_path = make_boundary_path(lons, lats)\n",
    "ax.set_boundary(boundary_path, transform=ccrs.PlateCarree())\n",
    "cf = ax.contourf(lons, lats, mean_c4_anom, levels=clevs_anom, \n",
    "                 cmap=cmap2, extend='both', transform=ccrs.PlateCarree())\n",
    "c = ax.contour(lons, lats, mean_c4, levels=clevs, colors='black', linewidths=1, transform=ccrs.PlateCarree())\n",
    "ax.clabel(c, inline=1, fmt='%4.0f', fontsize=10)\n",
    "cb = fig.colorbar(cf, orientation='horizontal', aspect=65, shrink=1, pad=0.05, extendrect='True')\n",
    "cb.set_label('Anomaly ('+units+')', fontsize=12)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "figname=dir_figs+varname+'_'+domain_name+'_'+season_name+'_'+'regimes2'\n",
    "fig.savefig(figname+'.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etape 6 : temps sensible associé aux régimes de temps"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Ouverture du fichier de réanalyses quotidiennes ERA5 de température à 2m (T2m) et de précipitations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_t0    = xr.open_dataset(dir_data+'t2m_eur_19790101_20191231.nc')\n",
    "data_tp0    = xr.open_dataset(dir_data+'tp_eur_19790101_20191231.nc')\n",
    "print(data_t0)\n",
    "print(data_tp0)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Sélection de la sous-periode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if season_name == 'winter':\n",
    "    d1='1979-12-01T09'\n",
    "    d2='2018-03-31T09'\n",
    "\n",
    "if season_name == 'summer':\n",
    "    d1='1979-06-01T09'\n",
    "    d2='2018-09-30T09'\n",
    "\n",
    "    # Date index from startday to endday\n",
    "d = pd.date_range(d1, d2, freq='D')\n",
    "print(d)\n",
    "\n",
    "# Remove 29/02\n",
    "#mask = is_leap_and_29Feb(d)\n",
    "#d=d[~mask]\n",
    "#print(d)\n",
    "\n",
    "# Select Season\n",
    "if season_name == 'winter':\n",
    "    mm=np.any([d.month==12,d.month==1,d.month==2,d.month==3],axis=0)\n",
    "if season_name == 'summer':\n",
    "    mm=np.any([d.month==6,d.month==7,d.month==8,d.month==9],axis=0)\n",
    "\n",
    "dd2=d[mm]\n",
    "print(dd2)\n",
    "\n",
    "data_t    = xr.open_dataset(dir_data+'t2m_eur_19790101_20191231.nc').sel(time=slice(d1,d2))\n",
    "data_t    = data_t.sel(time=dd2)\n",
    "data_tp    = xr.open_dataset(dir_data+'tp_eur_19790101_20191231.nc').sel(time=slice(d1,d2))\n",
    "data_tp    = data_tp.sel(time=dd2)\n",
    "\n",
    "\n",
    "print(data_t0)\n",
    "print(data_tp0)\n",
    "print(data_t)\n",
    "print(data_tp)\n",
    "\n",
    "lat_t  = data_t.latitude.values\n",
    "lon_t  = data_t.longitude.values\n",
    "time_t  = data_t.time.values"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Calcul des anomalies quotidiennes de T2m et de précipitations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(' ----- Computing daily anomalies of T2m ----- ')\n",
    "data_t_anom = data_t.groupby('time.dayofyear') - data_t.groupby('time.dayofyear').mean('time')\n",
    "print(' ----- Computing daily anomalies of precipitation ----- ')\n",
    "data_tp_anom = data_tp.groupby('time.dayofyear') - data_tp.groupby('time.dayofyear').mean('time')\n",
    "\n",
    "t2m_anom=data_t_anom['t2m']\n",
    "tp_anom=data_tp_anom['tp']*1000\n",
    "\n",
    "print(t2m_anom.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Calcul des composites de T2m et de précipitations pour chaque cluster. Pour chaque cluster, on fait la moyenne du champ pour les jours qui \"tombent\" dans ce cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(cluster.shape)\n",
    "print(dates2)\n",
    "\n",
    "if season_name=='winter':\n",
    "    if var_text=='Z500':\n",
    "        dd1='1979-12-01T18'\n",
    "        dd2='2018-03-31T18'\n",
    "    if var_text=='MSLP':\n",
    "        dd1='1979-12-01T09'\n",
    "        dd2='2018-03-31T09'\n",
    "        \n",
    "if season_name=='summer':\n",
    "    if var_text=='Z500':\n",
    "        dd1='1979-06-01T18'\n",
    "        dd2='2018-09-30T18'\n",
    "    if var_text=='MSLP':\n",
    "        dd1='1979-06-01T09'\n",
    "        dd2='2018-09-30T09'\n",
    "        \n",
    "index_y=np.all([dates2>=dd1, dates2<=dd2], axis=0)\n",
    "cluster_t=cluster[index_y]\n",
    "print(cluster_t.shape)\n",
    "\n",
    "id_cluster1_t=np.any([cluster_t==0],axis=0)\n",
    "id_cluster2_t=np.any([cluster_t==1],axis=0)\n",
    "id_cluster3_t=np.any([cluster_t==2],axis=0)\n",
    "id_cluster4_t=np.any([cluster_t==3],axis=0)\n",
    "\n",
    "mean_c1_anom_t = t2m_anom[id_cluster1_t,:,:].mean(axis=0)\n",
    "mean_c2_anom_t = t2m_anom[id_cluster2_t,:,:].mean(axis=0)\n",
    "mean_c3_anom_t = t2m_anom[id_cluster3_t,:,:].mean(axis=0)\n",
    "mean_c4_anom_t = t2m_anom[id_cluster4_t,:,:].mean(axis=0)\n",
    "\n",
    "mean_c1_anom_tp = tp_anom[id_cluster1_t,:,:].mean(axis=0)\n",
    "mean_c2_anom_tp = tp_anom[id_cluster2_t,:,:].mean(axis=0)\n",
    "mean_c3_anom_tp = tp_anom[id_cluster3_t,:,:].mean(axis=0)\n",
    "mean_c4_anom_tp = tp_anom[id_cluster4_t,:,:].mean(axis=0)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Tracé des composites des anomalies de T2m pour chaque régime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#projection2=ccrs.EuroPP()\n",
    "#projection2=ccrs.PlateCarree()\n",
    "projection2=ccrs.NearsidePerspective(central_longitude=5.0, central_latitude=55.0)\n",
    "bounds = [(-20, 30, 30, 80)]\n",
    "\n",
    "levs_t_anom = np.linspace(-4, 4, 21)\n",
    "\n",
    "fig = plt.figure(figsize=(15, 10))\n",
    "fig.suptitle('Composites of 2-meter temperature anomalies : ERA5 DJFM 1979-2018', fontsize=16)\n",
    "\n",
    "ax = fig.add_subplot(2, 2, 1, projection=projection2)\n",
    "plt.title(regime[0], fontsize=10, loc='center', color=couleur[0])\n",
    "ax.coastlines()\n",
    "ax.set_extent(*bounds, crs=ccrs.PlateCarree())\n",
    "boundary_path = make_boundary_path(lon_t, lat_t)\n",
    "ax.set_boundary(boundary_path, transform=ccrs.PlateCarree())\n",
    "cf = ax.contourf(lon_t, lat_t, mean_c1_anom_t, levels=levs_t_anom, \n",
    "                 cmap=cmap2, extend='both', transform=ccrs.PlateCarree())\n",
    "ax.clabel(c, inline=1, fmt='%4.0f', fontsize=10)\n",
    "cb = fig.colorbar(cf, orientation='vertical', aspect=65, shrink=1, pad=0.05, extendrect='True')\n",
    "cb.set_label('Anomaly (°C)', fontsize=12)\n",
    "\n",
    "ax = fig.add_subplot(2, 2, 2, projection=projection2)\n",
    "plt.title(regime[1], fontsize=10, loc='center', color=couleur[1])\n",
    "ax.coastlines()\n",
    "ax.set_extent(*bounds, crs=ccrs.PlateCarree())\n",
    "boundary_path = make_boundary_path(lon_t, lat_t)\n",
    "ax.set_boundary(boundary_path, transform=ccrs.PlateCarree())\n",
    "cf = ax.contourf(lon_t, lat_t, mean_c2_anom_t, levels=levs_t_anom, \n",
    "                 cmap=cmap2, extend='both', transform=ccrs.PlateCarree())\n",
    "ax.clabel(c, inline=1, fmt='%4.0f', fontsize=10)\n",
    "cb = fig.colorbar(cf, orientation='vertical', aspect=65, shrink=1, pad=0.05, extendrect='True')\n",
    "cb.set_label('Anomaly (°C)', fontsize=12)\n",
    "\n",
    "ax = fig.add_subplot(2, 2, 3, projection=projection2)\n",
    "plt.title(regime[2], fontsize=10, loc='center', color=couleur[2])\n",
    "ax.coastlines()\n",
    "ax.set_extent(*bounds, crs=ccrs.PlateCarree())\n",
    "boundary_path = make_boundary_path(lon_t, lat_t)\n",
    "ax.set_boundary(boundary_path, transform=ccrs.PlateCarree())\n",
    "cf = ax.contourf(lon_t, lat_t, mean_c3_anom_t, levels=levs_t_anom, \n",
    "                 cmap=cmap2, extend='both', transform=ccrs.PlateCarree())\n",
    "ax.clabel(c, inline=1, fmt='%4.0f', fontsize=10)\n",
    "cb = fig.colorbar(cf, orientation='vertical', aspect=65, shrink=1, pad=0.05, extendrect='True')\n",
    "cb.set_label('Anomaly (°C)', fontsize=12)\n",
    "\n",
    "ax = fig.add_subplot(2, 2, 4, projection=projection2)\n",
    "plt.title(regime[3], fontsize=10, loc='center', color=couleur[3])\n",
    "ax.coastlines()\n",
    "ax.set_extent(*bounds, crs=ccrs.PlateCarree())\n",
    "boundary_path = make_boundary_path(lon_t, lat_t)\n",
    "ax.set_boundary(boundary_path, transform=ccrs.PlateCarree())\n",
    "cf = ax.contourf(lon_t, lat_t, mean_c4_anom_t, levels=levs_t_anom, \n",
    "                 cmap=cmap2, extend='both', transform=ccrs.PlateCarree())\n",
    "ax.clabel(c, inline=1, fmt='%4.0f', fontsize=10)\n",
    "cb = fig.colorbar(cf, orientation='vertical', aspect=65, shrink=1, pad=0.05, extendrect='True')\n",
    "cb.set_label('Anomaly (°C)', fontsize=12)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "figname=dir_figs+varname+'_'+domain_name+'_t2m_composite_DJFM'\n",
    "fig.savefig(figname+'.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Tracé des composites des anomalies de précipitations pour chaque régime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cmap3='BrBG'\n",
    "\n",
    "levs_tp_anom = np.linspace(-1, 1, 21)\n",
    "\n",
    "fig = plt.figure(figsize=(15, 10))\n",
    "fig.suptitle('Composites of precipitation anomalies : ERA5 1979-2018', fontsize=16)\n",
    "\n",
    "ax = fig.add_subplot(2, 2, 1, projection=projection2)\n",
    "plt.title(regime[0], fontsize=10, loc='center', color=couleur[0])\n",
    "ax.coastlines()\n",
    "ax.set_extent(*bounds, crs=ccrs.PlateCarree())\n",
    "boundary_path = make_boundary_path(lon_t, lat_t)\n",
    "ax.set_boundary(boundary_path, transform=ccrs.PlateCarree())\n",
    "cf = ax.contourf(lon_t, lat_t, mean_c1_anom_tp, levels=levs_tp_anom, \n",
    "                 cmap=cmap3, extend='both', transform=ccrs.PlateCarree())\n",
    "ax.clabel(c, inline=1, fmt='%4.0f', fontsize=10)\n",
    "cb = fig.colorbar(cf, orientation='vertical', aspect=65, shrink=1, pad=0.05, extendrect='True')\n",
    "cb.set_label('Anomaly (mm/day)', fontsize=12)\n",
    "\n",
    "ax = fig.add_subplot(2, 2, 2, projection=projection2)\n",
    "plt.title(regime[1], fontsize=10, loc='center', color=couleur[1])\n",
    "ax.coastlines()\n",
    "ax.set_extent(*bounds, crs=ccrs.PlateCarree())\n",
    "boundary_path = make_boundary_path(lon_t, lat_t)\n",
    "ax.set_boundary(boundary_path, transform=ccrs.PlateCarree())\n",
    "cf = ax.contourf(lon_t, lat_t, mean_c2_anom_tp, levels=levs_tp_anom, \n",
    "                 cmap=cmap3, extend='both', transform=ccrs.PlateCarree())\n",
    "ax.clabel(c, inline=1, fmt='%4.0f', fontsize=10)\n",
    "cb = fig.colorbar(cf, orientation='vertical', aspect=65, shrink=1, pad=0.05, extendrect='True')\n",
    "cb.set_label('Anomaly (mm/day)', fontsize=12)\n",
    "\n",
    "ax = fig.add_subplot(2, 2, 3, projection=projection2)\n",
    "plt.title(regime[2], fontsize=10, loc='center', color=couleur[2])\n",
    "ax.coastlines()\n",
    "ax.set_extent(*bounds, crs=ccrs.PlateCarree())\n",
    "boundary_path = make_boundary_path(lon_t, lat_t)\n",
    "ax.set_boundary(boundary_path, transform=ccrs.PlateCarree())\n",
    "cf = ax.contourf(lon_t, lat_t, mean_c3_anom_tp, levels=levs_tp_anom, \n",
    "                 cmap=cmap3, extend='both', transform=ccrs.PlateCarree())\n",
    "ax.clabel(c, inline=1, fmt='%4.0f', fontsize=10)\n",
    "cb = fig.colorbar(cf, orientation='vertical', aspect=65, shrink=1, pad=0.05, extendrect='True')\n",
    "cb.set_label('Anomaly (mm/day)', fontsize=12)\n",
    "\n",
    "ax = fig.add_subplot(2, 2, 4, projection=projection2)\n",
    "plt.title(regime[3], fontsize=10, loc='center', color=couleur[3])\n",
    "ax.coastlines()\n",
    "ax.set_extent(*bounds, crs=ccrs.PlateCarree())\n",
    "boundary_path = make_boundary_path(lon_t, lat_t)\n",
    "ax.set_boundary(boundary_path, transform=ccrs.PlateCarree())\n",
    "cf = ax.contourf(lon_t, lat_t, mean_c4_anom_tp, levels=levs_tp_anom, \n",
    "                 cmap=cmap3, extend='both', transform=ccrs.PlateCarree())\n",
    "ax.clabel(c, inline=1, fmt='%4.0f', fontsize=10)\n",
    "cb = fig.colorbar(cf, orientation='vertical', aspect=65, shrink=1, pad=0.05, extendrect='True')\n",
    "cb.set_label('Anomaly (mm/day)', fontsize=12)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "figname=dir_figs+varname+'_'+domain_name+'_precip_composite_DJFM'\n",
    "fig.savefig(figname+'.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>Question : </b>\n",
    "<p><b>1) </b>Préciser l’impact de chaque régime en temps sensible (température/précipitation) sur l'Europe de l'ouest. Ces impacts sont-ils spatialement homogènes pour tous les régimes ? Sinon, préciser les disparités régionales. Comparer éventuellement aux composites suivants :\n",
    "    \n",
    "http://blogs.reading.ac.uk/weather-and-climate-at-reading/files/2020/02/RLee-Fig-1.png</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Réponse : </b>\n",
    "<p>\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etape 7 : étude des occurrences saisonnières des régimes"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Calcul du nombre d'occurences de régimes par saison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Find indexes for end of season\n",
    "time_str = [x for x in range(len(dates2))]\n",
    "date_str = [x for x in range(len(dates2))]\n",
    "for i in range(len(dates2)):\n",
    "    time_str[i] = str(dates2[i])\n",
    "    date_str[i] = time_str[i][5:10]\n",
    "\n",
    "if season_name == 'winter':\n",
    "    index_end = [i for i, value in enumerate(date_str) if value == '03-31']\n",
    "\n",
    "if season_name == 'summer':\n",
    "    index_end = [i for i, value in enumerate(date_str) if value == '08-31']\n",
    "    \n",
    "print(index_end)\n",
    "print(len(index_end))\n",
    "\n",
    "seasons= [x for x in range(int(season1),int(season2)+1)]\n",
    "cl1_count=np.zeros(len(index_end))\n",
    "cl2_count=np.zeros(len(index_end))\n",
    "cl3_count=np.zeros(len(index_end))\n",
    "cl4_count=np.zeros(len(index_end))\n",
    "\n",
    "# Cluster1\n",
    "cl1_count[0]=list(cluster[0:index_end[0]+1]).count(0)\n",
    "for i in range(1,len(index_end)):\n",
    " cl1_count[i]=list(cluster[index_end[i-1]+1:index_end[i]+1]).count(0)\n",
    " \n",
    "# Cluster2\n",
    "cl2_count[0]=list(cluster[0:index_end[0]+1]).count(1)\n",
    "for i in range(1,len(index_end)):\n",
    " cl2_count[i]=list(cluster[index_end[i-1]+1:index_end[i]+1]).count(1)\n",
    "\n",
    "# Cluster3\n",
    "cl3_count[0]=list(cluster[0:index_end[0]+1]).count(2)\n",
    "for i in range(1,len(index_end)):\n",
    " cl3_count[i]=list(cluster[index_end[i-1]+1:index_end[i]+1]).count(2)\n",
    "\n",
    "# Cluster4\n",
    "cl4_count[0]=list(cluster[0:index_end[0]+1]).count(3)\n",
    "for i in range(1,len(index_end)):\n",
    " cl4_count[i]=list(cluster[index_end[i-1]+1:index_end[i]+1]).count(3)\n",
    "\n",
    "print(seasons)\n",
    "print(cl1_count)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Tracé des occurences de régimes par saison et des tendances linéaires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# calculate trends\n",
    "X = np.reshape(seasons, (len(seasons), 1))\n",
    "\n",
    "y = cl1_count\n",
    "model = LinearRegression()\n",
    "model.fit(X, cl1_count)\n",
    "trend_cl1 = model.predict(X)\n",
    "\n",
    "y = cl2_count\n",
    "model = LinearRegression()\n",
    "model.fit(X, cl2_count)\n",
    "trend_cl2 = model.predict(X)\n",
    "\n",
    "y = cl3_count\n",
    "model = LinearRegression()\n",
    "model.fit(X, cl3_count)\n",
    "trend_cl3 = model.predict(X)\n",
    "\n",
    "y = cl4_count\n",
    "model = LinearRegression()\n",
    "model.fit(X, cl4_count)\n",
    "trend_cl4 = model.predict(X)\n",
    "\n",
    "def plot_regimes_occ(ax):\n",
    " plt.xlabel('Year')\n",
    " plt.ylabel('Number of days')\n",
    " plt.xlim(int(season1), int(season2))\n",
    " plt.ylim(0, 85)\n",
    " plt.axvline(1960, color='grey', linestyle='--')\n",
    " plt.axvline(1970, color='grey', linestyle='--')\n",
    " plt.axvline(1980, color='grey', linestyle='--')\n",
    " plt.axvline(1990, color='grey', linestyle='--')\n",
    " plt.axvline(2000, color='grey', linestyle='--')\n",
    " plt.axvline(2010, color='grey', linestyle='--')\n",
    " return ax\n",
    "\n",
    "fig = plt.figure(figsize=(15, 15))\n",
    "fig.suptitle('Weather regime occurrences : '\n",
    "             +var_text+' - '+domain+' - '+season+ ' '+season1+'-'+season2, fontsize=16)\n",
    "ax = fig.add_subplot(2, 2, 1)\n",
    "plt.title(regime[0]+' (mean = '+str(int(cl1_count.mean()))+'d)', fontsize=10, loc='center', color=couleur[0])\n",
    "plot_regimes_occ(ax)\n",
    "colormat=np.where(cl1_count>cl1_count.mean(), 'red','blue')\n",
    "plt.bar(seasons,cl1_count-cl1_count.mean(), bottom=cl1_count.mean(), color=colormat, linewidth=1)\n",
    "plt.plot(seasons,trend_cl1, color='k', linewidth=1)\n",
    "\n",
    "ax = fig.add_subplot(2, 2, 2)\n",
    "plt.title(regime[1]+' (mean = '+str(int(cl2_count.mean()))+'d)', fontsize=10, loc='center', color=couleur[1])\n",
    "plot_regimes_occ(ax)\n",
    "colormat=np.where(cl2_count>cl2_count.mean(), 'red','blue')\n",
    "plt.bar(seasons,cl2_count-cl2_count.mean(), bottom=cl2_count.mean(), color=colormat, linewidth=1)\n",
    "plt.plot(seasons,trend_cl2, color='k', linewidth=1)\n",
    "\n",
    "ax = fig.add_subplot(2, 2, 3)\n",
    "plt.title(regime[2]+' (mean = '+str(int(cl3_count.mean()))+'d)', fontsize=10, loc='center', color=couleur[2])\n",
    "plot_regimes_occ(ax)\n",
    "colormat=np.where(cl3_count>cl3_count.mean(), 'red','blue')\n",
    "plt.bar(seasons,cl3_count-cl3_count.mean(), bottom=cl3_count.mean(), color=colormat, linewidth=1)\n",
    "plt.plot(seasons,trend_cl3, color='k', linewidth=1)\n",
    "\n",
    "ax = fig.add_subplot(2, 2, 4)\n",
    "plt.title(regime[3]+' (mean = '+str(int(cl4_count.mean()))+'d)', fontsize=10, loc='center', color=couleur[3])\n",
    "plot_regimes_occ(ax)\n",
    "colormat=np.where(cl4_count>cl4_count.mean(), 'red','blue')\n",
    "plt.bar(seasons,cl4_count-cl4_count.mean(), bottom=cl4_count.mean(), color=colormat, linewidth=1)\n",
    "plt.plot(seasons,trend_cl4, color='k', linewidth=1)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "figname=dir_figs+varname+'_'+domain_name+'_'+season_name+'_regimes_occurrence'\n",
    "fig.savefig(figname+'.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Tracé des occurences de régimes par saison sous forme de barres verticales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 10))\n",
    "fig.suptitle('Weather regime occurrences : '\n",
    "             +var_text+' - '+domain+' - '+season+ ' '+season1+'-'+season2, fontsize=16)\n",
    "\n",
    "ax = fig.add_subplot(111)\n",
    "plt.bar(seasons, cl1_count, color=couleur[0])\n",
    "plt.bar(seasons, cl2_count, bottom=cl1_count, color=couleur[1])\n",
    "plt.bar(seasons, cl3_count, bottom=cl1_count+cl2_count, color=couleur[2])\n",
    "plt.bar(seasons, cl4_count, bottom=cl1_count+cl2_count+cl3_count, color=couleur[3])\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Weather regime occurrence\")\n",
    "plt.xlim(seasons[0]-1,seasons[-1]+1)\n",
    "plt.legend([regime[0], regime[1], regime[2], regime[3]])\n",
    "\n",
    "plt.show()\n",
    "\n",
    "figname=dir_figs+varname+'_'+domain_name+'_'+season_name+'_regimes_occurrence2'\n",
    "fig.savefig(figname+'.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>Questions : </b>\n",
    "<p><b>1) </b>Quels régimes semblent caractérisés par des tendances linéaires sur la période totale des données ?</p>  \n",
    "<p><b>2) </b>Pour les régimes avec tendance, identifier 2 hivers particuliers qui s’opposent à cette tendance ou au contraire qui accentuent cette tendance.\n",
    "<p><b>3) </b>Pour chaque régime, identifier les hivers avec le maximum/minimum d'occurrence.\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Réponses : </b>\n",
    "<p>\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>Question codage : classement des occurences de régimes </b>\n",
    "<p>Le tableau seasons contient les saisons de l'étude. Le tableau regime fait la correspondance entre le numéro de régime et le nom du régime. Les tableaux cl1_count, cl2_count, cl3_count et cl4_count correspondent aux nombres d'occurences par saison de chaque régime de temps.\n",
    "\n",
    "- Exploiter ces tableaux pour classer, pour chaque régime, les saisons par ordre croissant d'occurence de régime.\n",
    "\n",
    "Indication : les fonctions suivantes pourront s'avérer utiles :\n",
    "- https://numpy.org/doc/stable/reference/generated/numpy.sort.html\n",
    "- https://numpy.org/doc/stable/reference/generated/numpy.argsort.html\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Réponse dans la cellule de code ci-dessous : </b>\n",
    "<p>\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Classement des occurences de régimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etape 8 : corrélation régimes/indices océaniques (Nino 3.4, TNA, AMV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "<b>Etape à faire uniquement pour les régimes d'hiver (code à adapter pour l'été). </b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "NINO34 : indice d’anomalie de température de surface de la mer (SST) sur le Pacifique central (5N-5S, 170W-120W) et qui caractérise l’ENSO (El Nino Southern Oscillation).\n",
    "\n",
    "TNA (Tropical Northern Atlantic) : indice d’anomalie de SST moyennées sur tout l’Atlantique nord tropical (5.5N-23.5N, 15W-57.5W).\n",
    "\n",
    "AMV/AMO (Atlantic Multi-decadal Variability/Oscillation): indice d’anomalie de SST moyennées sur l’ensemble de l’Atlantique Nord (0N-65N, 80W-0E).\n",
    "\n",
    "https://www.esrl.noaa.gov/psd/data/climateindices/list/\n",
    "\n",
    "A partir des séries mensuelles on construit des moyennes JFM et on normalise les séries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#nino=np.loadtxt(dir_data+'nina34.1958-2018.data')\n",
    "nino=np.loadtxt(dir_data+'nino34.anom.1958-2018.data')\n",
    "tna=np.loadtxt(dir_data+'tna.1958-2018.data')\n",
    "amo=np.loadtxt(dir_data+'amon.us.1958-2018.data')\n",
    "\n",
    "dates = pd.date_range(season1, '2019', freq='M')\n",
    "\n",
    "nino=nino[0:,1:]\n",
    "nino=nino.flatten()\n",
    "nino = Series(nino, index=dates)\n",
    "print(nino)\n",
    "nino=nino.rolling(window=3, center=False).mean()\n",
    "nino=nino[nino.index.month == 3]\n",
    "nino=(nino-nino.mean())/nino.std()\n",
    "print(nino)\n",
    "\n",
    "tna=tna[0:,1:]\n",
    "tna=tna.flatten()\n",
    "tna = Series(tna, index=dates)\n",
    "print(tna)\n",
    "tna=tna.rolling(window=3, center=False).mean()\n",
    "tna=tna[tna.index.month == 3]\n",
    "tna=(tna-tna.mean())/tna.std()\n",
    "print(tna)\n",
    "\n",
    "amo=amo[0:,1:]\n",
    "amo=amo.flatten()\n",
    "amo = Series(amo, index=dates)\n",
    "print(amo)\n",
    "amo=amo.rolling(window=3, center=False).mean()\n",
    "amo=amo[amo.index.month == 3]\n",
    "amo=(amo-amo.mean())/amo.std()\n",
    "print(amo)\n",
    "\n",
    "years=np.arange(int(season1),2019)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Fonction de tracé des séries annuelles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_ocean(ax):\n",
    "    plt.title('Data : https://www.esrl.noaa.gov/psd/data/climateindices/list/' , fontsize=12, color='grey')\n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel('SST anomaly (K)')\n",
    "    plt.xlim(int(season1), 2018)\n",
    "    plt.axvline(1960, color='grey', linestyle='--', linewidth=0.5)\n",
    "    plt.axvline(1970, color='grey', linestyle='--', linewidth=0.5)\n",
    "    plt.axvline(1980, color='grey', linestyle='--', linewidth=0.5)\n",
    "    plt.axvline(1990, color='grey', linestyle='--', linewidth=0.5)\n",
    "    plt.axvline(2000, color='grey', linestyle='--', linewidth=0.5)\n",
    "    plt.axvline(2010, color='grey', linestyle='--', linewidth=0.5)\n",
    "\n",
    "    plt.axhline(0, color='k')\n",
    "    plt.axhline(1, color='grey', linestyle='--', linewidth=0.5)\n",
    "    plt.axhline(1.5, color='grey', linestyle='--', linewidth=0.5)\n",
    "    plt.axhline(2, color='grey', linestyle='--', linewidth=0.5)\n",
    "    plt.axhline(-1, color='grey', linestyle='--', linewidth=0.5)\n",
    "    plt.axhline(-1.5, color='grey', linestyle='--', linewidth=0.5)\n",
    "    plt.axhline(-2, color='grey', linestyle='--', linewidth=0.5)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Tracé de la série AMO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(17, 10))\n",
    "fig.suptitle('AMO SST anomaly - JFM mean', fontsize=16)\n",
    "plot_ocean(ax)\n",
    "plt.plot(years, amo, color='black', linewidth=2)\n",
    "plt.fill_between(years, amo, where=amo > 0, facecolor='red', interpolate=True) \n",
    "plt.fill_between(years, amo, where=amo < 0, facecolor='blue', interpolate=True) \n",
    "plt.show()\n",
    "\n",
    "figname=dir_figs+varname+'_'+domain_name+'_'+season_name+'_AMO'\n",
    "fig.savefig(figname+'.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Tracé de la série TNA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(17, 10))\n",
    "fig.suptitle('TNA SST anomaly - JFM mean', fontsize=16)\n",
    "plot_ocean(ax)\n",
    "plt.plot(years, tna, color='black', linewidth=2)\n",
    "plt.fill_between(years, tna, where=tna > 0, facecolor='red', interpolate=True) \n",
    "plt.fill_between(years, tna, where=tna < 0, facecolor='blue', interpolate=True) \n",
    "\n",
    "plt.show()\n",
    "\n",
    "figname=dir_figs+varname+'_'+domain_name+'_'+season_name+'_TNA'\n",
    "fig.savefig(figname+'.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Tracé de la série Nino 3.4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(17, 10))\n",
    "fig.suptitle('Nino 3.4 SST anomaly - JFM mean', fontsize=16)\n",
    "plot_ocean(ax)\n",
    "plt.plot(years, nino, color='black', linewidth=2)\n",
    "plt.fill_between(years, nino, where=nino > 0, facecolor='red', interpolate=True) \n",
    "plt.fill_between(years, nino, where=nino < 0, facecolor='blue', interpolate=True)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "figname=dir_figs+varname+'_'+domain_name+'_'+season_name+'_Nino'\n",
    "fig.savefig(figname+'.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Tracé des séries AMO, TNA, Nino 3.4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(17, 10))\n",
    "fig.suptitle('Oceanic indices - Annual mean', fontsize=16)\n",
    "plt.title('Data : https://www.esrl.noaa.gov/psd/data/climateindices/list/' , fontsize=12, color='grey')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Oceanic index')\n",
    "ax = nino.plot(color='red', linewidth=2, label='Niño 3.4 SST anomaly - JFM mean')\n",
    "ax = tna.plot(color='blue', linewidth=2, label='TNA SST anomaly - JFM mean')\n",
    "ax = amo.plot(color='green', linewidth=2, label='AMO SST anomaly - JFM mean')\n",
    "\n",
    "plt.axhline(0, color='k')\n",
    "plt.axhline(1, color='grey', linestyle='--', linewidth=0.5)\n",
    "plt.axhline(1.5, color='grey', linestyle='--', linewidth=0.5)\n",
    "plt.axhline(2, color='grey', linestyle='--', linewidth=0.5)\n",
    "plt.axhline(-1, color='grey', linestyle='--', linewidth=0.5)\n",
    "plt.axhline(-1.5, color='grey', linestyle='--', linewidth=0.5)\n",
    "plt.axhline(-2, color='grey', linestyle='--', linewidth=0.5)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "figname=dir_figs+varname+'_'+domain_name+'_'+season_name+'_cor_regimes_ocean'\n",
    "fig.savefig(figname+'.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Calcul des anomalies d'occurences de régimes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cl1_count_a=((cl1_count-cl1_count.mean())/cl1_count.mean())*100\n",
    "cl2_count_a=((cl2_count-cl2_count.mean())/cl2_count.mean())*100\n",
    "cl3_count_a=((cl3_count-cl3_count.mean())/cl3_count.mean())*100\n",
    "cl4_count_a=((cl4_count-cl4_count.mean())/cl4_count.mean())*100\n",
    "\n",
    "print(nino.shape)\n",
    "print(cl1_count_a.shape) # 2 dernières années en +\n",
    "print(cl1_count_a[0:-2].shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Calcul des corrélations entre les anomalies d'occurences de régimes et les indices océaniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cor_nino1=np.corrcoef(nino, cl1_count_a[0:-2])\n",
    "cor_nino2=np.corrcoef(nino, cl2_count_a[0:-2])\n",
    "cor_nino3=np.corrcoef(nino, cl3_count_a[0:-2])\n",
    "cor_nino4=np.corrcoef(nino, cl4_count_a[0:-2])\n",
    "\n",
    "print(\"NINO34 correlation\")\n",
    "print(regime[0]+\" : \", cor_nino1[1,0])\n",
    "print(regime[1]+\" : \", cor_nino2[1,0])\n",
    "print(regime[2]+\" : \", cor_nino3[1,0])\n",
    "print(regime[3]+\" : \", cor_nino4[1,0])\n",
    "\n",
    "cor_tna1=np.corrcoef(tna, cl1_count_a[0:-2])\n",
    "cor_tna2=np.corrcoef(tna, cl2_count_a[0:-2])\n",
    "cor_tna3=np.corrcoef(tna, cl3_count_a[0:-2])\n",
    "cor_tna4=np.corrcoef(tna, cl4_count_a[0:-2])\n",
    "print(\"TNA correlation\")\n",
    "print(regime[0]+\" : \", cor_tna1[1,0])\n",
    "print(regime[1]+\" : \", cor_tna2[1,0])\n",
    "print(regime[2]+\" : \", cor_tna3[1,0])\n",
    "print(regime[3]+\" : \", cor_tna4[1,0])\n",
    "\n",
    "cor_amo1=np.corrcoef(amo, cl1_count_a[0:-2])\n",
    "cor_amo2=np.corrcoef(amo, cl2_count_a[0:-2])\n",
    "cor_amo3=np.corrcoef(amo, cl3_count_a[0:-2])\n",
    "cor_amo4=np.corrcoef(amo, cl4_count_a[0:-2])\n",
    "print(\"AMO correlation\")\n",
    "print(regime[0]+\" : \", cor_amo1[1,0])\n",
    "print(regime[1]+\" : \", cor_amo2[1,0])\n",
    "print(regime[2]+\" : \", cor_amo3[1,0])\n",
    "print(regime[3]+\" : \", cor_amo4[1,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>Question : </b>\n",
    "<p><b>1) </b>Quelles sont les corrélations les plus fortes entre régimes de temps et indices océaniques en hiver ?</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Réponse : </b>\n",
    "<p>\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etape 8 : retour sur une saison particulière"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Choix de la saison (Attention, pour un hiver N-N+1, entrer N)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if season_name == 'winter':\n",
    "    choix=input('hiver (pour un hiver N-N+1, entrer N) : ')\n",
    "    leap_year=calendar.isleap(int(choix)+1)\n",
    "    if var_text=='Z500':\n",
    "        date1=choix+'-12-01T18'\n",
    "    if var_text=='MSLP':\n",
    "        date1=choix+'-12-01T09'\n",
    "    idx_date1=dates2.get_loc(date1, method ='ffill')\n",
    "    if leap_year:\n",
    "        print('Année bisextile')\n",
    "        idx_date2=idx_date1+122\n",
    "    else:\n",
    "        idx_date2=idx_date1+121\n",
    "    \n",
    "if season_name == 'summer':\n",
    "    choix=input('été ? ')\n",
    "    if var_text=='Z500':\n",
    "        date1=choix+'-06-01T18'\n",
    "    if var_text=='MSLP':\n",
    "        date1=choix+'-06-01T09'\n",
    "    idx_date1=dates2.get_loc(date1, method ='ffill')\n",
    "    idx_date2=idx_date1+121"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Gestion des dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "time=dates2[idx_date1:idx_date2]\n",
    "print(time.shape)\n",
    "\n",
    "date1=str(time[0])[0:10]\n",
    "date2=str(time[-1])[0:10]\n",
    "\n",
    "time_str = [x for x in range(len(time))]\n",
    "date_str = [x for x in range(len(time))]\n",
    "date_str_title = [x for x in range(len(time))]\n",
    "\n",
    "for i in range(len(time)):\n",
    "    time_str[i] = str(time[i])\n",
    "    date_str_title[i] = time_str[i][0:10]\t\n",
    "    date_str[i] = time_str[i][5:10]\n",
    "    \n",
    "leap_year=calendar.isleap(int(time_str[-1][0:4]))\n",
    "if leap_year:\n",
    "    print('Année bisextile')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Selection des données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_month    = data_season.sel(time=slice(date1,date2))\n",
    "z=data_month[varname]/var_div\n",
    "\n",
    "data_month_anom    = data_anom.sel(time=slice(date1,date2))\n",
    "z_anom=data_month_anom[varname]/var_div\n",
    "\n",
    "lat  = data_month_anom.lat.values\n",
    "lon  = data_month_anom.lon.values"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Titres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if varname=='z':\n",
    "    plt_title2 = 'Geopotential height anomaly ('+units+') at 500 hPa : '+ str(date1)+'-'+str(date2)\n",
    "\n",
    "if varname=='msl':\n",
    "    plt_title2 = 'Mean Sea Level Pressure anomaly ('+units+') : '+ str(date1)+'-'+str(date2)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Vignettes d'anomalies quotidiennes avec attribution du cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "axes_class = (GeoAxes, dict(map_projection=projection))\n",
    "fig = plt.figure(figsize=(17,10))\n",
    "fig.suptitle(plt_title2, fontsize=16)\n",
    "\n",
    "axgr = AxesGrid(fig, 111, axes_class=axes_class,\n",
    "       nrows_ncols=(5, 6),\n",
    "       axes_pad=0.6,\n",
    "       cbar_location='right',\n",
    "       cbar_mode='single', # None/single/each\n",
    "       cbar_pad=0.2,\n",
    "       cbar_size='3%',\n",
    "       label_mode='')  # note the empty label_mode\n",
    "                   \n",
    "for i, ax in enumerate(axgr):\n",
    "    reg=cluster[idx_date1+i] # régime\n",
    "    ax.coastlines()\n",
    "    ax.set_extent([lonW, lonE, latS, latN], crs=ccrs.PlateCarree())\n",
    "    boundary_path = make_boundary_path(lon, lat)\n",
    "    ax.set_boundary(boundary_path, transform=ccrs.PlateCarree())\n",
    "    ax.gridlines(crs=ccrs.PlateCarree(), linewidth=0.5, color='gray', alpha=0.5, linestyle='-')\n",
    "    ax.set_title(date_str_title[i]+' '+regime[reg], fontsize=10, color=colors[idx_date1+i])\n",
    "    p1 = ax.contourf(lon, lat, z_anom[i,:,:], levels2, transform=ccrs.PlateCarree(), cmap=cmap2, extend='both')\n",
    "    p2 = ax.contour(lon, lat, z_anom[i,:,:], levels2, colors='black', linewidths=0.2, transform=ccrs.PlateCarree())\n",
    "    axgr.cbar_axes[i].colorbar(p1)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "figname=dir_figs+varname+'_anom_'+domain_name+'_'+season_name+'_cluster_'+str(date1)+'-'+str(date2)+'_1'\n",
    "fig.savefig(figname+'.png', bbox_inches='tight')\n",
    "\n",
    "#\n",
    "axes_class = (GeoAxes, dict(map_projection=projection))\n",
    "fig = plt.figure(figsize=(17,10))\n",
    "fig.suptitle(plt_title2, fontsize=16)\n",
    "\n",
    "axgr = AxesGrid(fig, 111, axes_class=axes_class,\n",
    "       nrows_ncols=(5, 6),\n",
    "       axes_pad=0.6,\n",
    "       cbar_location='right',\n",
    "       cbar_mode='single', # None/single/each\n",
    "       cbar_pad=0.2,\n",
    "       cbar_size='3%',\n",
    "       label_mode='')  # note the empty label_mode\n",
    "\n",
    "for i, ax in enumerate(axgr):\n",
    "    reg=cluster[idx_date1+30+i] # régime\n",
    "    ax.coastlines()\n",
    "    ax.set_extent([lonW, lonE, latS, latN], crs=ccrs.PlateCarree())\n",
    "    boundary_path = make_boundary_path(lon, lat)\n",
    "    ax.set_boundary(boundary_path, transform=ccrs.PlateCarree())\n",
    "    ax.gridlines(crs=ccrs.PlateCarree(), linewidth=0.5, color='gray', alpha=0.5, linestyle='-')\n",
    "    ax.set_title(date_str_title[i+30]+' '+regime[reg], fontsize=10, color=colors[idx_date1+i+30])\n",
    "    p1 = ax.contourf(lon, lat, z_anom[i+30,:,:], levels2, transform=ccrs.PlateCarree(), cmap=cmap2, extend='both')\n",
    "    p2 = ax.contour(lon, lat, z_anom[i+30,:,:], levels2, colors='black', linewidths=0.2, transform=ccrs.PlateCarree())\n",
    "    axgr.cbar_axes[i].colorbar(p1)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "figname=dir_figs+varname+'_anom_'+domain_name+'_'+season_name+'_cluster_'+str(date1)+'-'+str(date2)+'_2'\n",
    "fig.savefig(figname+'.png', bbox_inches='tight')\n",
    "\n",
    "#\n",
    "axes_class = (GeoAxes, dict(map_projection=projection))\n",
    "fig = plt.figure(figsize=(17,10))\n",
    "fig.suptitle(plt_title2, fontsize=16)\n",
    "\n",
    "axgr = AxesGrid(fig, 111, axes_class=axes_class,\n",
    "       nrows_ncols=(5, 6),\n",
    "       axes_pad=0.6,\n",
    "       cbar_location='right',\n",
    "       cbar_mode='single', # None/single/each\n",
    "       cbar_pad=0.2,\n",
    "       cbar_size='3%',\n",
    "       label_mode='')  # note the empty label_mode\n",
    "\n",
    "for i, ax in enumerate(axgr):\n",
    "    reg=cluster[idx_date1+60+i] # régime\n",
    "    ax.coastlines()\n",
    "    ax.set_extent([lonW, lonE, latS, latN], crs=ccrs.PlateCarree())\n",
    "    boundary_path = make_boundary_path(lon, lat)\n",
    "    ax.set_boundary(boundary_path, transform=ccrs.PlateCarree())\n",
    "    ax.gridlines(crs=ccrs.PlateCarree(), linewidth=0.5, color='gray', alpha=0.5, linestyle='-')\n",
    "    ax.set_title(date_str_title[i+60]+' '+regime[reg], fontsize=10, color=colors[idx_date1+i+60])\n",
    "    p1 = ax.contourf(lon, lat, z_anom[i+60,:,:], levels2, transform=ccrs.PlateCarree(), cmap=cmap2, extend='both')\n",
    "    p2 = ax.contour(lon, lat, z_anom[i+60,:,:], levels2, colors='black', linewidths=0.2, transform=ccrs.PlateCarree())\n",
    "    axgr.cbar_axes[i].colorbar(p1)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "figname=dir_figs+varname+'_anom_'+domain_name+'_'+season_name+'_cluster_'+str(date1)+'-'+str(date2)+'_3'\n",
    "fig.savefig(figname+'.png', bbox_inches='tight')\n",
    "\n",
    "#\n",
    "axes_class = (GeoAxes, dict(map_projection=projection))\n",
    "fig = plt.figure(figsize=(17,10))\n",
    "fig.suptitle(plt_title2, fontsize=16)\n",
    "\n",
    "axgr = AxesGrid(fig, 111, axes_class=axes_class,\n",
    "       nrows_ncols=(5, 6),\n",
    "       axes_pad=0.6,\n",
    "       cbar_location='right',\n",
    "       cbar_mode='single', # None/single/each\n",
    "       cbar_pad=0.2,\n",
    "       cbar_size='3%',\n",
    "       label_mode='')  # note the empty label_mode\n",
    "\n",
    "for i, ax in enumerate(axgr):\n",
    "    reg=cluster[idx_date1+90+i] # régime\n",
    "    ax.coastlines()\n",
    "    ax.set_extent([lonW, lonE, latS, latN], crs=ccrs.PlateCarree())\n",
    "    boundary_path = make_boundary_path(lon, lat)\n",
    "    ax.set_boundary(boundary_path, transform=ccrs.PlateCarree())\n",
    "    ax.gridlines(crs=ccrs.PlateCarree(), linewidth=0.5, color='gray', alpha=0.5, linestyle='-')\n",
    "    ax.set_title(date_str_title[i+90]+' '+regime[reg], fontsize=10, color=colors[idx_date1+i+90])\n",
    "    p1 = ax.contourf(lon, lat, z_anom[i+90,:,:], levels2, transform=ccrs.PlateCarree(), cmap=cmap2, extend='both')\n",
    "    p2 = ax.contour(lon, lat, z_anom[i+90,:,:], levels2, colors='black', linewidths=0.2, transform=ccrs.PlateCarree())\n",
    "    axgr.cbar_axes[i].colorbar(p1)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "figname=dir_figs+varname+'_anom_'+domain_name+'_'+season_name+'_cluster_'+str(date1)+'-'+str(date2)+'_4'\n",
    "fig.savefig(figname+'.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Bilan des régimes de temps de la saison sous forme de frise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Nombre de jours par régime sur la saison choisie.\n",
    "nc1s=list(cluster[idx_date1:idx_date2]).count(0)\n",
    "nc2s=list(cluster[idx_date1:idx_date2]).count(1)\n",
    "nc3s=list(cluster[idx_date1:idx_date2]).count(2)\n",
    "nc4s=list(cluster[idx_date1:idx_date2]).count(3)\n",
    "\n",
    "# Fonction pour la légende.\n",
    "def plot_regimes_leg(ax):\n",
    "    patch1 = mpatches.Patch(color=couleur[0], label=regime[0]+' : '+str(nc1s)+' ('+str(f1s)+'%)')\n",
    "    patch2 = mpatches.Patch(color=couleur[1], label=regime[1]+' : '+str(nc2s)+' ('+str(f2s)+'%)')\n",
    "    patch3 = mpatches.Patch(color=couleur[2], label=regime[2]+' : '+str(nc3s)+' ('+str(f3s)+'%)')\n",
    "    patch4 = mpatches.Patch(color=couleur[3], label=regime[3]+' : '+str(nc4s)+' ('+str(f4s)+'%)')\n",
    "    all_handles = (patch1, patch2, patch3, patch4)\n",
    "    leg = ax.legend(handles=all_handles, loc='lower right')\n",
    "    return ax\n",
    "\n",
    "f1s=round(nc1s/cluster[idx_date1:idx_date2].shape[0]*100,2)\n",
    "f2s=round(nc2s/cluster[idx_date1:idx_date2].shape[0]*100,2)\n",
    "f3s=round(nc3s/cluster[idx_date1:idx_date2].shape[0]*100,2)\n",
    "f4s=round(nc4s/cluster[idx_date1:idx_date2].shape[0]*100,2)\n",
    "\n",
    "fig = plt.figure(figsize=(15, 2))\n",
    "fig.suptitle('Weather regimes : '+date_str_title[0]+' to '+date_str_title[-1], fontsize=14)\n",
    "\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "# create a collection with a rectangle for each day\n",
    "col = PatchCollection([Rectangle((y, 0), 1, 1) for y in range(len(time))])\n",
    "\n",
    "#data = cluster[idx_date1:idx_date2]\n",
    "#col.set_array(data)\n",
    "col.set_color(colors[idx_date1:idx_date2])\n",
    "ax.add_collection(col)\n",
    "\n",
    "if season_name == 'winter':\n",
    "    labels = (\"Dec\", \"Jan\", \"Feb\", \"Mar\", \"Avr\")\n",
    "    positions = (0, 31, 31+31, 31+31+28, 31+31+28+31)\n",
    "    if leap_year:\n",
    "        positions = (0, 31, 31+31, 31+31+29, 31+31+29+31)\n",
    "\n",
    "if season_name == 'summer':\n",
    "    positions = (0, 30, 30+31, 30+31+31, 30+31+31+30)\n",
    "    labels = (\"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\")\n",
    "\n",
    "plt.xticks(positions, labels)\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_xlim(0, len(time))\n",
    "ax.yaxis.set_major_formatter(plt.NullFormatter())\n",
    "plt.axvline(x=positions[0], c='black')\n",
    "plt.axvline(x=positions[1], c='black')\n",
    "plt.axvline(x=positions[2], c='black')\n",
    "plt.axvline(x=positions[3], c='black')\n",
    "\n",
    "plot_regimes_leg(ax)\n",
    "\n",
    "fig.savefig(dir_figs+varname+'_'+domain_name+'_'+season_name+\n",
    "            '_regimes-stripes_'+date_str_title[0]+'-'+date_str_title[-1]+'.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>Questions : </b>\n",
    "<p><b>1) </b>Quel a été le régime de temps dominant au cours de l'hiver 2019-2020 ? Principalement au cours de quels mois ?</p>\n",
    "<br>\n",
    "<b>Relancer l'étape 8 pour l'hiver 2011-2012 : </b>\n",
    "<p><b>2) </b>Quel régime de temps a été absent au cours de l'hiver 2011-2012 ?</p>\n",
    "<p><b>3) </b>Quel régime de temps a dominé en début de mois de février 2012 ? Quelle en a été la conséquence sur le temps sensible en France ?</p>\n",
    "<br>\n",
    "<b>Relancer l'étape 8 pour l'hiver 2009-2010 : </b>\n",
    "<p><b>4) </b>Quel a été le régime de temps dominant au cours de l'hiver 2009-2010 ?  Au cours de quel mois les occurrences de ce régime ont-elles été les plus nombreuses ?</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Réponses : </b>\n",
    "<p>\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autres visualisations"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Cartes individuelles des anomalies avec attribution du cluster avec composite du régime en vis-à-vis (fichiers png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(time)):\n",
    "    #print(date_str_title[i])\n",
    "    reg=cluster[idx_date1+i]\n",
    "    if reg==0:\n",
    "            composite  = mean_c1_anom\n",
    "            composite_mean = mean_c1\n",
    "    if reg==1:\n",
    "            composite  = mean_c2_anom\n",
    "            composite_mean = mean_c2\n",
    "    if reg==2:\n",
    "            composite  = mean_c3_anom\n",
    "            composite_mean = mean_c3\n",
    "    if reg==3:\n",
    "            composite  = mean_c4_anom\n",
    "            composite_mean = mean_c4\n",
    "            \n",
    "    fig = plt.figure(figsize=(15., 5.))\n",
    "    fig.suptitle(plt_title2, fontsize=16)\n",
    "    \n",
    "    ax = fig.add_subplot(1,2,1, projection=projection)\n",
    "    ax.set_title(date_str_title[i]+' '+regime[reg], fontsize=10, color=colors[idx_date1+i])\n",
    "    ax.coastlines()\n",
    "    ax.set_extent([lonW, lonE, latS, latN], crs=ccrs.PlateCarree())\n",
    "    boundary_path = make_boundary_path(lon, lat)\n",
    "    ax.set_boundary(boundary_path, transform=ccrs.PlateCarree())\n",
    "    ax.gridlines(crs=ccrs.PlateCarree(), linewidth=0.5, color='gray', alpha=0.5, linestyle='-')\n",
    "    p1 = ax.contourf(lon, lat, z_anom[i,:,:], levels2, transform=ccrs.PlateCarree(), cmap=cmap2, extend='both')\n",
    "    p2 = ax.contour(lon, lat, z_anom[i,:,:], levels2, colors='black', linewidths=0.2, transform=ccrs.PlateCarree())\n",
    "    p3 = ax.contour(lon, lat, z[i,:,:], levels1, colors='black', linewidths=1, transform=ccrs.PlateCarree())\n",
    "    ax.clabel(p3, inline=1, fmt='%4.0f', fontsize=10)\n",
    "    cb = fig.colorbar(p1, orientation='horizontal', aspect=65, shrink=0.5, pad=0.05, extendrect='True')\n",
    "    cb.set_label('Anomaly ('+units+')', fontsize=12)\n",
    "    \n",
    "    ax = fig.add_subplot(1,2,2, projection=projection)\n",
    "    plt.title(regime[reg]+' composite', fontsize=10, loc='center', color=colors[idx_date1+i])\n",
    "    ax.coastlines()\n",
    "    ax.set_extent([lonW, lonE, latS, latN], crs=ccrs.PlateCarree())\n",
    "    boundary_path = make_boundary_path(lon, lat)\n",
    "    ax.set_boundary(boundary_path, transform=ccrs.PlateCarree())\n",
    "    ax.gridlines(crs=ccrs.PlateCarree(), linewidth=0.5, color='gray', alpha=0.5, linestyle='-')\n",
    "    cf = ax.contourf(lons, lats, composite, levels=clevs_anom, \n",
    "                     cmap=cmap2, extend='both', transform=ccrs.PlateCarree())\n",
    "    c0 = ax.contour(lons, lats, composite, levels=clevs_anom, colors='black', linewidths=0.2,\n",
    "                    transform=ccrs.PlateCarree())\n",
    "    c = ax.contour(lons, lats, composite_mean, levels=clevs, colors='black', linewidths=1,\n",
    "                   transform=ccrs.PlateCarree())\n",
    "    ax.clabel(c, inline=1, fmt='%4.0f', fontsize=10)\n",
    "    cb = fig.colorbar(cf, orientation='horizontal', aspect=65, shrink=0.5, pad=0.05, extendrect='True')\n",
    "    cb.set_label('Anomaly ('+units+')', fontsize=12)\n",
    "\n",
    "    figname=dir_anim+varname+'_anom_cluster'+domain_name+'_'+season_name+'_'+date_str_title[i]\n",
    "    fig.savefig(figname+'.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "print('png files are in the animation folder, ready to make the animation')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Animation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gif_filepath = dir_anim+varname+'_anom_cluster_'+domain_name+'_'+season_name+'_'+str(date1)+'-'+str(date2)+'.gif'\n",
    "make_animation()\n",
    "IPdisplay.Image(url=gif_filepath)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Visualisation de la saison considérée dans l'espace des phases défini par PC1 et PC2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 10))\n",
    "fig.suptitle('PC1 and PC2 phase space : '+date_str_title[0]+' to '+date_str_title[-1], fontsize=14)\n",
    "\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "plot_phase_space2d(ax)\n",
    "ax.scatter(pcs[idx_date1:idx_date2,0], pcs[idx_date1:idx_date2,1], c=colors[idx_date1:idx_date2], s=10)\n",
    "ax.scatter(centroids[:, 0], centroids[:, 1], c=couleur, s=2000, alpha=1, marker='+')\n",
    "\n",
    "for i,type in enumerate(date_str):\n",
    "    x = pc1[idx_date1+i]\n",
    "    y = pc2[idx_date1+i]\n",
    "    plt.text(x, y, type, fontsize=6)\n",
    "\n",
    "plot_regimes_leg(ax)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "figname=dir_figs+varname+'_'+domain_name+'_'+season_name+'_pc12_'+date_str_title[0]+'-'+date_str_title[-1]\n",
    "fig.savefig(figname+'.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Visualisation de la saison considérée dans l'espace des phases défini par PC1 PC2 et PC3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 10))\n",
    "fig.suptitle('PC phase space : '+date_str_title[0]+' to '+date_str_title[-1], fontsize=14)\n",
    "\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "plot_phase_space3d(ax)\n",
    "ax.scatter(pcs[idx_date1:idx_date2,0], pcs[idx_date1:idx_date2,1], pcs[idx_date1:idx_date2,2],\n",
    "           c=colors[idx_date1:idx_date2], s=10)\n",
    "ax.scatter(centroids[:, 0], centroids[:, 1], centroids[:, 2], c=couleur, s=200, alpha=1, marker='+')\n",
    "\n",
    "plot_regimes_leg(ax)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "figname=dir_figs+varname+'_'+domain_name+'_'+season_name+'_pc123_'+date_str_title[0]+'-'+date_str_title[-1]\n",
    "fig.savefig(figname+'.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Création des vignettes de la saison considérée dans l'espace des phases défini par PC1 et PC2 (fichiers png)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# loop for each day\t\n",
    "for i in range(len(time)):\n",
    " #print(date_str[i])\n",
    " fig = plt.figure(figsize=(10, 10))\n",
    " fig.suptitle('PC1 and PC2 phase space : '+date_str_title[0]+' to '+date_str_title[-1], fontsize=14)\n",
    " ax = fig.add_subplot(1, 1, 1)\n",
    " plot_phase_space2d(ax)\n",
    " ax.scatter(pcs[idx_date1:idx_date1+i+1,0], pcs[idx_date1:idx_date1+i+1,1], \n",
    "            c=colors[idx_date1:idx_date1+i+1], s=10)\n",
    " ax.scatter(centroids[:, 0], centroids[:, 1], c=couleur, s=2000, alpha=1, marker='+')\n",
    " x = pc1[idx_date1+i]\n",
    " y = pc2[idx_date1+i]\n",
    " plt.text(x, y, date_str[i], fontsize=10)\n",
    " plot_regimes_leg(ax)\n",
    " figname=dir_anim+varname+'_'+domain_name+'_'+season_name+'_PC_2d_phase_space_4clusters_'+date_str_title[i]\n",
    " fig.savefig(figname+'.png')\n",
    " plt.close()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Animation de la saison considérée dans l'espace des phases défini par PC1 et PC2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gif_filepath = dir_anim+varname+'_'+domain_name+'_'+season_name+'_PC_2d_phase_space_4clusters_'+date_str_title[0]+'-'+date_str_title[-1]+'.gif'\n",
    "make_animation()\n",
    "IPdisplay.Image(url=gif_filepath)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Distances aux centroides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import scipy.spatial.distance as sdist\n",
    "dist=sdist.cdist(pcs, centroids)\n",
    "dist_c1=dist[:,0]\n",
    "dist_c2=dist[:,1]\n",
    "dist_c3=dist[:,2]\n",
    "dist_c4=dist[:,3]\n",
    "\n",
    "def plot_dist(ax):\n",
    "    #plt.ylim(0, 5)\n",
    "    plt.axhline(0, color='k')\n",
    "    plt.xlim(xmin=datetime.datetime(int(str(time[0])[0:4]), int(str(time[0])[5:7]),\n",
    "                                    int(str(time[0])[8:10])),\n",
    "             xmax=datetime.datetime(int(str(time[-1])[0:4]), int(str(time[-1])[5:7]),\n",
    "                                    int(str(time[-1])[8:10])))\n",
    "    #ax.spines['right'].set_visible(False)\n",
    "    #ax.spines['top'].set_visible(False)\n",
    "    #ax.spines['bottom'].set_visible(False)\n",
    "    #ax.spines['left'].set_visible(False)\n",
    "    #ax.axes.get_yaxis().set_visible(False)\n",
    "    return ax\n",
    "\n",
    "d1=dist_c1[idx_date1:idx_date2] # distance au régime 1\n",
    "d2=dist_c2[idx_date1:idx_date2] # distance au régime 2\n",
    "d3=dist_c3[idx_date1:idx_date2] # distance au régime 3\n",
    "d4=dist_c4[idx_date1:idx_date2] # distance au régime 4\n",
    "\n",
    "fig=plt.figure(figsize=(20, 7))\n",
    "fig.suptitle('Regime distance from centroid', fontsize=16)\n",
    "\n",
    "ax = fig.add_subplot(4, 1, 1)\n",
    "plot_dist(ax)\n",
    "plt.scatter(time, d1, color='blue', s=200000/d1, label='Distance '+regime[0])\n",
    "plt.legend()\n",
    "\n",
    "ax = fig.add_subplot(4, 1, 2)\n",
    "plot_dist(ax)\n",
    "plt.scatter(time, d2, color='red', s=200000/d2, label='Distance '+regime[1])\n",
    "plt.legend()\n",
    "\n",
    "ax = fig.add_subplot(4, 1, 3)\n",
    "plot_dist(ax)\n",
    "plt.scatter(time, d3, color='green', s=200000/d3, label='Distance '+regime[2])\n",
    "plt.legend()\n",
    "\n",
    "ax = fig.add_subplot(4, 1, 4)\n",
    "plot_dist(ax)\n",
    "plt.scatter(time, d4, color='orange', s=200000/d4, label='Distance '+regime[3])\n",
    "plt.axhline(0, color='k')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "fig.savefig(dir_figs+varname+'_'+domain_name+'_'+season_name+\n",
    "            '_regimes-distances_'+date_str_title[0]+'-'+date_str_title[-1]+'.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus : les frises des régimes de tous les hivers de la base de données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "<b>Etape à faire uniquement pour les régimes d'hiver (code à adapter pour l'été). </b>\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "A comparer avec le produit de Simon Lee :\n",
    "    \n",
    "https://simonleewx.files.wordpress.com/2022/10/atlantic_regimes_timeseries_by_winter_1980-2022.png\n",
    "</div>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Boucle multi-frises hivers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "w=np.arange(1957,2020,1)\n",
    "winters = [str(a) for a in w]\n",
    "\n",
    "for winter in winters:\n",
    "    leap_year=calendar.isleap(int(winter)+1)\n",
    "    if var_text=='Z500':\n",
    "        date1=winter+'-12-01T18'\n",
    "    if var_text=='MSLP':\n",
    "        date1=winter+'-12-01T09'\n",
    "    idx_date1=dates2.get_loc(date1, method ='ffill')\n",
    "    if leap_year:\n",
    "        idx_date2=idx_date1+122\n",
    "    else:\n",
    "        idx_date2=idx_date1+121\n",
    "    \n",
    "    time=dates2[idx_date1:idx_date2]\n",
    "\n",
    "    date1=str(time[0])[0:10]\n",
    "    date2=str(time[-1])[0:10]\n",
    "\n",
    "    time_str = [x for x in range(len(time))]\n",
    "    date_str = [x for x in range(len(time))]\n",
    "    date_str_title = [x for x in range(len(time))]\n",
    "\n",
    "    for i in range(len(time)):\n",
    "        time_str[i] = str(time[i])\n",
    "        date_str_title[i] = time_str[i][0:10]\t\n",
    "        date_str[i] = time_str[i][5:10]\n",
    "\n",
    "    leap_year=calendar.isleap(int(time_str[-1][0:4]))\n",
    "\n",
    "    data_month    = data_season.sel(time=slice(date1,date2))\n",
    "    z=data_month[varname]/var_div\n",
    "\n",
    "    data_month_anom    = data_anom.sel(time=slice(date1,date2))\n",
    "    z_anom=data_month_anom[varname]/var_div\n",
    "\n",
    "    lat  = data_month_anom.lat.values\n",
    "    lon  = data_month_anom.lon.values\n",
    "\n",
    "    if varname=='z':\n",
    "        plt_title2 = 'Geopotential height anomaly ('+units+') at 500 hPa : '+ str(date1)+'-'+str(date2)\n",
    "\n",
    "    if varname=='msl':\n",
    "        plt_title2 = 'Mean Sea Level Pressure anomaly ('+units+') : '+ str(date1)+'-'+str(date2)\n",
    "\n",
    "    nc1s=list(cluster[idx_date1:idx_date2]).count(0)\n",
    "    nc2s=list(cluster[idx_date1:idx_date2]).count(1)\n",
    "    nc3s=list(cluster[idx_date1:idx_date2]).count(2)\n",
    "    nc4s=list(cluster[idx_date1:idx_date2]).count(3)\n",
    "\n",
    "    f1s=round(nc1s/cluster[idx_date1:idx_date2].shape[0]*100,2)\n",
    "    f2s=round(nc2s/cluster[idx_date1:idx_date2].shape[0]*100,2)\n",
    "    f3s=round(nc3s/cluster[idx_date1:idx_date2].shape[0]*100,2)\n",
    "    f4s=round(nc4s/cluster[idx_date1:idx_date2].shape[0]*100,2)\n",
    "\n",
    "    fig = plt.figure(figsize=(15, 2))\n",
    "    fig.suptitle('Weather regimes : '+date_str_title[0]+' to '+date_str_title[-1], fontsize=14)\n",
    "\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "    # create a collection with a rectangle for each day\n",
    "    col = PatchCollection([Rectangle((y, 0), 1, 1) for y in range(len(time))])\n",
    "\n",
    "    #data = cluster[idx_date1:idx_date2]\n",
    "    #col.set_array(data)\n",
    "    col.set_color(colors[idx_date1:idx_date2])\n",
    "    ax.add_collection(col)\n",
    "    \n",
    "    if season_name == 'winter':\n",
    "        labels = (\"Dec\", \"Jan\", \"Feb\", \"Mar\", \"Avr\")\n",
    "        positions = (0, 31, 31+31, 31+31+28, 31+31+28+31)\n",
    "        if leap_year:\n",
    "            positions = (0, 31, 31+31, 31+31+29, 31+31+29+31)\n",
    "\n",
    "    if season_name == 'summer':\n",
    "        positions = (0, 30, 30+31, 30+31+31, 30+31+31+30)\n",
    "        labels = (\"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\")\n",
    "\n",
    "    plt.xticks(positions, labels)\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.set_xlim(0, len(time))\n",
    "    ax.yaxis.set_major_formatter(plt.NullFormatter())\n",
    "    plt.axvline(x=positions[0], c='black')\n",
    "    plt.axvline(x=positions[1], c='black')\n",
    "    plt.axvline(x=positions[2], c='black')\n",
    "    plt.axvline(x=positions[3], c='black')\n",
    "    plt.axvline(x=positions[4], c='black')\n",
    "    \n",
    "    plot_regimes_leg(ax)\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "    fig.savefig(dir_figs+varname+'_'+domain_name+'_'+season_name+\n",
    "                '_regimes-stripes_'+date_str_title[0]+'-'+date_str_title[-1]+'.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>Tâches supplémentaires : </b>\n",
    "<p><b>1) </b>Consulter les produits de suivi des régimes de temps de l'équipe prévisions saisonnières de Météo-France : \n",
    "\n",
    "http://seasonal.meteo.fr/content/suivi-clim-regimes-quot\n",
    "    \n",
    "http://seasonal.meteo.fr/content/suivi-clim-regimes-trim\n",
    "\n",
    "</p>\n",
    "<p><b>2) </b>Consulter les prévisions à long terme (J+46) des régimes de temps Atlantique réalisées par le centre Européen de prévisions météorologiques ECMWF :\n",
    "    \n",
    "https://charts.ecmwf.int/products/extended-regime-probabilities\n",
    "</p>\n",
    "<p><b>3) </b> Refaire le calepin afin d’extraire les régimes de Pmer sur l’Atlantique Nord pour les mois d’été (juin-juillet-août-septembre).</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "<b>Défi codage n°1 (*) : séquences record de régimes </b>\n",
    "<p>\n",
    "Le tableau cluster contient les numéros de régime pour chaque jour de l'étude (0 = régime 1, 1 = régime 2, 2 = régime 3, 3 = régime 4). Le tableau regime fait la correspondance entre le numéro de régime et le nom du régime. L'index de date dates2 contient les dates de l'étude.\n",
    "\n",
    "- Exploiter ces 3 tableaux pour établir le top 20 des séquences les plus longues d'un même régime en précisant pour chaque séquence le régime considéré ainsi que la date de de début et de fin de la séquence.\n",
    "\n",
    "Indication : les fonctions suivantes pourront s'avérer utiles :\n",
    "- https://docs.python.org/3/library/itertools.html#itertools.groupby\n",
    "- https://numpy.org/doc/stable/reference/generated/numpy.sort.html\n",
    "- https://numpy.org/doc/stable/reference/generated/numpy.argsort.html\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "<b>Défi codage N°2 (**) : non prise en compte des régimes non persistants : </b>\n",
    "<p>\n",
    "Le tableau cluster contient les numéros de régime pour chaque jour de l'étude (0 = régime 1, 1 = régime 2, 2 = régime 3, 3 = régime 4).\n",
    "\n",
    "- Exploiter ce tableau pour déclassifier les séquences de moins de 3 jours consécutifs d'un même régime en les attribuant à un nouveau numéro de régime (4 = classe régime \"poubelle\"). Ces séqeunces correspondent en effet à des phases de transitions entre 2 régimes.\n",
    "\n",
    "Indication : la fonction suivante pourra s'avérer utile :\n",
    "- https://docs.python.org/3/library/itertools.html#itertools.groupby\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "<b>Défi codage N°3 (**) : non prise en compte des régimes non robustes : </b>\n",
    "<p>\n",
    "Le tableau cluster contient les numéros de régime pour chaque jour de l'étude (0 = régime 1, 1 = régime 2, 2 = régime 3, 3 = régime 4). Les dataArray mean_c1_anom, mean_c2_anom, mean_c3_anom, mean_c3_anom correspondent aux composites des régimes 1 à 4. Le dataArray data_anom[varname][:,:,:]/var_div contient les champs d'anomalies sur toute la période d'étude.\n",
    "\n",
    "- Exploiter ces données pour déclassifier les régimes dont la corrélation spatiale avec le composite est inférieure à 0.25 en les attribuant à un régime 4 (classe régime \"poubelle\"). Ces séquences correspondent en effet à des régimes non robustes.\n",
    "\n",
    "Indication : les fonctions suivantes pourront s'avérer utiles :\n",
    "- https://numpy.org/doc/stable/reference/generated/numpy.corrcoef.html\n",
    "- https://numpy.org/doc/stable/reference/generated/numpy.ndarray.flatten.html (pour aplatir les tableaux 2D)\n",
    "</p>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
