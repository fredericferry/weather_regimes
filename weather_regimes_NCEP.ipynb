{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etude des régimes de temps\n",
    "\n",
    "\n",
    "**Auteur : FERRY Frédéric (ENM/C3M) - Janvier 2022.\n",
    "mailto:frederic.ferry@meteo.fr\n",
    "\n",
    "Les régimes de temps sont des briques élémentaires de la circulation extratropicale de grande échelle spatialement bien définis, récurrents, de durée de vie de l’ordre de quelques jours à quelques semaines. **Le régime de temps est la principale entité physique des fluctuations atmosphériques aux moyennes latitudes** et les changements du temps qu'il fait peuvent se comprendre comme le passage d'un régime à un autre. La variabilité climatique peut, quant à elle, s'interpréter comme la conséquence sur une longue période de transitions privilégiées vers un régime donné. Ainsi, le concept de régime de temps fournit une grille de lecture simplificatrice du climat des latitudes moyennes et de son évolution.\n",
    "\n",
    "**On s'intéressera ici à l'étude des régimes de temps de l'Atlantique Nord (et éventuellement du Pacifique nord) à partir de séries quotidiennes de géopotentiel à 500 hPa et de pression réduite au niveau de la mer**. \n",
    "\n",
    "- Etape 1 : ouverture et sélection des données quotidiennes\n",
    "- Etape 2 : calcul des anomalies quotidiennes\n",
    "- Etape 3 : décomposition des données en temps et en espace (analyse en composantes principales, ACP)\n",
    "- Etape 4 : classification en 4 classes = régimes (méthode k-means)\n",
    "- Etape 5 : obtention des régimes de temps\n",
    "- Etape 6 : temps sensible associé aux régimes de temps\n",
    "- Etape 7 : étude des occurrences saisonnières des régimes de temps\n",
    "- Etape 8 : corrélation régimes/indices océaniques (Nino 3.4, TNA, AMV)\n",
    "- Etape 9 : retour sur une saison particulière\n",
    "\n",
    "Concepts Python illustrés :\n",
    "\n",
    "- Exploitation de fichiers de données météorologiques au format netcdf (xarray/netCDF4)\n",
    "- Calcul d'anomalies quotidiennes (méthode groupby de xarray)\n",
    "- Création de séries temporelles (pandas)\n",
    "- Tracé de cartes (matplotlib/cartopy)\n",
    "- Régression linéaire (module LinearRegression de sklearn, https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)\n",
    "- Analyse en composantes principales (package eofs, https://ajdawson.github.io/eofs/latest/)\n",
    "- Représentation des données dans un espace des phases (scatterplot 2D ou 3D)\n",
    "- Tracé de densité de points (module gaussian_kde de scipy)\n",
    "- Classification K-means (module KMeans de sklearn, https://scikit-learn.org/stable/modules/clustering.html)\n",
    "- Réalisation de cartes composites (moyenne par classe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>Instructions : </b>\n",
    "<p><b>1) </b>Exécuter les cellules qui suivent de façon séquentielle</p>\n",
    "<p><b>2) </b>Répondre aux questions (celulles de couleur jaune) dans les cadres réponses dédiés (cellules de couleur verte)</p>\n",
    "<p><b>3) </b>Sauvegarder le calepin final au format pdf</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "<b>Attention : les étapes 3 (Analyse en composantes principales) et 4 (classification) ne sont pas au programme de première année et sont à utiliser ici comme des boîtes noires </b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import calendar\n",
    "from calendar import isleap\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "import IPython.display as IPdisplay, matplotlib.font_manager as fm\n",
    "from PIL import Image\n",
    "import glob\n",
    "\n",
    "import xarray as xr\n",
    "from netCDF4 import Dataset\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import Series\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.patches import Rectangle\n",
    "from matplotlib.collections import PatchCollection\n",
    "from mpl_toolkits.axes_grid1 import AxesGrid\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.path as mpath\n",
    "\n",
    "from cartopy import config\n",
    "import cartopy.feature as cfeature\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.mpl.geoaxes import GeoAxes\n",
    "from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter\n",
    "\n",
    "from eofs.standard import Eof\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Dossiers des données, figures, animations et résultats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dir_data='./data/'\n",
    "dir_res='./result/'\n",
    "dir_figs='./figs/'\n",
    "dir_anim='./anim/'\n",
    "\n",
    "if not os.path.exists(dir_figs):\n",
    "    os.makedirs(dir_figs)\n",
    "if not os.path.exists(dir_anim):\n",
    "    os.makedirs(dir_anim)\n",
    "if not os.path.exists(dir_res):\n",
    "    os.makedirs(dir_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etape 1 : ouverture et sélection des données quotidiennes"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Ouverture (via xarray) du fichier des données :\n",
    "\n",
    "zg500_1d_19480101_20191231_NCEP.nc :\n",
    "Fichier au format netcdf issu des réanalyses quotidiennes du NCEP (https://psl.noaa.gov/cgi-bin/db_search/DBListFiles.pl?did=195&tid=89433&vid=663)\n",
    "Les données sont des valeurs quotidiennes de hauteur géopotentielle à 500hPa (variable zg500, unité : mètres) sur le globe et pour la période 1948-2019.\n",
    "\n",
    "slp_1d_19480101_20191231_NCEP.nc :\n",
    "Fichier au format netcdf issu des réanalyses quotidiennes du NCEP (https://psl.noaa.gov/cgi-bin/db_search/DBListFiles.pl?did=195&tid=89476&vid=676)\n",
    "Les données sont des valeurs quotidiennes de pression réduite au niveau de la mer (variable slp, unité : Pa) sur le globe et pour la période 1948-2019."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Choix de la variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "var_text=input(\"Z500 ou Pmer : Z500/MSLP? \")\n",
    "\n",
    "if var_text=='Z500':\n",
    "    infile = dir_data+'zg500_1d_19480101_20191231_NCEP.nc'\n",
    "    varname='zg500'\n",
    "    var_div=1\n",
    "    units='m'\n",
    "\n",
    "if var_text=='MSLP':\n",
    "    infile = dir_data+'slp_1d_19480101_20191231_NCEP.nc'\n",
    "    varname='slp'\n",
    "    var_div=100\n",
    "    units='hPa'\n",
    "\n",
    "data0    = xr.open_dataset(infile)\n",
    "print(data0.variables)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Choix du domaine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "domain_name=input(\"Domaine Atlantique nord ou Pacifique : natl/npac ? \")\n",
    "\n",
    "if domain_name=='natl':\n",
    "    domain='North Atlantic'\n",
    "    latS=20\n",
    "    latN=80\n",
    "    lonW=-80\n",
    "    lonE=30\n",
    "if domain_name=='npac':\n",
    "    domain='North Pacific'\n",
    "    latS=20\n",
    "    latN=80\n",
    "    lonW=115\n",
    "    lonE=285"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Choix de la saison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "season_name=input(\"Saison hiver ou été : winter/summer ? \")\n",
    "\n",
    "if season_name=='winter':\n",
    "    season='Winter'\n",
    "    startday  = '1957-12-01'\n",
    "    endday  = '2018-03-31'\n",
    "if season_name=='summer':\n",
    "    season='Summer'\n",
    "    startday  = '1958-06-01'\n",
    "    endday  = '2018-09-30'\n",
    "\n",
    "# Date index from startday to endday\n",
    "dates = pd.date_range(startday, endday, freq='D')\n",
    "print(dates)\n",
    "\n",
    "# Remove 29/02\n",
    "#def is_leap_and_29Feb(s):\n",
    "#    return (s.year % 4 == 0) & ((s.year % 100 != 0) | (s.year % 400 == 0)) & (s.month == 2) & (s.day == 29)\n",
    "#mask = is_leap_and_29Feb(dates)\n",
    "#dates=dates[~mask]\n",
    "#print(dates)\n",
    "\n",
    "# Select Season\n",
    "if season_name == 'winter':\n",
    "    months=np.any([dates.month==12,dates.month==1,dates.month==2,dates.month==3],axis=0)\n",
    "if season_name == 'summer':\n",
    "    months=np.any([dates.month==6,dates.month==7,dates.month==8,dates.month==9],axis=0)\n",
    "\n",
    "dates2=dates[months]\n",
    "print(dates2)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Conversion des longitudes : 0 - 360 --> -180 - 180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def lonflip(da):\n",
    "    lon_name = 'lon'\n",
    "    da['_longitude_adjusted'] = xr.where(\n",
    "        da[lon_name] > 180,\n",
    "        da[lon_name] - 360,\n",
    "        da[lon_name])\n",
    "    da = (\n",
    "        da\n",
    "        .swap_dims({lon_name: '_longitude_adjusted'})\n",
    "        .sel(**{'_longitude_adjusted': sorted(da._longitude_adjusted)})\n",
    "        .drop(lon_name))\n",
    "    da = da.rename({'_longitude_adjusted': lon_name})\n",
    "    return da"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Sélection des données sur le sous-domaine et la période choisis. Création d'un nouveau fichier netcdf des données quotidiennes sur le sous-domaine et la période retenus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if domain_name=='natl':\n",
    "    data = lonflip(data0)\n",
    "if domain_name=='npac':\n",
    "    data = data0\n",
    "\n",
    "data_season = data.sel(lat=slice(latN,latS)).sel(lon=slice(lonW,lonE)).sel(time=dates2)\n",
    "print(data_season)\n",
    "\n",
    "lat  = data_season.lat.values\n",
    "lon  = data_season.lon.values\n",
    "time  = data_season.time.values\n",
    "\n",
    "if season_name == 'winter':\n",
    "    season1= str(data_season.time.values[130])[0:4]\n",
    "    season2= str(data_season.time.values[-1])[0:4]\n",
    "\n",
    "if season_name == 'summer':\n",
    "    season1= str(data_season.time.values[0])[0:4]\n",
    "    season2= str(data_season.time.values[-1])[0:4]\n",
    "\n",
    "print(' ----- Saving new seasonnal file from '+startday+ ' to '+endday+ ' on new domain  ----- ')\n",
    "infile1 = dir_res+varname+'_'+startday+'_'+endday+'_'+domain_name+'.nc'\n",
    "data_season.to_netcdf(infile1)\n",
    "print(' new daily seasonnal file over subdomain is here : ')\n",
    "print(infile1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Vérification des dates (cellule à vider après vérification)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with np.printoptions(threshold=np.inf):\n",
    "    print(time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etape 2 : calcul des anomalies quotidiennes"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Calcul des anomalies quotidiennes sur le sous-domaine et la période retenus.\n",
    "Sauvegarde du fichier d'anomalies quotidiennes au format netcdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(' ----- Computing daily anomalies ----- ')\n",
    "data_anom = data_season.groupby('time.dayofyear') - data_season.groupby('time.dayofyear').mean('time')\n",
    "print(data_anom)\n",
    "print(' ----- Writing netcdf ----- ')\n",
    "infile2 = dir_res+varname+'_anom_'+startday+'_'+endday+'_'+domain_name+'.nc'\n",
    "data_anom.to_netcdf(infile2)\n",
    "print(' netcdf file of daily anomalies is here : ')\n",
    "print(infile2)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Sélection des données (total et anomalie) pour 30 jours consécutifs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if season_name == 'winter':\n",
    "    #date1='19891201'\n",
    "    #date2='19891230'\n",
    "    #date1='19900101'\n",
    "    #date2='19900130'\n",
    "    #date1='20100201'\n",
    "    #date2='20100302'\n",
    "    date1='20111201'\n",
    "    date2='20111230'\n",
    "    \n",
    "if season_name == 'summer':\n",
    "    date1='20030801'\n",
    "    date2='20030830'\n",
    "    \n",
    "data_month    = data_season.sel(time=slice(date1,date2))\n",
    "data_month_anom    = data_anom.sel(time=slice(date1,date2))\n",
    "\n",
    "z=data_month[varname]/var_div\n",
    "z_anom=data_month_anom[varname]/var_div\n",
    "\n",
    "time  = data_month.time.values\n",
    "\n",
    "time_str=[x for x in range(len(time))]\n",
    "date_str=[x for x in range(len(time))]\n",
    "\n",
    "for i in range(len(time)):\n",
    "\ttime_str[i] = str(time[i])\n",
    "\tdate_str[i] = time_str[i][0:10]\n",
    "    \n",
    "print(data_month)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Définition de la projection, fonction pour la découpe du contour des cartes en projection non rectangulaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "projection = ccrs.Orthographic(central_longitude=(lonW+lonE)/2, central_latitude=(latS+latN)/2)\n",
    "\n",
    "def make_boundary_path(lon,lat):\n",
    "    lons,lats=np.meshgrid(lon,lat)\n",
    "    boundary_path = np.array([lons[-1,:],lats[-1,:]])\n",
    "    boundary_path = np.append(boundary_path,np.array([lons[::-1,-1],lats[::-1,-1]]),axis=1)\n",
    "    boundary_path = np.append(boundary_path,np.array([lons[1,::-1],lats[1,::-1]]),axis=1)\n",
    "    boundary_path = np.append(boundary_path,np.array([lons[:,1],lats[:,1]]),axis=1)\n",
    "    boundary_path = mpath.Path(np.swapaxes(boundary_path, 0, 1))\n",
    "    return boundary_path"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Domaine de tracé, échelles de valeurs, titres, palettes de couleurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if varname=='zg500':\n",
    "    levels1 = np.arange(4800,6200,100)\n",
    "    plt_title1 = 'Geopotential height ('+units+') at 500 hPa : '+ str(date1)+'-'+str(date2)\n",
    "    levels2 = np.arange(-500,550,50)\n",
    "    plt_title2 = 'Geopotential height anomaly ('+units+') at 500 hPa : '+ str(date1)+'-'+str(date2)\n",
    "\n",
    "if varname=='slp':\n",
    "    levels1 = np.arange(980,1040,5)\n",
    "    plt_title1 = 'Mean Sea Level Pressure ('+units+') : '+ str(date1)+'-'+str(date2)\n",
    "    levels2 = np.arange(-25,27.5,2.5)\n",
    "    plt_title2 = 'Mean Sea Level Pressure anomaly ('+units+') : '+ str(date1)+'-'+str(date2)\n",
    "\n",
    "cmap1='jet'\n",
    "cmap2='RdBu_r'"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Cartes individuelles (champ total + anomalie) pour la séquence choisie (fichiers png)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(time)):\n",
    "    #print(date_str[i])\n",
    "    fig = plt.figure(figsize=(8., 8.))\n",
    "    fig.suptitle(plt_title2, fontsize=16)\n",
    "    ax = fig.add_subplot(1,1,1, projection=projection)\n",
    "    ax.set_title(date_str[i], loc='center')\n",
    "    ax.coastlines()\n",
    "    ax.gridlines(crs=ccrs.PlateCarree(), linewidth=0.5, color='gray', alpha=0.5, linestyle='-')\n",
    "    ax.set_extent([lonW, lonE, latS, latN], crs=ccrs.PlateCarree())\n",
    "    boundary_path = make_boundary_path(lon, lat)\n",
    "    ax.set_boundary(boundary_path, transform=ccrs.PlateCarree())\n",
    "    p1 = ax.contourf(lon, lat, z_anom[i,:,:], levels2, transform=ccrs.PlateCarree(), cmap=cmap2, extend='both')\n",
    "    p2 = ax.contour(lon, lat, z_anom[i,:,:], levels2, colors='black', linewidths=0.2, transform=ccrs.PlateCarree())\n",
    "    p3 = ax.contour(lon, lat, z[i,:,:], levels1, colors='black', linewidths=1, transform=ccrs.PlateCarree())\n",
    "    ax.clabel(p3, inline=1, fmt='%4.0f', fontsize=10)\n",
    "    cb = fig.colorbar(p1, orientation='horizontal', aspect=65, shrink=0.5, pad=0.05, extendrect='True')\n",
    "    cb.set_label('Anomaly ('+units+')', fontsize=12)\n",
    "\n",
    "    figname=dir_anim+varname+'_anom_'+domain_name+'_'+season_name+'_'+date_str[i]\n",
    "    fig.savefig(figname+'.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "print('png files are in the animation folder, ready to make the animation')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Fonction de création d'une animation à partir des fichiers png présents dans le dossier anim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def make_animation():\n",
    "    nbimages=len(time)\n",
    "    # create a tuple of display durations, one for each frame\n",
    "    first_last = 1000 #show the first and last frames for 1000 ms\n",
    "    standard_duration = 1000 #show all other frames for 1000 ms\n",
    "    durations = tuple([first_last] + [standard_duration] * (nbimages - 2) + [first_last])\n",
    "    # load all the static images into a list\n",
    "    images = [Image.open(image) for image in sorted(glob.glob('{}/*.png'.format(dir_anim)))]\n",
    "    # save as an animated gif\n",
    "    gif = images[0]\n",
    "    gif.info['duration'] = durations #ms per frame\n",
    "    gif.info['loop'] = 0 #how many times to loop (0=infinite)\n",
    "    gif.save(fp=gif_filepath, format='gif', save_all=True, append_images=images[1:])\n",
    "    # verify that the number of frames in the gif equals the number of image files and durations\n",
    "    Image.open(gif_filepath).n_frames == len(images) == len(durations)\n",
    "    # clean png\n",
    "    os.chdir(dir_anim)\n",
    "    for f in glob.glob(\"*.png\"):\n",
    "        os.remove(f)\n",
    "    os.chdir(\"../\")\n",
    "    return Image"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Animation des cartes du mois (champ total + anomalie)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gif_filepath = dir_anim+varname+'_anom_'+domain_name+'_'+season_name+'_'+str(date1)+'-'+str(date2)+'.gif'\n",
    "make_animation()\n",
    "IPdisplay.Image(url=gif_filepath)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Tracé des vignettes du champ quotidien pour les 30 jours consécutifs choisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "axes_class = (GeoAxes, dict(map_projection=projection))\n",
    "fig = plt.figure(figsize=(17,10))\n",
    "fig.suptitle(plt_title1, fontsize=16)\n",
    "\n",
    "axgr = AxesGrid(fig, 111, axes_class=axes_class,\n",
    "       nrows_ncols=(5, 6),\n",
    "       axes_pad=0.6,\n",
    "       cbar_location='right',\n",
    "       cbar_mode='single', # None/single/each\n",
    "       cbar_pad=0.2,\n",
    "       cbar_size='3%',\n",
    "       label_mode='')  # note the empty label_mode\n",
    "                   \n",
    "for i, ax in enumerate(axgr):\n",
    "    ax.coastlines()\n",
    "    ax.gridlines(crs=ccrs.PlateCarree(), linewidth=0.5, color='gray', alpha=0.5, linestyle='-')\n",
    "    ax.set_extent([lonW, lonE, latS, latN], crs=ccrs.PlateCarree())\n",
    "    boundary_path = make_boundary_path(lon, lat)\n",
    "    ax.set_boundary(boundary_path, transform=ccrs.PlateCarree())\n",
    "    ax.set_title(date_str[i], fontsize=10)\n",
    "    p1 = ax.contourf(lon, lat, z[i,:,:], levels1, transform=ccrs.PlateCarree(), cmap=cmap1, extend='both')\n",
    "    p2 = ax.contour(lon, lat, z[i,:,:], levels1, colors='black', linewidths=0.2, transform=ccrs.PlateCarree())\n",
    "    axgr.cbar_axes[i].colorbar(p1)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "figname=dir_figs+varname+'_'+domain_name+'_'+season_name+'_'+str(date1)+'-'+str(date2)\n",
    "fig.savefig(figname+'.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Tracé des vignettes de l'anomalie quotidienne pour les 30 jours consécutifs choisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "axes_class = (GeoAxes, dict(map_projection=projection))\n",
    "fig = plt.figure(figsize=(17,10))\n",
    "fig.suptitle(plt_title2, fontsize=16)\n",
    "\n",
    "axgr = AxesGrid(fig, 111, axes_class=axes_class,\n",
    "       nrows_ncols=(5, 6),\n",
    "       axes_pad=0.6,\n",
    "       cbar_location='right',\n",
    "       cbar_mode='single', # None/single/each\n",
    "       cbar_pad=0.2,\n",
    "       cbar_size='3%',\n",
    "       label_mode='')  # note the empty label_mode\n",
    "                   \n",
    "for i, ax in enumerate(axgr):\n",
    "    ax.coastlines()\n",
    "    ax.gridlines(crs=ccrs.PlateCarree(), linewidth=0.5, color='gray', alpha=0.5, linestyle='-')\n",
    "    ax.set_extent([lonW, lonE, latS, latN], crs=ccrs.PlateCarree())\n",
    "    boundary_path = make_boundary_path(lon, lat)\n",
    "    ax.set_boundary(boundary_path, transform=ccrs.PlateCarree())\n",
    "    ax.set_title(date_str[i], fontsize=10)\n",
    "    p1 = ax.contourf(lon, lat, z_anom[i,:,:], levels2, transform=ccrs.PlateCarree(), cmap=cmap2, extend='both')\n",
    "    p2 = ax.contour(lon, lat, z_anom[i,:,:], levels2, colors='black', linewidths=0.2, transform=ccrs.PlateCarree())\n",
    "    axgr.cbar_axes[i].colorbar(p1)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "figname=dir_figs+varname+'_anom_'+domain_name+'_'+season_name+'_'+str(date1)+'-'+str(date2)\n",
    "fig.savefig(figname+'.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>Question : </b>\n",
    "<p><b>1) </b>Pour la séquence mensuelle choisie, peut-on déjà regrouper subjectivement des jours qui se ressemblent ? Combien de groupes pourrait-on faire ?</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Réponse : </b>\n",
    "<p>\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etape 3 : décomposition des données en temps et en espace (analyse en composantes principales, ACP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "<b>Exécuter l'ensemble des cellules de l'étape 3 ci-dessous</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Ouverture (via netcdf4) des données quotidennes, domaine Nord Atlantique, période DJFM 1957-2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "filename = infile1\n",
    "ncin = Dataset(filename, 'r')\n",
    "lons = ncin.variables['lon'][:]\n",
    "lats = ncin.variables['lat'][:]\n",
    "var = ncin.variables[varname][:]/var_div\n",
    "ncin.close()\n",
    "\n",
    "filename = infile2\n",
    "ncin = Dataset(filename, 'r')\n",
    "lons = ncin.variables['lon'][:]\n",
    "lats = ncin.variables['lat'][:]\n",
    "var_anom = ncin.variables[varname][:]/var_div\n",
    "ncin.close()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Réalisation de l'ACP. Avant de réaliser l'ACP on applique une pondération. En effet, sur une grille régulière lat/lon qui ne conserve pas les aires, chaque point de grille n'est pas représentatif de la même surface. Ainsi, si aucune pondération n'est faite avant l'ACP il y aura un problème de distortion aux hautes latitudes. On applique donc en chaque point de grille une pondération consistant à diviser le champ par la racine carrée du cosinus de la latitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "wgts = np.sqrt(np.cos(np.deg2rad(lats)))[:, np.newaxis]\n",
    "solver = Eof(var_anom, weights=wgts, center=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Récupération des 15 premiers vecteurs propres (EOFs, structures spatiales) divisés par la racine carrée de leur valeur propre (i.e écart-type de leur composante principale).\n",
    "Récupération des séries temporelles des composantes principales associées (PCs) non normalisées.\n",
    "Récupération du pourcentage de variance expliqué par chaque composante principale (plus de 80% de la variabilité totale sont expliqués par les 10 premières composantes principales)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n=15\n",
    "eofs = solver.eofs(neofs=n, eofscaling=1)\n",
    "pcs = solver.pcs(npcs=n, pcscaling=0)\n",
    "#pcs_norm = solver.pcs(npcs=n, pcscaling=1)\n",
    "varfrac = solver.varianceFraction()\n",
    "print(\"% de variance expliquée par les 10 premiers EOFs : \", 100*varfrac[0:10].sum())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Tracé des structures spatiales (EOFs) des composantes principales (PCs) et du pourcentage de variance expliqué."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "axes_class = (GeoAxes, dict(map_projection=projection))\n",
    "\n",
    "fig = plt.figure(figsize=(15,6))\n",
    "fig.suptitle('EOFs : '+var_text+' - '+domain+' - '+season+ ' '+season1+'-'+season2, fontsize=16)\n",
    "\n",
    "axgr = AxesGrid(fig, 111, axes_class=axes_class,\n",
    "       nrows_ncols=(3, 5),\n",
    "       axes_pad=0.6,\n",
    "       cbar_location='right',\n",
    "       cbar_mode='each', # None/single/each\n",
    "       cbar_pad=0.2,\n",
    "       cbar_size='3%',\n",
    "       label_mode='')  # note the empty label_mode\n",
    "\n",
    "for i, ax in enumerate(axgr):\n",
    "    ax.coastlines()\n",
    "    ax.set_extent([lonW, lonE, latS, latN], crs=ccrs.PlateCarree())\n",
    "    boundary_path = make_boundary_path(lon, lat)\n",
    "    ax.set_boundary(boundary_path, transform=ccrs.PlateCarree())\n",
    "    ax.set_title('EOF'+str(i+1)+' ('+str(int(varfrac[i]*100))+'%)', fontsize=10, loc='center')\n",
    "    cf = ax.contourf(lons, lats, eofs[i]*1e5, transform=ccrs.PlateCarree(), cmap='bwr', extend='both')\n",
    "    c = ax.contour(lons, lats, eofs[i]*1e5, colors='black', linewidths=1, transform=ccrs.PlateCarree())\n",
    "    axgr.cbar_axes[i].colorbar(cf)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "figname=dir_figs+varname+'_'+domain_name+'_'+season_name+'_eofs'\n",
    "fig.savefig(figname+'.png', bbox_inches='tight')\n",
    "\n",
    "fig = plt.figure(figsize=(15,6))\n",
    "fig.suptitle('PCs : '+var_text+' - '+domain+' - '+season+ ' '+season1+'-'+season2, fontsize=16)\n",
    "\n",
    "plt.subplots_adjust(hspace=0.5, wspace=0.4)\n",
    "\n",
    "for i in range(0, 15):\n",
    "        plt.subplot(3, 5, i+1)\n",
    "        plt.title('PC'+str(i+1)+'(t)')\n",
    "        plt.axhline(0, color='k', linewidth=0.5)\n",
    "        if varname=='zg500':\n",
    "            plt.ylim(-5000, 5000)\n",
    "        if varname=='slp':\n",
    "            plt.ylim(-200, 200)\n",
    "        plt.plot(pcs[:,i], color='k', linewidth=0.5, alpha=0.7)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "figname=dir_figs+varname+'_'+domain_name+'_'+season_name+'_pcs'\n",
    "fig.savefig(figname+'.png', bbox_inches='tight')\n",
    "             \n",
    "fig = plt.figure(figsize=(15, 8))\n",
    "fig.suptitle('Variance fraction : '+var_text+' - '+domain+' - '+season+ ' '+season1+'-'+season2, fontsize=16)\n",
    "\n",
    "eof_num = range(1, 16)\n",
    "plt.bar(eof_num, varfrac[0:15], width=0.5)\n",
    "plt.axhline(0, color='k')\n",
    "plt.xticks(range(1, 16))\n",
    "plt.xlabel('EOF #')\n",
    "plt.ylabel('Variance Fraction')\n",
    "plt.xlim(1, 15)\n",
    "plt.ylim(np.min(varfrac), np.max(varfrac)+0.01)\n",
    "plt.show()\n",
    "\n",
    "figname=dir_figs+varname+'_'+domain_name+'_'+season_name+'_varfrac'\n",
    "fig.savefig(figname+'.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Tracé des 3 premières structures spatiales (EOFs) et des séries temporelles associées (PCs). On change les signes des EOFs et PCs 1 & 2 pour avoir les correspondances suivantes :\n",
    "EOF1 > 0 : NAO+ ; EOF1 < 0 : NAO-\n",
    "EOF2 > 0 : blocage ; EOF2 < 0 : antiblocage\n",
    "EOF3 > 0 : dorsale atlantique ; EOF3 < 0 : minimum atlantique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "eof1=eofs[0]*(-1)\n",
    "eof2=eofs[1]*(-1)\n",
    "eof3=eofs[2]\n",
    "\n",
    "pc1=pcs[:,0]*(-1)\n",
    "pc2=pcs[:,1]*(-1)\n",
    "pc3=pcs[:,2]\n",
    "\n",
    "def plot_pc(ax):\n",
    "    plt.xlabel('Time (days)')\n",
    "    plt.axhline(0, color='k')\n",
    "    if varname=='zg500':\n",
    "        ax.set_ylim(-5000, 5000)\n",
    "    if varname=='slp':\n",
    "        ax.set_ylim(-200, 200)\n",
    "    return ax\n",
    "\n",
    "if varname=='zg500':\n",
    "    clevs = np.linspace(-6, 6, 11)\n",
    "if varname=='slp':\n",
    "    clevs = np.linspace(-5, 5, 11)\n",
    "\n",
    "fig = plt.figure(figsize=(15, 15))\n",
    "\n",
    "fig.suptitle('EOFs and PCs : '+var_text+' - '+domain+' - '+season+ ' '+season1+'-'+season2, fontsize=16)\n",
    "ax = fig.add_subplot(3, 2, 1, projection=projection)\n",
    "plt.title('EOF1 ('+str(int(varfrac[0]*100))+'%)', fontsize=10, loc='center')\n",
    "ax.coastlines()\n",
    "ax.set_extent([lonW, lonE, latS, latN], crs=ccrs.PlateCarree())\n",
    "boundary_path = make_boundary_path(lon, lat)\n",
    "ax.set_boundary(boundary_path, transform=ccrs.PlateCarree())\n",
    "cf = ax.contourf(lons, lats, eof1*1e5, clevs, cmap='bwr', extend='both', transform=ccrs.PlateCarree())\n",
    "c = ax.contour(lons, lats, eof1*1e5, clevs, colors='black', linewidths=1, transform=ccrs.PlateCarree())\n",
    "cb = fig.colorbar(cf, orientation='horizontal', aspect=70, shrink=0.6, pad=0.1, extendrect='True')\n",
    "cb.set_label('$10^{5}$', fontsize=12)\n",
    "\n",
    "ax = fig.add_subplot(3, 2, 2)\n",
    "plot_pc(ax)\n",
    "plt.title('PC1')\n",
    "plt.plot(pc1, color='k', linewidth=1)\n",
    "\n",
    "ax = fig.add_subplot(3, 2, 3, projection=projection)\n",
    "plt.title('EOF2 ('+str(int(varfrac[1]*100))+'%)', fontsize=10, loc='center')\n",
    "ax.coastlines()\n",
    "ax.set_extent([lonW, lonE, latS, latN], crs=ccrs.PlateCarree())\n",
    "boundary_path = make_boundary_path(lon, lat)\n",
    "ax.set_boundary(boundary_path, transform=ccrs.PlateCarree())\n",
    "cf = ax.contourf(lons, lats, eof2*1e5, clevs, cmap='bwr', extend='both', transform=ccrs.PlateCarree())\n",
    "c = ax.contour(lons, lats, eof2*1e5, clevs, colors='black', linewidths=1, transform=ccrs.PlateCarree())\n",
    "cb = fig.colorbar(cf, orientation='horizontal', aspect=70, shrink=0.6, pad=0.1, extendrect='True')\n",
    "cb.set_label('$10^{5}$', fontsize=12)\n",
    "\n",
    "ax = fig.add_subplot(3, 2, 4)\n",
    "plot_pc(ax)\n",
    "plt.title('PC2')\n",
    "plt.plot(pc2, color='k', linewidth=1)\n",
    "\n",
    "ax = fig.add_subplot(3, 2, 5, projection=projection)\n",
    "plt.title('EOF3 ('+str(int(varfrac[2]*100))+'%)', fontsize=10, loc='center')\n",
    "ax.coastlines()\n",
    "ax.set_extent([lonW, lonE, latS, latN], crs=ccrs.PlateCarree())\n",
    "boundary_path = make_boundary_path(lon, lat)\n",
    "ax.set_boundary(boundary_path, transform=ccrs.PlateCarree())\n",
    "cf = ax.contourf(lons, lats, eof3*1e5, clevs, cmap='bwr', extend='both', transform=ccrs.PlateCarree())\n",
    "c = ax.contour(lons, lats, eof3*1e5, clevs, colors='black', linewidths=1, transform=ccrs.PlateCarree())\n",
    "cb = fig.colorbar(cf, orientation='horizontal', aspect=70, shrink=0.6, pad=0.1, extendrect='True')\n",
    "cb.set_label('$10^{5}$', fontsize=12)\n",
    "\n",
    "ax = fig.add_subplot(3, 2, 6)\n",
    "plot_pc(ax)\n",
    "plt.title('PC3')\n",
    "plt.plot(pc3, color='k', linewidth=1)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "figname=dir_figs+varname+'_'+domain_name+'_'+season_name+'_eofs_pcs'\n",
    "fig.savefig(figname+'.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Reconstruction d'un champ à partir des EOFs et des PCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "day=int(input(\"Entrer un numéro de jour pour la reconstruction du champ : \"))\n",
    "field=var_anom[day]\n",
    "\n",
    "#5 EOFS\n",
    "reconst=eofs[0]*pcs[day,0]*np.std(\n",
    "    pcs[:,0])+eofs[1]*pcs[day,1]*np.std(\n",
    "    pcs[:,1])+eofs[2]*pcs[day,2]*np.std(\n",
    "    pcs[:,2])+eofs[3]*pcs[day,3]*np.std(\n",
    "    pcs[:,3])+eofs[4]*pcs[day,4]*np.std(\n",
    "    pcs[:,4])\n",
    "\n",
    "reconst=reconst/wgts\n",
    "\n",
    "#15 EOFS\n",
    "reconst2=eofs[0]*pcs[day,0]*np.std(\n",
    "    pcs[:,0])+eofs[1]*pcs[day,1]*np.std(\n",
    "    pcs[:,1])+eofs[2]*pcs[day,2]*np.std(\n",
    "    pcs[:,2])+eofs[3]*pcs[day,3]*np.std(\n",
    "    pcs[:,3])+eofs[4]*pcs[day,4]*np.std(\n",
    "    pcs[:,4])+eofs[5]*pcs[day,5]*np.std(    \n",
    "    pcs[:,5])+eofs[6]*pcs[day,6]*np.std(    \n",
    "    pcs[:,6])+eofs[7]*pcs[day,7]*np.std(\n",
    "    pcs[:,7])+eofs[8]*pcs[day,8]*np.std(\n",
    "    pcs[:,8])+eofs[9]*pcs[day,9]*np.std(\n",
    "    pcs[:,9])+eofs[10]*pcs[day,10]*np.std(\n",
    "    pcs[:,10])+eofs[11]*pcs[day,11]*np.std(\n",
    "    pcs[:,11])+eofs[12]*pcs[day,12]*np.std(\n",
    "    pcs[:,12])+eofs[13]*pcs[day,13]*np.std(\n",
    "    pcs[:,13])+eofs[14]*pcs[day,14]*np.std(\n",
    "    pcs[:,14])\n",
    "\n",
    "reconst2=reconst2/wgts\n",
    "\n",
    "fig = plt.figure(figsize=(15, 5))\n",
    "\n",
    "fig.suptitle('Reconstruction from the EOFs and PCs', fontsize=16)\n",
    "ax = fig.add_subplot(131, projection=projection)\n",
    "plt.title('Anomaly field', fontsize=10, loc='center')\n",
    "ax.coastlines()\n",
    "ax.set_extent([lonW, lonE, latS, latN], crs=ccrs.PlateCarree())\n",
    "boundary_path = make_boundary_path(lon, lat)\n",
    "ax.set_boundary(boundary_path, transform=ccrs.PlateCarree())\n",
    "cf = ax.contourf(lons, lats, field, levels2, cmap=cmap2, extend='both', transform=ccrs.PlateCarree())\n",
    "c = ax.contour(lons, lats, field, levels2, colors='black', linewidths=1, transform=ccrs.PlateCarree())\n",
    "cb = fig.colorbar(cf, orientation='horizontal', aspect=65, shrink=1, pad=0.05, extendrect='True')\n",
    "cb.set_label(units, fontsize=12)\n",
    "\n",
    "ax = fig.add_subplot(132, projection=projection)\n",
    "plt.title('Reconstruction with 5 EOFs', fontsize=10, loc='center')\n",
    "ax.coastlines()\n",
    "ax.set_extent([lonW, lonE, latS, latN], crs=ccrs.PlateCarree())\n",
    "boundary_path = make_boundary_path(lon, lat)\n",
    "ax.set_boundary(boundary_path, transform=ccrs.PlateCarree())\n",
    "cf = ax.contourf(lons, lats, reconst, levels2, cmap=cmap2, extend='both', transform=ccrs.PlateCarree())\n",
    "c = ax.contour(lons, lats, reconst, levels2, colors='black', linewidths=1, transform=ccrs.PlateCarree())\n",
    "cb = fig.colorbar(cf, orientation='horizontal', aspect=65, shrink=1, pad=0.05, extendrect='True')\n",
    "cb.set_label(units, fontsize=12)\n",
    "\n",
    "ax = fig.add_subplot(133, projection=projection)\n",
    "plt.title('Reconstruction with 15 EOFs', fontsize=10, loc='center')\n",
    "ax.coastlines()\n",
    "ax.set_extent([lonW, lonE, latS, latN], crs=ccrs.PlateCarree())\n",
    "boundary_path = make_boundary_path(lon, lat)\n",
    "ax.set_boundary(boundary_path, transform=ccrs.PlateCarree())\n",
    "cf = ax.contourf(lons, lats, reconst2, levels2, cmap=cmap2, extend='both', transform=ccrs.PlateCarree())\n",
    "c = ax.contour(lons, lats, reconst2, levels2, colors='black', linewidths=1, transform=ccrs.PlateCarree())\n",
    "cb = fig.colorbar(cf, orientation='horizontal', aspect=65, shrink=1, pad=0.05, extendrect='True')\n",
    "cb.set_label(units, fontsize=12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Fonction de tracé pour l'espace des phases 2D défini par PC1 et PC2 et dans l'espace des phases 3D défini par PC1 PC2 et PC3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_phase_space2d(ax):\n",
    "    plt.title('')\n",
    "    plt.xlabel('PC1')\n",
    "    plt.ylabel('PC2')\n",
    "    if varname=='zg500':\n",
    "        plt.xlim(-5000, 5000)\n",
    "        plt.ylim(-5000, 5000)\n",
    "    if varname=='slp':\n",
    "        plt.xlim(-200, 200)\n",
    "        plt.ylim(-200, 200)\n",
    "    plt.axvline(0, color='k', linestyle='--')\n",
    "    plt.axhline(0, color='k', linestyle='--')\n",
    "    return ax\n",
    "\n",
    "def plot_phase_space3d(ax):\n",
    "    ax.set_xlabel('PC1')\n",
    "    ax.set_ylabel('PC2')\n",
    "    ax.set_zlabel('PC3')\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Tracé du nuage de points des séries temporelles dans l'espace des phases défini par PC1 et PC2 (+ densité avec la fonction gaussian_kde de scipy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "fig.suptitle('PC1 and PC2 phase space density', fontsize=14)\n",
    "plot_phase_space2d(ax)\n",
    "xy = np.vstack([pc1,pc2])\n",
    "z = gaussian_kde(xy)(xy)\n",
    "#ax.scatter(pc1,pc2, s=10, color = 'r')\n",
    "ax.scatter(pc1, pc2, cmap='jet', c=z, s=10)\n",
    "plt.show()\n",
    "\n",
    "figname=dir_figs+varname+'_'+domain_name+'_'+season_name+'_pc12_density'\n",
    "fig.savefig(figname+'.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Tracé du nuage de points des séries temporelles dans l'espace des phases défini par PC1 PC2 et PC3 (projection=3D, + densité avec la fonction gaussian_kde de scipy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 10))\n",
    "fig.suptitle('PC1 PC2 and PC3 phase space', fontsize=14)\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "plot_phase_space3d(ax)\n",
    "xyz = np.vstack([pc1,pc2,pc3])\n",
    "z = gaussian_kde(xyz)(xyz)\n",
    "#ax.scatter(pc1,pc2,pc3, s=10, color = 'r')\n",
    "ax.scatter(pc1, pc2, pc3, cmap='jet', c=z, s=10)\n",
    "plt.show()\n",
    "\n",
    "figname=dir_figs+varname+'_'+domain_name+'_'+season_name+'_pc123_density'\n",
    "fig.savefig(figname+'.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etape 4 : classification en 4 classes = régimes (méthode k-means)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "<b>Exécuter l'ensemble des cellules de l'étape 4 ci-dessous</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Les régimes de temps sont des attracteurs dans l'espace climatique. Pour les mettre en évidence on utilise une méthode de classification (\"clustering\") de type Kmeans. Cette méthode nécessite un choix a priori d'un nombre de classes que l'on fixe à 4 (4 attracteurs dans l'espace climatique). La classification est faite dans l'espace des phases des PCs issu de l'ACP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour une illustration de l'implémentation de la méthode k-means en Python, consulter le lien suivant : https://mubaris.com/posts/kmeans-clustering/"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Clustering - méthode K-means. L'algorithme est exécuté 100 fois avec différents \"centroid seeds\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pcs = np.array([pc1,pc2,pc3,pcs[:,3],\n",
    "                pcs[:,4],pcs[:,5],pcs[:,6],\n",
    "                pcs[:,7],pcs[:,8],pcs[:,9],\n",
    "                pcs[:,10],pcs[:,11],pcs[:,12],\n",
    "                pcs[:,13],pcs[:,14]],)\n",
    "pcs=pcs.transpose()\n",
    "\n",
    "#Number of time the k-means algorithm will be run with different centroid seeds\n",
    "n_init=100\n",
    "#Maximum number of iterations of the k-means algorithm for a single run\n",
    "max_iter=500\n",
    "\n",
    "# Number of clusters\n",
    "kmeans = KMeans(n_clusters=4, n_init=n_init, max_iter=max_iter, algorithm=\"full\", verbose=1)\n",
    "# Fitting the input data\n",
    "kmeans = kmeans.fit(pcs)\n",
    "# Getting the cluster labels\n",
    "cluster = kmeans.predict(pcs)\n",
    "# Centroid values\n",
    "centroids = kmeans.cluster_centers_\n",
    "\n",
    "print(cluster)\n",
    "print(cluster.shape)\n",
    "print(centroids.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Comptage du nombre de jours par cluster et des fréquences (nombre de jours du cluster divisé par nombre de jours total)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nc1=list(cluster[:]).count(0)\n",
    "nc2=list(cluster[:]).count(1)\n",
    "nc3=list(cluster[:]).count(2)\n",
    "nc4=list(cluster[:]).count(3)\n",
    "\n",
    "f1=int(nc1/cluster.shape[0]*100)\n",
    "f2=int(nc2/cluster.shape[0]*100)\n",
    "f3=int(nc3/cluster.shape[0]*100)\n",
    "f4=int(nc4/cluster.shape[0]*100)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Création du tableau des couleurs selon le numéro de cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "colors=[\"\"]*len(cluster)\n",
    "couleur=[\"blue\",\"red\",\"green\",\"orange\"]\n",
    "for i in range(len(cluster)):\n",
    " colors[i]=couleur[cluster[i]]\n",
    "\n",
    "label=couleur[0]+' : '+str(nc1)+' ('+str(f1)+'%)'+', '+couleur[1]+' : '+str(nc2)+' ('+str(f2)+'%)'+', '+couleur[2]+' : '+str(nc3)+' ('+str(f3)+'%)'+', '+couleur[3]+' : '+str(nc4)+' ('+str(f4)+'%)'\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Tracé du nuage de points des séries temporelles dans l'espace des phases défini par PC1 et PC2 après clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111)\n",
    "fig.suptitle('PC1 and PC2 phase space (4 clusters)', fontsize=14)\n",
    "plot_phase_space2d(ax)\n",
    "plt.scatter(pc1, pc2, c=colors, s=10, label=label)\n",
    "plt.scatter(centroids[:, 0], centroids[:, 1], c=couleur, s=2000, alpha=1, marker='+');\n",
    "\n",
    "patch1 = mpatches.Patch(color=couleur[0], label='Cluster 1 : '+str(nc1)+' ('+str(f1)+'%)')\n",
    "patch2 = mpatches.Patch(color=couleur[1], label='Cluster 2 : '+str(nc2)+' ('+str(f2)+'%)')\n",
    "patch3 = mpatches.Patch(color=couleur[2], label='Cluster 3 : '+str(nc3)+' ('+str(f3)+'%)')\n",
    "patch4 = mpatches.Patch(color=couleur[3], label='Cluster 4 : '+str(nc4)+' ('+str(f4)+'%)')\n",
    "all_handles = (patch1, patch2, patch3, patch4)\n",
    "leg = ax.legend(handles=all_handles, loc='upper right')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "figname=dir_figs+varname+'_'+domain_name+'_'+season_name+'_pc12_clustering'\n",
    "fig.savefig(figname+'.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Tracé du nuage de points des séries temporelles dans l'espace des phases défini par PC1 PC2 et PC3 après clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 10))\n",
    "fig.suptitle('PC1 PC2 and PC3 phase space (4 clusters)', fontsize=14)\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "plot_phase_space3d(ax)\n",
    "ax.scatter(pc1, pc2, pc3, c=colors, s=10, label=label)\n",
    "ax.scatter(centroids[:, 0], centroids[:, 1], centroids[:, 2], c=couleur, s=2000, alpha=1, marker='+')\n",
    "\n",
    "patch1 = mpatches.Patch(color=couleur[0], label='Cluster 1 : '+str(nc1)+' ('+str(f1)+'%)')\n",
    "patch2 = mpatches.Patch(color=couleur[1], label='Cluster 2 : '+str(nc2)+' ('+str(f2)+'%)')\n",
    "patch3 = mpatches.Patch(color=couleur[2], label='Cluster 3 : '+str(nc3)+' ('+str(f3)+'%)')\n",
    "patch4 = mpatches.Patch(color=couleur[3], label='Cluster 4 : '+str(nc4)+' ('+str(f4)+'%)')\n",
    "all_handles = (patch1, patch2, patch3, patch4)\n",
    "leg = ax.legend(handles=all_handles, loc='lower right')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "figname=dir_figs+varname+'_'+domain_name+'_'+season_name+'_pc123_clustering'\n",
    "fig.savefig(figname+'.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etape 5 : obtention des régimes de temps"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Calcul des composites du champ pour chaque cluster. Pour chaque cluster, on fait la moyenne du champ pour tous jours qui sont classés dans ce cluster --> 4 régimes de temps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "id_cluster1=np.any([cluster==0],axis=0)\n",
    "id_cluster2=np.any([cluster==1],axis=0)\n",
    "id_cluster3=np.any([cluster==2],axis=0)\n",
    "id_cluster4=np.any([cluster==3],axis=0)\n",
    "\n",
    "print(id_cluster1)\n",
    "print(id_cluster2)\n",
    "print(id_cluster3)\n",
    "print(id_cluster4)\n",
    "\n",
    "mean_c1 = var[id_cluster1,:,:].mean(axis=0)\n",
    "mean_c2 = var[id_cluster2,:,:].mean(axis=0)\n",
    "mean_c3 = var[id_cluster3,:,:].mean(axis=0)\n",
    "mean_c4 = var[id_cluster4,:,:].mean(axis=0)\n",
    "\n",
    "mean_c1_anom = var_anom[id_cluster1,:,:].mean(axis=0)\n",
    "mean_c2_anom = var_anom[id_cluster2,:,:].mean(axis=0)\n",
    "mean_c3_anom = var_anom[id_cluster3,:,:].mean(axis=0)\n",
    "mean_c4_anom = var_anom[id_cluster4,:,:].mean(axis=0)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Tracé des 4 régimes de temps (anomalie en couleur et champ moyen en isolignes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if varname=='zg500':\n",
    "    clevs = np.linspace(5000, 6000, 11)\n",
    "    clevs_anom = np.linspace(-150, 150, 11)\n",
    "if varname=='slp':\n",
    "    clevs = np.linspace(990, 1020, 15)\n",
    "    clevs_anom = np.linspace(-8, 8, 17)\n",
    "\n",
    "fig = plt.figure(figsize=(15, 10))\n",
    "fig.suptitle('Weather regimes : '+var_text+' - '+domain+' - '+season+ ' '+season1+'-'+season2, fontsize=16)\n",
    "\n",
    "ax = fig.add_subplot(2, 2, 1, projection=projection)\n",
    "plt.title('Regime 1 (freq = '+str(f1)+'%)', fontsize=10, loc='center', color=couleur[0])\n",
    "ax.coastlines()\n",
    "ax.set_extent([lonW, lonE, latS, latN], crs=ccrs.PlateCarree())\n",
    "boundary_path = make_boundary_path(lons, lats)\n",
    "ax.set_boundary(boundary_path, transform=ccrs.PlateCarree())\n",
    "cf = ax.contourf(lons, lats, mean_c1_anom, levels=clevs_anom, \n",
    "                 cmap=cmap2, extend='both', transform=ccrs.PlateCarree())\n",
    "c = ax.contour(lons, lats, mean_c1, levels=clevs, colors='black', linewidths=1, transform=ccrs.PlateCarree())\n",
    "ax.clabel(c, inline=1, fmt='%4.0f', fontsize=10)\n",
    "cb = fig.colorbar(cf, orientation='horizontal', aspect=65, shrink=1, pad=0.05, extendrect='True')\n",
    "cb.set_label('Anomaly ('+units+')', fontsize=12)\n",
    "\n",
    "ax = fig.add_subplot(2, 2, 2, projection=projection)\n",
    "plt.title('Regime 2 (freq = '+str(f2)+'%)', fontsize=10, loc='center', color=couleur[1])\n",
    "ax.coastlines()\n",
    "ax.set_extent([lonW, lonE, latS, latN], crs=ccrs.PlateCarree())\n",
    "boundary_path = make_boundary_path(lons, lats)\n",
    "ax.set_boundary(boundary_path, transform=ccrs.PlateCarree())\n",
    "cf = ax.contourf(lons, lats, mean_c2_anom, levels=clevs_anom, \n",
    "                 cmap=cmap2, extend='both', transform=ccrs.PlateCarree())\n",
    "c = ax.contour(lons, lats, mean_c2, levels=clevs, colors='black', linewidths=1, transform=ccrs.PlateCarree())\n",
    "ax.clabel(c, inline=1, fmt='%4.0f', fontsize=10)\n",
    "cb = fig.colorbar(cf, orientation='horizontal', aspect=65, shrink=1, pad=0.05, extendrect='True')\n",
    "cb.set_label('Anomaly ('+units+')', fontsize=12)\n",
    "\n",
    "ax = fig.add_subplot(2, 2, 3, projection=projection)\n",
    "plt.title('Regime 3 (freq = '+str(f3)+'%)', fontsize=10, loc='center', color=couleur[2])\n",
    "ax.coastlines()\n",
    "ax.set_extent([lonW, lonE, latS, latN], crs=ccrs.PlateCarree())\n",
    "boundary_path = make_boundary_path(lons, lats)\n",
    "ax.set_boundary(boundary_path, transform=ccrs.PlateCarree())\n",
    "cf = ax.contourf(lons, lats, mean_c3_anom, levels=clevs_anom, \n",
    "                 cmap=cmap2, extend='both', transform=ccrs.PlateCarree())\n",
    "c = ax.contour(lons, lats, mean_c3, levels=clevs, colors='black', linewidths=1, transform=ccrs.PlateCarree())\n",
    "ax.clabel(c, inline=1, fmt='%4.0f', fontsize=10)\n",
    "cb = fig.colorbar(cf, orientation='horizontal', aspect=65, shrink=1, pad=0.05, extendrect='True')\n",
    "cb.set_label('Anomaly ('+units+')', fontsize=12)\n",
    "\n",
    "ax = fig.add_subplot(2, 2, 4, projection=projection)\n",
    "plt.title('Regime 4 (freq = '+str(f4)+'%)', fontsize=10, loc='center', color=couleur[3])\n",
    "ax.coastlines()\n",
    "ax.set_extent([lonW, lonE, latS, latN], crs=ccrs.PlateCarree())\n",
    "boundary_path = make_boundary_path(lons, lats)\n",
    "ax.set_boundary(boundary_path, transform=ccrs.PlateCarree())\n",
    "cf = ax.contourf(lons, lats, mean_c4_anom, levels=clevs_anom, \n",
    "                 cmap=cmap2, extend='both', transform=ccrs.PlateCarree())\n",
    "c = ax.contour(lons, lats, mean_c4, levels=clevs, colors='black', linewidths=1, transform=ccrs.PlateCarree())\n",
    "ax.clabel(c, inline=1, fmt='%4.0f', fontsize=10)\n",
    "cb = fig.colorbar(cf, orientation='horizontal', aspect=65, shrink=1, pad=0.05, extendrect='True')\n",
    "cb.set_label('Anomaly ('+units+')', fontsize=12)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "figname=dir_figs+varname+'_'+domain_name+'_'+season_name+'_'+'regimes'\n",
    "fig.savefig(figname+'.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>Questions : </b>\n",
    "<p><b>1) </b>Identifier le régime NAO+ (ou régime zonal)\n",
    "</p>\n",
    "<p><b>2) </b>Identifier le régime NAO- (ou régime de l'anticyclone Groenlandais)\n",
    "</p>\n",
    "<p><b>3) </b>Identifier le régime de Dorsale Atlantique\n",
    "</p>\n",
    "<p><b>4) </b>Identifier le régime de Blocage Scandinave\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Réponse dans la cellule de code ci-dessous </b>\n",
    "<p>\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if domain_name=='natl' and season_name=='winter':\n",
    "    r1=input(\"Parmi les propositions suivantes nommer le régime 1 : NAO+ / NAO- / Dorsale Atl / Blocage \")\n",
    "    r2=input(\"Parmi les propositions suivantes nommer le régime 2 : NAO+ / NAO- / Dorsale Atl / Blocage \")\n",
    "    r3=input(\"Parmi les propositions suivantes nommer le régime 3 : NAO+ / NAO- / Dorsale Atl / Blocage \")\n",
    "    r4=input(\"Parmi les propositions suivantes nommer le régime 4 : NAO+ / NAO- / Dorsale Atl / Blocage \")\n",
    "\n",
    "if domain_name=='npac' and season_name=='winter':\n",
    "    r1=input(\"Parmi les propositions suivantes nommer le régime 1 : Alaskan Ridge / Arctic Low / Arctic High / Pac Trough \")\n",
    "    r2=input(\"Parmi les propositions suivantes nommer le régime 2 : Alaskan Ridge / Arctic Low / Arctic High / Pac Trough \")\n",
    "    r3=input(\"Parmi les propositions suivantes nommer le régime 3 : Alaskan Ridge / Arctic Low / Arctic High / Pac Trough \")\n",
    "    r4=input(\"Parmi les propositions suivantes nommer le régime 4 : Alaskan Ridge / Arctic Low / Arctic High / Pac Trough \")\n",
    "\n",
    "if domain_name=='natl' and season_name=='summer':\n",
    "    r1=input(\"Parmi les propositions suivantes nommer le régime 1 : Zonal / Anticyclone Gro / Blocage été / Thalweg Atl \")\n",
    "    r2=input(\"Parmi les propositions suivantes nommer le régime 2 : Zonal / Anticyclone Gro / Blocage été / Thalweg Atl \")\n",
    "    r3=input(\"Parmi les propositions suivantes nommer le régime 3 : Zonal / Anticyclone Gro / Blocage été / Thalweg Atl \")\n",
    "    r4=input(\"Parmi les propositions suivantes nommer le régime 4 : Zonal / Anticyclone Gro / Blocage été / Thalweg Atl \")\n",
    "\n",
    "if domain_name=='npac' and season_name=='summer':\n",
    "    r1=input(\"Nommer le régime 1 : \")\n",
    "    r2=input(\"Nommer le régime 2 : \")\n",
    "    r3=input(\"Nommer le régime 3 : \")\n",
    "    r4=input(\"Nommer le régime 4 : \")\n",
    "\n",
    "regime=[r1, r2, r3, r4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>Question : </b>\n",
    "<p><b>1) </b>Pour chaque régime, indiquer la circulation dominante (vents) associée sur l’Europe de l’ouest (Grande Bretagne-Benelux-Allemagne-France- Espagne-Suisse-Italie).</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Réponse : </b>\n",
    "<p>\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etape 6 : temps sensible associé aux régimes de temps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "<b>Etape à faire uniquement pour les régimes de l'Atlantique nord (données non disponibles ailleurs). </b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Ouverture du fichier de réanalyses quotidiennes ERA5 de température à 2m (T2m) et de précipitations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_t0    = xr.open_dataset(dir_data+'t2m_eur_19790101_20191231.nc')\n",
    "data_tp0    = xr.open_dataset(dir_data+'tp_eur_19790101_20191231.nc')\n",
    "print(data_t0)\n",
    "print(data_tp0)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Sélection de la sous-periode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if season_name == 'winter':\n",
    "    d1='1979-12-01T09'\n",
    "    d2='2018-03-31T09'\n",
    "\n",
    "if season_name == 'summer':\n",
    "    d1='1979-06-01T09'\n",
    "    d2='2018-09-30T09'\n",
    "\n",
    "    # Date index from startday to endday\n",
    "d = pd.date_range(d1, d2, freq='D')\n",
    "print(d)\n",
    "\n",
    "# Remove 29/02\n",
    "#mask = is_leap_and_29Feb(d)\n",
    "#d=d[~mask]\n",
    "#print(d)\n",
    "\n",
    "# Select Season\n",
    "if season_name == 'winter':\n",
    "    mm=np.any([d.month==12,d.month==1,d.month==2,d.month==3],axis=0)\n",
    "if season_name == 'summer':\n",
    "    mm=np.any([d.month==6,d.month==7,d.month==8,d.month==9],axis=0)\n",
    "\n",
    "dd2=d[mm]\n",
    "print(dd2)\n",
    "\n",
    "data_t    = xr.open_dataset(dir_data+'t2m_eur_19790101_20191231.nc').sel(time=slice(d1,d2))\n",
    "data_t    = data_t.sel(time=dd2)\n",
    "data_tp    = xr.open_dataset(dir_data+'tp_eur_19790101_20191231.nc').sel(time=slice(d1,d2))\n",
    "data_tp    = data_tp.sel(time=dd2)\n",
    "\n",
    "\n",
    "print(data_t0)\n",
    "print(data_tp0)\n",
    "print(data_t)\n",
    "print(data_tp)\n",
    "\n",
    "lat_t  = data_t.latitude.values\n",
    "lon_t  = data_t.longitude.values\n",
    "time_t  = data_t.time.values"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Calcul des anomalies quotidiennes de T2m et de précipitations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(' ----- Computing daily anomalies of T2m ----- ')\n",
    "data_t_anom = data_t.groupby('time.dayofyear') - data_t.groupby('time.dayofyear').mean('time')\n",
    "print(' ----- Computing daily anomalies of precipitation ----- ')\n",
    "data_tp_anom = data_tp.groupby('time.dayofyear') - data_tp.groupby('time.dayofyear').mean('time')\n",
    "\n",
    "t2m_anom=data_t_anom['t2m']\n",
    "tp_anom=data_tp_anom['tp']*1000\n",
    "\n",
    "print(t2m_anom.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Calcul des composites de T2m et de précipitations pour chaque cluster. Pour chaque cluster, on fait la moyenne du champ pour les jours qui \"tombent\" dans ce cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(cluster.shape)\n",
    "\n",
    "if season_name=='winter':\n",
    "    dd1='1979-12-01'\n",
    "    dd2='2018-03-31'\n",
    "    \n",
    "if season_name=='summer':\n",
    "    dd1='1979-06-01'\n",
    "    dd2='2018-09-30'\n",
    "\n",
    "index_y=np.all([dates2>=dd1, dates2<=dd2], axis=0)\n",
    "cluster_t=cluster[index_y]\n",
    "print(cluster_t.shape)\n",
    "\n",
    "id_cluster1_t=np.any([cluster_t==0],axis=0)\n",
    "id_cluster2_t=np.any([cluster_t==1],axis=0)\n",
    "id_cluster3_t=np.any([cluster_t==2],axis=0)\n",
    "id_cluster4_t=np.any([cluster_t==3],axis=0)\n",
    "\n",
    "mean_c1_anom_t = t2m_anom[id_cluster1_t,:,:].mean(axis=0)\n",
    "mean_c2_anom_t = t2m_anom[id_cluster2_t,:,:].mean(axis=0)\n",
    "mean_c3_anom_t = t2m_anom[id_cluster3_t,:,:].mean(axis=0)\n",
    "mean_c4_anom_t = t2m_anom[id_cluster4_t,:,:].mean(axis=0)\n",
    "\n",
    "mean_c1_anom_tp = tp_anom[id_cluster1_t,:,:].mean(axis=0)\n",
    "mean_c2_anom_tp = tp_anom[id_cluster2_t,:,:].mean(axis=0)\n",
    "mean_c3_anom_tp = tp_anom[id_cluster3_t,:,:].mean(axis=0)\n",
    "mean_c4_anom_tp = tp_anom[id_cluster4_t,:,:].mean(axis=0)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Tracé des composites des anomalies de T2m pour chaque régime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#projection2=ccrs.EuroPP()\n",
    "#projection2=ccrs.PlateCarree()\n",
    "projection2=ccrs.NearsidePerspective(central_longitude=5.0, central_latitude=55.0)\n",
    "bounds = [(-20, 30, 30, 80)]\n",
    "\n",
    "levs_t_anom = np.linspace(-4, 4, 21)\n",
    "\n",
    "fig = plt.figure(figsize=(15, 10))\n",
    "fig.suptitle('Composites of 2-meter temperature anomalies : ERA5 DJFM 1979-2018', fontsize=16)\n",
    "\n",
    "ax = fig.add_subplot(2, 2, 1, projection=projection2)\n",
    "plt.title(regime[0], fontsize=10, loc='center', color=couleur[0])\n",
    "ax.coastlines()\n",
    "ax.set_extent(*bounds, crs=ccrs.PlateCarree())\n",
    "boundary_path = make_boundary_path(lon_t, lat_t)\n",
    "ax.set_boundary(boundary_path, transform=ccrs.PlateCarree())\n",
    "cf = ax.contourf(lon_t, lat_t, mean_c1_anom_t, levels=levs_t_anom, \n",
    "                 cmap=cmap2, extend='both', transform=ccrs.PlateCarree())\n",
    "ax.clabel(c, inline=1, fmt='%4.0f', fontsize=10)\n",
    "cb = fig.colorbar(cf, orientation='vertical', aspect=65, shrink=1, pad=0.05, extendrect='True')\n",
    "cb.set_label('Anomaly (°C)', fontsize=12)\n",
    "\n",
    "ax = fig.add_subplot(2, 2, 2, projection=projection2)\n",
    "plt.title(regime[1], fontsize=10, loc='center', color=couleur[1])\n",
    "ax.coastlines()\n",
    "ax.set_extent(*bounds, crs=ccrs.PlateCarree())\n",
    "boundary_path = make_boundary_path(lon_t, lat_t)\n",
    "ax.set_boundary(boundary_path, transform=ccrs.PlateCarree())\n",
    "cf = ax.contourf(lon_t, lat_t, mean_c2_anom_t, levels=levs_t_anom, \n",
    "                 cmap=cmap2, extend='both', transform=ccrs.PlateCarree())\n",
    "ax.clabel(c, inline=1, fmt='%4.0f', fontsize=10)\n",
    "cb = fig.colorbar(cf, orientation='vertical', aspect=65, shrink=1, pad=0.05, extendrect='True')\n",
    "cb.set_label('Anomaly (°C)', fontsize=12)\n",
    "\n",
    "ax = fig.add_subplot(2, 2, 3, projection=projection2)\n",
    "plt.title(regime[2], fontsize=10, loc='center', color=couleur[2])\n",
    "ax.coastlines()\n",
    "ax.set_extent(*bounds, crs=ccrs.PlateCarree())\n",
    "boundary_path = make_boundary_path(lon_t, lat_t)\n",
    "ax.set_boundary(boundary_path, transform=ccrs.PlateCarree())\n",
    "cf = ax.contourf(lon_t, lat_t, mean_c3_anom_t, levels=levs_t_anom, \n",
    "                 cmap=cmap2, extend='both', transform=ccrs.PlateCarree())\n",
    "ax.clabel(c, inline=1, fmt='%4.0f', fontsize=10)\n",
    "cb = fig.colorbar(cf, orientation='vertical', aspect=65, shrink=1, pad=0.05, extendrect='True')\n",
    "cb.set_label('Anomaly (°C)', fontsize=12)\n",
    "\n",
    "ax = fig.add_subplot(2, 2, 4, projection=projection2)\n",
    "plt.title(regime[3], fontsize=10, loc='center', color=couleur[3])\n",
    "ax.coastlines()\n",
    "ax.set_extent(*bounds, crs=ccrs.PlateCarree())\n",
    "boundary_path = make_boundary_path(lon_t, lat_t)\n",
    "ax.set_boundary(boundary_path, transform=ccrs.PlateCarree())\n",
    "cf = ax.contourf(lon_t, lat_t, mean_c4_anom_t, levels=levs_t_anom, \n",
    "                 cmap=cmap2, extend='both', transform=ccrs.PlateCarree())\n",
    "ax.clabel(c, inline=1, fmt='%4.0f', fontsize=10)\n",
    "cb = fig.colorbar(cf, orientation='vertical', aspect=65, shrink=1, pad=0.05, extendrect='True')\n",
    "cb.set_label('Anomaly (°C)', fontsize=12)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "figname=dir_figs+varname+'_'+domain_name+'_t2m_composite_DJFM'\n",
    "fig.savefig(figname+'.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Tracé des composites des anomalies de précipitations pour chaque régime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cmap3='BrBG'\n",
    "\n",
    "levs_tp_anom = np.linspace(-1, 1, 21)\n",
    "\n",
    "fig = plt.figure(figsize=(15, 10))\n",
    "fig.suptitle('Composites of precipitation anomalies : ERA5 1979-2018', fontsize=16)\n",
    "\n",
    "ax = fig.add_subplot(2, 2, 1, projection=projection2)\n",
    "plt.title(regime[0], fontsize=10, loc='center', color=couleur[0])\n",
    "ax.coastlines()\n",
    "ax.set_extent(*bounds, crs=ccrs.PlateCarree())\n",
    "boundary_path = make_boundary_path(lon_t, lat_t)\n",
    "ax.set_boundary(boundary_path, transform=ccrs.PlateCarree())\n",
    "cf = ax.contourf(lon_t, lat_t, mean_c1_anom_tp, levels=levs_tp_anom, \n",
    "                 cmap=cmap3, extend='both', transform=ccrs.PlateCarree())\n",
    "ax.clabel(c, inline=1, fmt='%4.0f', fontsize=10)\n",
    "cb = fig.colorbar(cf, orientation='vertical', aspect=65, shrink=1, pad=0.05, extendrect='True')\n",
    "cb.set_label('Anomaly (mm/day)', fontsize=12)\n",
    "\n",
    "ax = fig.add_subplot(2, 2, 2, projection=projection2)\n",
    "plt.title(regime[1], fontsize=10, loc='center', color=couleur[1])\n",
    "ax.coastlines()\n",
    "ax.set_extent(*bounds, crs=ccrs.PlateCarree())\n",
    "boundary_path = make_boundary_path(lon_t, lat_t)\n",
    "ax.set_boundary(boundary_path, transform=ccrs.PlateCarree())\n",
    "cf = ax.contourf(lon_t, lat_t, mean_c2_anom_tp, levels=levs_tp_anom, \n",
    "                 cmap=cmap3, extend='both', transform=ccrs.PlateCarree())\n",
    "ax.clabel(c, inline=1, fmt='%4.0f', fontsize=10)\n",
    "cb = fig.colorbar(cf, orientation='vertical', aspect=65, shrink=1, pad=0.05, extendrect='True')\n",
    "cb.set_label('Anomaly (mm/day)', fontsize=12)\n",
    "\n",
    "ax = fig.add_subplot(2, 2, 3, projection=projection2)\n",
    "plt.title(regime[2], fontsize=10, loc='center', color=couleur[2])\n",
    "ax.coastlines()\n",
    "ax.set_extent(*bounds, crs=ccrs.PlateCarree())\n",
    "boundary_path = make_boundary_path(lon_t, lat_t)\n",
    "ax.set_boundary(boundary_path, transform=ccrs.PlateCarree())\n",
    "cf = ax.contourf(lon_t, lat_t, mean_c3_anom_tp, levels=levs_tp_anom, \n",
    "                 cmap=cmap3, extend='both', transform=ccrs.PlateCarree())\n",
    "ax.clabel(c, inline=1, fmt='%4.0f', fontsize=10)\n",
    "cb = fig.colorbar(cf, orientation='vertical', aspect=65, shrink=1, pad=0.05, extendrect='True')\n",
    "cb.set_label('Anomaly (mm/day)', fontsize=12)\n",
    "\n",
    "ax = fig.add_subplot(2, 2, 4, projection=projection2)\n",
    "plt.title(regime[3], fontsize=10, loc='center', color=couleur[3])\n",
    "ax.coastlines()\n",
    "ax.set_extent(*bounds, crs=ccrs.PlateCarree())\n",
    "boundary_path = make_boundary_path(lon_t, lat_t)\n",
    "ax.set_boundary(boundary_path, transform=ccrs.PlateCarree())\n",
    "cf = ax.contourf(lon_t, lat_t, mean_c4_anom_tp, levels=levs_tp_anom, \n",
    "                 cmap=cmap3, extend='both', transform=ccrs.PlateCarree())\n",
    "ax.clabel(c, inline=1, fmt='%4.0f', fontsize=10)\n",
    "cb = fig.colorbar(cf, orientation='vertical', aspect=65, shrink=1, pad=0.05, extendrect='True')\n",
    "cb.set_label('Anomaly (mm/day)', fontsize=12)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "figname=dir_figs+varname+'_'+domain_name+'_precip_composite_DJFM'\n",
    "fig.savefig(figname+'.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>Question : </b>\n",
    "<p><b>1) </b>Préciser l’impact de chaque régime en temps sensible (température/précipitation) sur l'Europe de l'ouest. Ces impacts sont-ils spatialement homogènes pour tous les régimes ? Sinon, préciser les disparités régionales. S'aider éventuellement des documents suivants :\n",
    "\n",
    "http://www.cerfacs.fr/~cassou/Regimes/Images/regime_mean_europe.gif\n",
    "http://blogs.reading.ac.uk/weather-and-climate-at-reading/files/2020/02/RLee-Fig-1.png</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Réponse : </b>\n",
    "<p>\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etape 7 : étude des occurrences saisonnières des régimes"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Calcul du nombre d'occurences de régimes par saison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Find indexes for end of season\n",
    "time_str = [x for x in range(len(dates2))]\n",
    "date_str = [x for x in range(len(dates2))]\n",
    "for i in range(len(dates2)):\n",
    "    time_str[i] = str(dates2[i])\n",
    "    date_str[i] = time_str[i][5:10]\n",
    "\n",
    "if season_name == 'winter':\n",
    "    index_end = [i for i, value in enumerate(date_str) if value == '03-31']\n",
    "\n",
    "if season_name == 'summer':\n",
    "    index_end = [i for i, value in enumerate(date_str) if value == '08-31']\n",
    "    \n",
    "print(index_end)\n",
    "print(len(index_end))\n",
    "\n",
    "seasons= [x for x in range(int(season1),int(season2)+1)]\n",
    "cl1_count=np.zeros(len(index_end))\n",
    "cl2_count=np.zeros(len(index_end))\n",
    "cl3_count=np.zeros(len(index_end))\n",
    "cl4_count=np.zeros(len(index_end))\n",
    "\n",
    "# Cluster1\n",
    "cl1_count[0]=list(cluster[0:index_end[0]+1]).count(0)\n",
    "for i in range(1,len(index_end)):\n",
    "    cl1_count[i]=list(cluster[index_end[i-1]+1:index_end[i]+1]).count(0)\n",
    "\n",
    "# Cluster2\n",
    "cl2_count[0]=list(cluster[0:index_end[0]+1]).count(1)\n",
    "for i in range(1,len(index_end)):\n",
    "    cl2_count[i]=list(cluster[index_end[i-1]+1:index_end[i]+1]).count(1)\n",
    "\n",
    "# Cluster3\n",
    "cl3_count[0]=list(cluster[0:index_end[0]+1]).count(2)\n",
    "for i in range(1,len(index_end)):\n",
    "    cl3_count[i]=list(cluster[index_end[i-1]+1:index_end[i]+1]).count(2)\n",
    "\n",
    "# Cluster4\n",
    "cl4_count[0]=list(cluster[0:index_end[0]+1]).count(3)\n",
    "for i in range(1,len(index_end)):\n",
    "    cl4_count[i]=list(cluster[index_end[i-1]+1:index_end[i]+1]).count(3)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Tracé des occurences de régimes par saison et des tendances linéaires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# calculate trends\n",
    "X = np.reshape(seasons, (len(seasons), 1))\n",
    "\n",
    "y = cl1_count\n",
    "model = LinearRegression()\n",
    "model.fit(X, cl1_count)\n",
    "trend_cl1 = model.predict(X)\n",
    "\n",
    "y = cl2_count\n",
    "model = LinearRegression()\n",
    "model.fit(X, cl2_count)\n",
    "trend_cl2 = model.predict(X)\n",
    "\n",
    "y = cl3_count\n",
    "model = LinearRegression()\n",
    "model.fit(X, cl3_count)\n",
    "trend_cl3 = model.predict(X)\n",
    "\n",
    "y = cl4_count\n",
    "model = LinearRegression()\n",
    "model.fit(X, cl4_count)\n",
    "trend_cl4 = model.predict(X)\n",
    "\n",
    "def plot_regimes_occ(ax):\n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel('Number of days')\n",
    "    plt.xlim(int(season1), int(season2))\n",
    "    plt.ylim(0, 85)\n",
    "    plt.axvline(1960, color='grey', linestyle='--')\n",
    "    plt.axvline(1970, color='grey', linestyle='--')\n",
    "    plt.axvline(1980, color='grey', linestyle='--')\n",
    "    plt.axvline(1990, color='grey', linestyle='--')\n",
    "    plt.axvline(2000, color='grey', linestyle='--')\n",
    "    plt.axvline(2010, color='grey', linestyle='--')\n",
    "    return ax\n",
    "\n",
    "fig = plt.figure(figsize=(15, 15))\n",
    "fig.suptitle('Weather regime occurrences : '\n",
    "             +var_text+' - '+domain+' - '+season+ ' '+season1+'-'+season2, fontsize=16)\n",
    "ax = fig.add_subplot(2, 2, 1)\n",
    "plt.title(regime[0]+' (mean = '+str(int(cl1_count.mean()))+'d)', fontsize=10, loc='center', color=couleur[0])\n",
    "plot_regimes_occ(ax)\n",
    "colormat=np.where(cl1_count>cl1_count.mean(), 'red','blue')\n",
    "plt.bar(seasons,cl1_count-cl1_count.mean(), bottom=cl1_count.mean(), color=colormat, linewidth=1)\n",
    "plt.plot(seasons,trend_cl1, color='k', linewidth=1)\n",
    "\n",
    "ax = fig.add_subplot(2, 2, 2)\n",
    "plt.title(regime[1]+' (mean = '+str(int(cl2_count.mean()))+'d)', fontsize=10, loc='center', color=couleur[1])\n",
    "plot_regimes_occ(ax)\n",
    "colormat=np.where(cl2_count>cl2_count.mean(), 'red','blue')\n",
    "plt.bar(seasons,cl2_count-cl2_count.mean(), bottom=cl2_count.mean(), color=colormat, linewidth=1)\n",
    "plt.plot(seasons,trend_cl2, color='k', linewidth=1)\n",
    "\n",
    "ax = fig.add_subplot(2, 2, 3)\n",
    "plt.title(regime[2]+' (mean = '+str(int(cl3_count.mean()))+'d)', fontsize=10, loc='center', color=couleur[2])\n",
    "plot_regimes_occ(ax)\n",
    "colormat=np.where(cl3_count>cl3_count.mean(), 'red','blue')\n",
    "plt.bar(seasons,cl3_count-cl3_count.mean(), bottom=cl3_count.mean(), color=colormat, linewidth=1)\n",
    "plt.plot(seasons,trend_cl3, color='k', linewidth=1)\n",
    "\n",
    "ax = fig.add_subplot(2, 2, 4)\n",
    "plt.title(regime[3]+' (mean = '+str(int(cl4_count.mean()))+'d)', fontsize=10, loc='center', color=couleur[3])\n",
    "plot_regimes_occ(ax)\n",
    "colormat=np.where(cl4_count>cl4_count.mean(), 'red','blue')\n",
    "plt.bar(seasons,cl4_count-cl4_count.mean(), bottom=cl4_count.mean(), color=colormat, linewidth=1)\n",
    "plt.plot(seasons,trend_cl4, color='k', linewidth=1)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "figname=dir_figs+varname+'_'+domain_name+'_'+season_name+'_regimes_occurrence'\n",
    "fig.savefig(figname+'.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>Questions : </b>\n",
    "<p><b>1) </b>Quels régimes semblent caractérisés par des tendances linéaires sur la période totale des données ?</p>  \n",
    "<p><b>2) </b>Pour les régimes avec tendance, identifier 2 hivers particuliers qui s’opposent à cette tendance ou au contraire qui accentuent cette tendance.\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Réponses : </b>\n",
    "<p>\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>Question codage : classement des occurences de régimes </b>\n",
    "<p>Le tableau seasons contient les saisons de l'étude. Le tableau regime fait la correspondance entre le numéro de régime et le nom du régime. Les tableaux cl1_count, cl2_count, cl3_count et cl4_count correspondent aux nombres d'occurences par saison de chaque régime de temps.\n",
    "\n",
    "- Exploiter ces tableaux pour classer, pour chaque régime, les saisons par ordre croissant d'occurence de régime.\n",
    "\n",
    "Indication : les fonctions suivantes pourront s'avérer utiles :\n",
    "- https://numpy.org/doc/stable/reference/generated/numpy.sort.html\n",
    "- https://numpy.org/doc/stable/reference/generated/numpy.argsort.html\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Réponse dans la cellule de code ci-dessous : </b>\n",
    "<p>\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(seasons)\n",
    "print(regime)\n",
    "print(cl1_count)\n",
    "print(cl2_count)\n",
    "print(cl3_count)\n",
    "print(cl4_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>Questions : </b>\n",
    "<p><b>1) </b>Quels sont les 3 hivers avec le plus (resp. moins) de régimes NAO+ ?</p>\n",
    "<p><b>2) </b>Quels sont les 3 hivers avec le plus (resp. moins) de régimes NAO- ?</p>\n",
    "<p><b>3) </b>Citer un hiver récent caractérisé par un nombre important de situations de blocage scandinave. ?</p>\n",
    "<p><b>4) </b>Citer un hiver récent caractérisé par un nombre important de situations de dorsale Atlantique.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Réponses : </b>\n",
    "<p>\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etape 8 : corrélation régimes/indices océaniques (Nino 3.4, TNA, AMV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "<b>Etape à faire uniquement pour les régimes d'hiver (code à adapter pour l'été). </b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "NINO34 : indice d’anomalie de température de surface de la mer (SST) sur le Pacifique central (5N-5S, 170W-120W) et qui caractérise l’ENSO (El Nino Southern Oscillation).\n",
    "\n",
    "TNA (Tropical Northern Atlantic) : indice d’anomalie de SST moyennées sur tout l’Atlantique nord tropical (5.5N-23.5N, 15W-57.5W).\n",
    "\n",
    "AMV/AMO (Atlantic Multi-decadal Variability/Oscillation): indice d’anomalie de SST moyennées sur l’ensemble de l’Atlantique Nord (0N-65N, 80W-0E).\n",
    "\n",
    "https://www.esrl.noaa.gov/psd/data/climateindices/list/\n",
    "\n",
    "A partir des séries mensuelles on construit des moyennes JFM et on normalise les séries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#nino=np.loadtxt(dir_data+'nina34.1958-2018.data')\n",
    "nino=np.loadtxt(dir_data+'nino34.anom.1958-2018.data')\n",
    "tna=np.loadtxt(dir_data+'tna.1958-2018.data')\n",
    "amo=np.loadtxt(dir_data+'amon.us.1958-2018.data')\n",
    "\n",
    "dates = pd.date_range(season1, '2019', freq='M')\n",
    "\n",
    "nino=nino[0:,1:]\n",
    "nino=nino.flatten()\n",
    "nino = Series(nino, index=dates)\n",
    "print(nino)\n",
    "nino=nino.rolling(window=3, center=False).mean()\n",
    "nino=nino[nino.index.month == 3]\n",
    "nino=(nino-nino.mean())/nino.std()\n",
    "print(nino)\n",
    "\n",
    "tna=tna[0:,1:]\n",
    "tna=tna.flatten()\n",
    "tna = Series(tna, index=dates)\n",
    "print(tna)\n",
    "tna=tna.rolling(window=3, center=False).mean()\n",
    "tna=tna[tna.index.month == 3]\n",
    "tna=(tna-tna.mean())/tna.std()\n",
    "print(tna)\n",
    "\n",
    "amo=amo[0:,1:]\n",
    "amo=amo.flatten()\n",
    "amo = Series(amo, index=dates)\n",
    "print(amo)\n",
    "amo=amo.rolling(window=3, center=False).mean()\n",
    "amo=amo[amo.index.month == 3]\n",
    "amo=(amo-amo.mean())/amo.std()\n",
    "print(amo)\n",
    "\n",
    "years=np.arange(int(season1),2019)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Fonction de tracé des séries annuelles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_ocean(ax):\n",
    "    plt.title('Data : https://www.esrl.noaa.gov/psd/data/climateindices/list/' , fontsize=12, color='grey')\n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel('SST anomaly (K)')\n",
    "    plt.xlim(int(season1), 2018)\n",
    "    plt.axvline(1960, color='grey', linestyle='--', linewidth=0.5)\n",
    "    plt.axvline(1970, color='grey', linestyle='--', linewidth=0.5)\n",
    "    plt.axvline(1980, color='grey', linestyle='--', linewidth=0.5)\n",
    "    plt.axvline(1990, color='grey', linestyle='--', linewidth=0.5)\n",
    "    plt.axvline(2000, color='grey', linestyle='--', linewidth=0.5)\n",
    "    plt.axvline(2010, color='grey', linestyle='--', linewidth=0.5)\n",
    "\n",
    "    plt.axhline(0, color='k')\n",
    "    plt.axhline(1, color='grey', linestyle='--', linewidth=0.5)\n",
    "    plt.axhline(1.5, color='grey', linestyle='--', linewidth=0.5)\n",
    "    plt.axhline(2, color='grey', linestyle='--', linewidth=0.5)\n",
    "    plt.axhline(-1, color='grey', linestyle='--', linewidth=0.5)\n",
    "    plt.axhline(-1.5, color='grey', linestyle='--', linewidth=0.5)\n",
    "    plt.axhline(-2, color='grey', linestyle='--', linewidth=0.5)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Tracé de la série AMO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(17, 10))\n",
    "fig.suptitle('AMO SST anomaly - JFM mean', fontsize=16)\n",
    "plot_ocean(ax)\n",
    "plt.plot(years, amo, color='black', linewidth=2)\n",
    "plt.fill_between(years, amo, where=amo > 0, facecolor='red', interpolate=True) \n",
    "plt.fill_between(years, amo, where=amo < 0, facecolor='blue', interpolate=True) \n",
    "plt.show()\n",
    "\n",
    "figname=dir_figs+varname+'_'+domain_name+'_'+season_name+'_AMO'\n",
    "fig.savefig(figname+'.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Tracé de la série TNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(17, 10))\n",
    "fig.suptitle('TNA SST anomaly - JFM mean', fontsize=16)\n",
    "plot_ocean(ax)\n",
    "plt.plot(years, tna, color='black', linewidth=2)\n",
    "plt.fill_between(years, tna, where=tna > 0, facecolor='red', interpolate=True) \n",
    "plt.fill_between(years, tna, where=tna < 0, facecolor='blue', interpolate=True) \n",
    "\n",
    "plt.show()\n",
    "\n",
    "figname=dir_figs+varname+'_'+domain_name+'_'+season_name+'_TNA'\n",
    "fig.savefig(figname+'.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Tracé de la série Nino 3.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(17, 10))\n",
    "fig.suptitle('Nino 3.4 SST anomaly - JFM mean', fontsize=16)\n",
    "plot_ocean(ax)\n",
    "plt.plot(years, nino, color='black', linewidth=2)\n",
    "plt.fill_between(years, nino, where=nino > 0, facecolor='red', interpolate=True) \n",
    "plt.fill_between(years, nino, where=nino < 0, facecolor='blue', interpolate=True)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "figname=dir_figs+varname+'_'+domain_name+'_'+season_name+'_Nino'\n",
    "fig.savefig(figname+'.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Tracé des séries AMO, TNA, Nino 3.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(17, 10))\n",
    "fig.suptitle('Oceanic indices - Annual mean', fontsize=16)\n",
    "plt.title('Data : https://www.esrl.noaa.gov/psd/data/climateindices/list/' , fontsize=12, color='grey')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Oceanic index')\n",
    "ax = nino.plot(color='red', linewidth=2, label='Niño 3.4 SST anomaly - JFM mean')\n",
    "ax = tna.plot(color='blue', linewidth=2, label='TNA SST anomaly - JFM mean')\n",
    "ax = amo.plot(color='green', linewidth=2, label='AMO SST anomaly - JFM mean')\n",
    "\n",
    "plt.axhline(0, color='k')\n",
    "plt.axhline(1, color='grey', linestyle='--', linewidth=0.5)\n",
    "plt.axhline(1.5, color='grey', linestyle='--', linewidth=0.5)\n",
    "plt.axhline(2, color='grey', linestyle='--', linewidth=0.5)\n",
    "plt.axhline(-1, color='grey', linestyle='--', linewidth=0.5)\n",
    "plt.axhline(-1.5, color='grey', linestyle='--', linewidth=0.5)\n",
    "plt.axhline(-2, color='grey', linestyle='--', linewidth=0.5)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "figname=dir_figs+varname+'_'+domain_name+'_'+season_name+'_cor_regimes_ocean'\n",
    "fig.savefig(figname+'.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Calcul des anomalies d'occurences de régimes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cl1_count_a=((cl1_count-cl1_count.mean())/cl1_count.mean())*100\n",
    "cl2_count_a=((cl2_count-cl2_count.mean())/cl2_count.mean())*100\n",
    "cl3_count_a=((cl3_count-cl3_count.mean())/cl3_count.mean())*100\n",
    "cl4_count_a=((cl4_count-cl4_count.mean())/cl4_count.mean())*100\n",
    "print(cl1_count_a)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Calcul des corrélations entre les anomalies d'occurences de régimes et les indices océaniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cor_nino1=np.corrcoef(nino, cl1_count_a)\n",
    "cor_nino2=np.corrcoef(nino, cl2_count_a)\n",
    "cor_nino3=np.corrcoef(nino, cl3_count_a)\n",
    "cor_nino4=np.corrcoef(nino, cl4_count_a)\n",
    "\n",
    "print(\"NINO34 correlation\")\n",
    "print(regime[0]+\" : \", cor_nino1[1,0])\n",
    "print(regime[1]+\" : \", cor_nino2[1,0])\n",
    "print(regime[2]+\" : \", cor_nino3[1,0])\n",
    "print(regime[3]+\" : \", cor_nino4[1,0])\n",
    "\n",
    "cor_tna1=np.corrcoef(tna, cl1_count_a)\n",
    "cor_tna2=np.corrcoef(tna, cl2_count_a)\n",
    "cor_tna3=np.corrcoef(tna, cl3_count_a)\n",
    "cor_tna4=np.corrcoef(tna, cl4_count_a)\n",
    "print(\"TNA correlation\")\n",
    "print(regime[0]+\" : \", cor_tna1[1,0])\n",
    "print(regime[1]+\" : \", cor_tna2[1,0])\n",
    "print(regime[2]+\" : \", cor_tna3[1,0])\n",
    "print(regime[3]+\" : \", cor_tna4[1,0])\n",
    "\n",
    "cor_amo1=np.corrcoef(amo, cl1_count_a)\n",
    "cor_amo2=np.corrcoef(amo, cl2_count_a)\n",
    "cor_amo3=np.corrcoef(amo, cl3_count_a)\n",
    "cor_amo4=np.corrcoef(amo, cl4_count_a)\n",
    "print(\"AMO correlation\")\n",
    "print(regime[0]+\" : \", cor_amo1[1,0])\n",
    "print(regime[1]+\" : \", cor_amo2[1,0])\n",
    "print(regime[2]+\" : \", cor_amo3[1,0])\n",
    "print(regime[3]+\" : \", cor_amo4[1,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>Question : </b>\n",
    "<p><b>1) </b>Quelles sont les corrélations les plus fortes entre régimes de temps et indices océaniques en hiver ?</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Réponse : </b>\n",
    "<p>\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etape 9 : retour sur une saison particulière"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Choix de la saison (Attention, pour un hiver N-N+1, entrer N)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if season_name == 'winter':\n",
    "    choix=input('hiver (pour un hiver N-N+1, entrer N) : ')\n",
    "    leap_year=calendar.isleap(int(choix)+1)\n",
    "    date1=choix+'-12-01'\n",
    "    idx_date1=dates2.get_loc(date1, method ='ffill')\n",
    "    if leap_year:\n",
    "        print('Année bisextile')\n",
    "        idx_date2=idx_date1+122\n",
    "    else:\n",
    "        idx_date2=idx_date1+121\n",
    "    \n",
    "if season_name == 'summer':\n",
    "    choix=input('été ? ')\n",
    "    date1=choix+'-06-01'\n",
    "    idx_date1=dates2.get_loc(date1, method ='ffill')\n",
    "    idx_date2=idx_date1+121"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Gestion des dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "time=dates2[idx_date1:idx_date2]\n",
    "print(time.shape)\n",
    "\n",
    "date1=str(time[0])[0:10]\n",
    "date2=str(time[-1])[0:10]\n",
    "print(date1)\n",
    "print(date2)\n",
    "\n",
    "time_str = [x for x in range(len(time))]\n",
    "date_str = [x for x in range(len(time))]\n",
    "date_str_title = [x for x in range(len(time))]\n",
    "\n",
    "for i in range(len(time)):\n",
    "    time_str[i] = str(time[i])\n",
    "    date_str_title[i] = time_str[i][0:10]\t\n",
    "    date_str[i] = time_str[i][5:10]\n",
    "    \n",
    "leap_year=calendar.isleap(int(time_str[-1][0:4]))\n",
    "if leap_year:\n",
    "    print('Année bisextile')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Selection des données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_month    = data_season.sel(time=slice(date1,date2))\n",
    "z=data_month[varname]/var_div\n",
    "\n",
    "data_month_anom    = data_anom.sel(time=slice(date1,date2))\n",
    "z_anom=data_month_anom[varname]/var_div\n",
    "\n",
    "lat  = data_month_anom.lat.values\n",
    "lon  = data_month_anom.lon.values"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Titres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if varname=='zg500':\n",
    "    plt_title2 = 'Geopotential height anomaly ('+units+') at 500 hPa : '+ str(date1)+'-'+str(date2)\n",
    "\n",
    "if varname=='slp':\n",
    "    plt_title2 = 'Mean Sea Level Pressure anomaly ('+units+') : '+ str(date1)+'-'+str(date2)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Cartes individuelles (champ total + anomalie) avec attribution du cluster (fichiers png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(time)):\n",
    "    #print(date_str_title[i])\n",
    "    reg=cluster[idx_date1+i]\n",
    "    if reg==0:\n",
    "            composite  = mean_c1_anom\n",
    "            composite_mean = mean_c1\n",
    "    if reg==1:\n",
    "            composite  = mean_c2_anom\n",
    "            composite_mean = mean_c2\n",
    "    if reg==2:\n",
    "            composite  = mean_c3_anom\n",
    "            composite_mean = mean_c3\n",
    "    if reg==3:\n",
    "            composite  = mean_c4_anom\n",
    "            composite_mean = mean_c4\n",
    "            \n",
    "    fig = plt.figure(figsize=(15., 5.))\n",
    "    fig.suptitle(plt_title2, fontsize=16)\n",
    "    \n",
    "    ax = fig.add_subplot(1,2,1, projection=projection)\n",
    "    ax.set_title(date_str_title[i]+' '+regime[reg], fontsize=10, color=colors[idx_date1+i])\n",
    "    ax.coastlines()\n",
    "    ax.set_extent([lonW, lonE, latS, latN], crs=ccrs.PlateCarree())\n",
    "    boundary_path = make_boundary_path(lon, lat)\n",
    "    ax.set_boundary(boundary_path, transform=ccrs.PlateCarree())\n",
    "    ax.gridlines(crs=ccrs.PlateCarree(), linewidth=0.5, color='gray', alpha=0.5, linestyle='-')\n",
    "    p1 = ax.contourf(lon, lat, z_anom[i,:,:], levels2, transform=ccrs.PlateCarree(), cmap=cmap2, extend='both')\n",
    "    p2 = ax.contour(lon, lat, z_anom[i,:,:], levels2, colors='black', linewidths=0.2, transform=ccrs.PlateCarree())\n",
    "    p3 = ax.contour(lon, lat, z[i,:,:], levels1, colors='black', linewidths=1, transform=ccrs.PlateCarree())\n",
    "    ax.clabel(p3, inline=1, fmt='%4.0f', fontsize=10)\n",
    "    cb = fig.colorbar(p1, orientation='horizontal', aspect=65, shrink=0.5, pad=0.05, extendrect='True')\n",
    "    cb.set_label('Anomaly ('+units+')', fontsize=12)\n",
    "    \n",
    "    ax = fig.add_subplot(1,2,2, projection=projection)\n",
    "    plt.title(regime[reg]+' composite', fontsize=10, loc='center', color=colors[idx_date1+i])\n",
    "    ax.coastlines()\n",
    "    ax.set_extent([lonW, lonE, latS, latN], crs=ccrs.PlateCarree())\n",
    "    boundary_path = make_boundary_path(lon, lat)\n",
    "    ax.set_boundary(boundary_path, transform=ccrs.PlateCarree())\n",
    "    ax.gridlines(crs=ccrs.PlateCarree(), linewidth=0.5, color='gray', alpha=0.5, linestyle='-')\n",
    "    cf = ax.contourf(lons, lats, composite, levels=clevs_anom, \n",
    "                     cmap=cmap2, extend='both', transform=ccrs.PlateCarree())\n",
    "    c0 = ax.contour(lons, lats, composite, levels=clevs_anom, colors='black', linewidths=0.2,\n",
    "                    transform=ccrs.PlateCarree())\n",
    "    c = ax.contour(lons, lats, composite_mean, levels=clevs, colors='black', linewidths=1,\n",
    "                   transform=ccrs.PlateCarree())\n",
    "    ax.clabel(c, inline=1, fmt='%4.0f', fontsize=10)\n",
    "    cb = fig.colorbar(cf, orientation='horizontal', aspect=65, shrink=0.5, pad=0.05, extendrect='True')\n",
    "    cb.set_label('Anomaly ('+units+')', fontsize=12)\n",
    "\n",
    "    figname=dir_anim+varname+'_anom_cluster'+domain_name+'_'+season_name+'_'+date_str_title[i]\n",
    "    fig.savefig(figname+'.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "print('png files are in the animation folder, ready to make the animation')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Animation de la saison avec composite du régime en vis-à-vis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gif_filepath = dir_anim+varname+'_anom_cluster_'+domain_name+'_'+season_name+'_'+str(date1)+'-'+str(date2)+'.gif'\n",
    "make_animation()\n",
    "IPdisplay.Image(url=gif_filepath)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Vignettes d'anomalies quotidiennes avec attribution du cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "axes_class = (GeoAxes, dict(map_projection=projection))\n",
    "fig = plt.figure(figsize=(17,10))\n",
    "fig.suptitle(plt_title2, fontsize=16)\n",
    "\n",
    "axgr = AxesGrid(fig, 111, axes_class=axes_class,\n",
    "       nrows_ncols=(5, 6),\n",
    "       axes_pad=0.6,\n",
    "       cbar_location='right',\n",
    "       cbar_mode='single', # None/single/each\n",
    "       cbar_pad=0.2,\n",
    "       cbar_size='3%',\n",
    "       label_mode='')  # note the empty label_mode\n",
    "                   \n",
    "for i, ax in enumerate(axgr):\n",
    "    reg=cluster[idx_date1+i] # régime\n",
    "    ax.coastlines()\n",
    "    ax.set_extent([lonW, lonE, latS, latN], crs=ccrs.PlateCarree())\n",
    "    boundary_path = make_boundary_path(lon, lat)\n",
    "    ax.set_boundary(boundary_path, transform=ccrs.PlateCarree())\n",
    "    ax.gridlines(crs=ccrs.PlateCarree(), linewidth=0.5, color='gray', alpha=0.5, linestyle='-')\n",
    "    ax.set_title(date_str_title[i]+' '+regime[reg], fontsize=10, color=colors[idx_date1+i])\n",
    "    p1 = ax.contourf(lon, lat, z_anom[i,:,:], levels2, transform=ccrs.PlateCarree(), cmap=cmap2, extend='both')\n",
    "    p2 = ax.contour(lon, lat, z_anom[i,:,:], levels2, colors='black', linewidths=0.2,\n",
    "                    transform=ccrs.PlateCarree())\n",
    "    axgr.cbar_axes[i].colorbar(p1)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "figname=dir_figs+varname+'_anom_'+domain_name+'_'+season_name+'_cluster_'+str(date1)+'-'+str(date2)+'_1'\n",
    "fig.savefig(figname+'.png', bbox_inches='tight')\n",
    "\n",
    "#\n",
    "axes_class = (GeoAxes, dict(map_projection=projection))\n",
    "fig = plt.figure(figsize=(17,10))\n",
    "fig.suptitle(plt_title2, fontsize=16)\n",
    "\n",
    "axgr = AxesGrid(fig, 111, axes_class=axes_class,\n",
    "       nrows_ncols=(5, 6),\n",
    "       axes_pad=0.6,\n",
    "       cbar_location='right',\n",
    "       cbar_mode='single', # None/single/each\n",
    "       cbar_pad=0.2,\n",
    "       cbar_size='3%',\n",
    "       label_mode='')  # note the empty label_mode\n",
    "\n",
    "for i, ax in enumerate(axgr):\n",
    "    reg=cluster[idx_date1+30+i] # régime\n",
    "    ax.coastlines()\n",
    "    ax.set_extent([lonW, lonE, latS, latN], crs=ccrs.PlateCarree())\n",
    "    boundary_path = make_boundary_path(lon, lat)\n",
    "    ax.set_boundary(boundary_path, transform=ccrs.PlateCarree())\n",
    "    ax.gridlines(crs=ccrs.PlateCarree(), linewidth=0.5, color='gray', alpha=0.5, linestyle='-')\n",
    "    ax.set_title(date_str_title[i+30]+' '+regime[reg], fontsize=10, color=colors[idx_date1+i+30])\n",
    "    p1 = ax.contourf(lon, lat, z_anom[i+30,:,:], levels2, transform=ccrs.PlateCarree(), cmap=cmap2, extend='both')\n",
    "    p2 = ax.contour(lon, lat, z_anom[i+30,:,:], levels2, colors='black', linewidths=0.2,\n",
    "                    transform=ccrs.PlateCarree())\n",
    "    axgr.cbar_axes[i].colorbar(p1)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "figname=dir_figs+varname+'_anom_'+domain_name+'_'+season_name+'_cluster_'+str(date1)+'-'+str(date2)+'_2'\n",
    "fig.savefig(figname+'.png', bbox_inches='tight')\n",
    "\n",
    "#\n",
    "axes_class = (GeoAxes, dict(map_projection=projection))\n",
    "fig = plt.figure(figsize=(17,10))\n",
    "fig.suptitle(plt_title2, fontsize=16)\n",
    "\n",
    "axgr = AxesGrid(fig, 111, axes_class=axes_class,\n",
    "       nrows_ncols=(5, 6),\n",
    "       axes_pad=0.6,\n",
    "       cbar_location='right',\n",
    "       cbar_mode='single', # None/single/each\n",
    "       cbar_pad=0.2,\n",
    "       cbar_size='3%',\n",
    "       label_mode='')  # note the empty label_mode\n",
    "\n",
    "for i, ax in enumerate(axgr):\n",
    "    reg=cluster[idx_date1+60+i] # régime\n",
    "    ax.coastlines()\n",
    "    ax.set_extent([lonW, lonE, latS, latN], crs=ccrs.PlateCarree())\n",
    "    boundary_path = make_boundary_path(lon, lat)\n",
    "    ax.set_boundary(boundary_path, transform=ccrs.PlateCarree())\n",
    "    ax.gridlines(crs=ccrs.PlateCarree(), linewidth=0.5, color='gray', alpha=0.5, linestyle='-')\n",
    "    ax.set_title(date_str_title[i+60]+' '+regime[reg], fontsize=10, color=colors[idx_date1+i+60])\n",
    "    p1 = ax.contourf(lon, lat, z_anom[i+60,:,:], levels2, transform=ccrs.PlateCarree(), cmap=cmap2, extend='both')\n",
    "    p2 = ax.contour(lon, lat, z_anom[i+60,:,:], levels2, colors='black', linewidths=0.2,\n",
    "                    transform=ccrs.PlateCarree())\n",
    "    axgr.cbar_axes[i].colorbar(p1)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "figname=dir_figs+varname+'_anom_'+domain_name+'_'+season_name+'_cluster_'+str(date1)+'-'+str(date2)+'_3'\n",
    "fig.savefig(figname+'.png', bbox_inches='tight')\n",
    "\n",
    "#\n",
    "axes_class = (GeoAxes, dict(map_projection=projection))\n",
    "fig = plt.figure(figsize=(17,10))\n",
    "fig.suptitle(plt_title2, fontsize=16)\n",
    "\n",
    "axgr = AxesGrid(fig, 111, axes_class=axes_class,\n",
    "       nrows_ncols=(5, 6),\n",
    "       axes_pad=0.6,\n",
    "       cbar_location='right',\n",
    "       cbar_mode='single', # None/single/each\n",
    "       cbar_pad=0.2,\n",
    "       cbar_size='3%',\n",
    "       label_mode='')  # note the empty label_mode\n",
    "\n",
    "for i, ax in enumerate(axgr):\n",
    "    reg=cluster[idx_date1+90+i] # régime\n",
    "    ax.coastlines()\n",
    "    ax.set_extent([lonW, lonE, latS, latN], crs=ccrs.PlateCarree())\n",
    "    boundary_path = make_boundary_path(lon, lat)\n",
    "    ax.set_boundary(boundary_path, transform=ccrs.PlateCarree())\n",
    "    ax.gridlines(crs=ccrs.PlateCarree(), linewidth=0.5, color='gray', alpha=0.5, linestyle='-')\n",
    "    ax.set_title(date_str_title[i+90]+' '+regime[reg], fontsize=10, color=colors[idx_date1+i+90])\n",
    "    p1 = ax.contourf(lon, lat, z_anom[i+90,:,:], levels2, transform=ccrs.PlateCarree(), cmap=cmap2, extend='both')\n",
    "    p2 = ax.contour(lon, lat, z_anom[i+90,:,:], levels2, colors='black', linewidths=0.2,\n",
    "                    transform=ccrs.PlateCarree())\n",
    "    axgr.cbar_axes[i].colorbar(p1)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "figname=dir_figs+varname+'_anom_'+domain_name+'_'+season_name+'_cluster_'+str(date1)+'-'+str(date2)+'_4'\n",
    "fig.savefig(figname+'.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Nombre de jours par régime sur la saison choisie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nc1s=list(cluster[idx_date1:idx_date2]).count(0)\n",
    "nc2s=list(cluster[idx_date1:idx_date2]).count(1)\n",
    "nc3s=list(cluster[idx_date1:idx_date2]).count(2)\n",
    "nc4s=list(cluster[idx_date1:idx_date2]).count(3)\n",
    "\n",
    "f1s=int(nc1s/cluster[idx_date1:idx_date2].shape[0]*100)\n",
    "f2s=int(nc2s/cluster[idx_date1:idx_date2].shape[0]*100)\n",
    "f3s=int(nc3s/cluster[idx_date1:idx_date2].shape[0]*100)\n",
    "f4s=int(nc4s/cluster[idx_date1:idx_date2].shape[0]*100)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Fonction pour la légende."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_regimes_leg(ax):\n",
    "    patch1 = mpatches.Patch(color=couleur[0], label=regime[0]+' : '+str(nc1s)+' ('+str(f1s)+'%)')\n",
    "    patch2 = mpatches.Patch(color=couleur[1], label=regime[1]+' : '+str(nc2s)+' ('+str(f2s)+'%)')\n",
    "    patch3 = mpatches.Patch(color=couleur[2], label=regime[2]+' : '+str(nc3s)+' ('+str(f3s)+'%)')\n",
    "    patch4 = mpatches.Patch(color=couleur[3], label=regime[3]+' : '+str(nc4s)+' ('+str(f4s)+'%)')\n",
    "    all_handles = (patch1, patch2, patch3, patch4)\n",
    "    leg = ax.legend(handles=all_handles, loc='lower right')\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Bilan des régimes de temps de la saison sous forme de frise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 2))\n",
    "fig.suptitle('Weather regimes : '+date_str_title[0]+' to '+date_str_title[-1], fontsize=14)\n",
    "\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "# create a collection with a rectangle for each day\n",
    "col = PatchCollection([Rectangle((y, 0), 1, 1) for y in range(len(time))])\n",
    "\n",
    "#data = cluster[idx_date1:idx_date2]\n",
    "#col.set_array(data)\n",
    "col.set_color(colors[idx_date1:idx_date2])\n",
    "ax.add_collection(col)\n",
    "\n",
    "if season_name == 'winter':\n",
    "    labels = (\"Dec\", \"Jan\", \"Feb\", \"Mar\", \"Avr\")\n",
    "    positions = (0, 31, 31+31, 31+31+28, 31+31+28+31)\n",
    "    if leap_year:\n",
    "        positions = (0, 31, 31+31, 31+31+29, 31+31+29+31)\n",
    "\n",
    "if season_name == 'summer':\n",
    "    positions = (0, 30, 30+31, 30+31+31, 30+31+31+30)\n",
    "    labels = (\"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\")\n",
    "\n",
    "plt.xticks(positions, labels)\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_xlim(0, len(time))\n",
    "ax.yaxis.set_major_formatter(plt.NullFormatter())\n",
    "plt.axvline(x=positions[0], c='black')\n",
    "plt.axvline(x=positions[1], c='black')\n",
    "plt.axvline(x=positions[2], c='black')\n",
    "plt.axvline(x=positions[3], c='black')\n",
    "\n",
    "plot_regimes_leg(ax)\n",
    "\n",
    "fig.savefig(dir_figs+varname+'_'+domain_name+'_'+season_name+\n",
    "            '_regimes-stripes_'+date_str_title[0]+'-'+date_str_title[-1]+'.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>Questions : </b>\n",
    "<p><b>1) </b>Quels sont les régimes de temps dominant du mois de décembre 2011 ?</p>\n",
    "<p><b>2) </b>Quel régime de temps a été absent au cours de l'hiver 2011-2012 ?</p>\n",
    "<p><b>3) </b>Quel régime de temps a dominé en début de mois de février 2012 ? Quelle en a été la conséquence sur le temps sensible en France ?</p>\n",
    "<p><b>4) </b>Quel a été le régime de temps dominant au cours de l'hiver 2009-2010 ?  Au cours de quel mois les occurrences de ce régime ont-elles été les plus nombreuses ?</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Réponses : </b>\n",
    "<p>\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Visualisation de la saison considérée dans l'espace des phases défini par PC1 et PC2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 10))\n",
    "fig.suptitle('PC1 and PC2 phase space : '+date_str_title[0]+' to '+date_str_title[-1], fontsize=14)\n",
    "\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "plot_phase_space2d(ax)\n",
    "ax.scatter(pcs[idx_date1:idx_date2,0], pcs[idx_date1:idx_date2,1], c=colors[idx_date1:idx_date2], s=10)\n",
    "ax.scatter(centroids[:, 0], centroids[:, 1], c=couleur, s=2000, alpha=1, marker='+')\n",
    "\n",
    "for i,type in enumerate(date_str):\n",
    "    x = pc1[idx_date1+i]\n",
    "    y = pc2[idx_date1+i]\n",
    "    plt.text(x, y, type, fontsize=6)\n",
    "\n",
    "plot_regimes_leg(ax)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "figname=dir_figs+varname+'_'+domain_name+'_'+season_name+'_pc12_'+date_str_title[0]+'-'+date_str_title[-1]\n",
    "fig.savefig(figname+'.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Visualisation de la saison considérée dans l'espace des phases défini par PC1 PC2 et PC3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 10))\n",
    "fig.suptitle('PC phase space : '+date_str_title[0]+' to '+date_str_title[-1], fontsize=14)\n",
    "\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "plot_phase_space3d(ax)\n",
    "ax.scatter(pcs[idx_date1:idx_date2,0], pcs[idx_date1:idx_date2,1], pcs[idx_date1:idx_date2,2],\n",
    "           c=colors[idx_date1:idx_date2], s=10)\n",
    "ax.scatter(centroids[:, 0], centroids[:, 1], centroids[:, 2], c=couleur, s=200, alpha=1, marker='+')\n",
    "\n",
    "plot_regimes_leg(ax)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "figname=dir_figs+varname+'_'+domain_name+'_'+season_name+'_pc123_'+date_str_title[0]+'-'+date_str_title[-1]\n",
    "fig.savefig(figname+'.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Création des vignettes de la saison considérée dans l'espace des phases défini par PC1 et PC2 (fichiers png)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# loop for each day\t\n",
    "for i in range(len(time)):\n",
    "    #print(date_str[i])\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    fig.suptitle('PC1 and PC2 phase space : '+date_str_title[0]+' to '+date_str_title[-1], fontsize=14)\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    plot_phase_space2d(ax)\n",
    "    ax.scatter(pcs[idx_date1:idx_date1+i+1,0], pcs[idx_date1:idx_date1+i+1,1], \n",
    "               c=colors[idx_date1:idx_date1+i+1], s=10)\n",
    "\n",
    "    ax.scatter(centroids[:, 0], centroids[:, 1], c=couleur, s=2000, alpha=1, marker='+')\n",
    "    x = pc1[idx_date1+i]\n",
    "    y = pc2[idx_date1+i]\n",
    "    plt.text(x, y, date_str[i], fontsize=10)\n",
    "    plot_regimes_leg(ax)\n",
    "    figname=dir_anim+varname+'_'+domain_name+'_'+season_name+'_PC_2d_phase_space_4clusters_'+date_str_title[i]\n",
    "    fig.savefig(figname+'.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Animation de la saison considérée dans l'espace des phases défini par PC1 et PC2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gif_filepath = dir_anim+varname+'_'+domain_name+'_'+season_name+'_PC_2d_phase_space_4clusters_'+date_str_title[0]+'-'+date_str_title[-1]+'.gif'\n",
    "make_animation()\n",
    "IPdisplay.Image(url=gif_filepath)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Distances aux centroides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import scipy.spatial.distance as sdist\n",
    "dist=sdist.cdist(pcs, centroids)\n",
    "dist_c1=dist[:,0]\n",
    "dist_c2=dist[:,1]\n",
    "dist_c3=dist[:,2]\n",
    "dist_c4=dist[:,3]\n",
    "\n",
    "def plot_dist(ax):\n",
    "    #plt.ylim(0, 5)\n",
    "    plt.axhline(0, color='k')\n",
    "    plt.xlim(xmin=datetime.datetime(int(str(time[0])[0:4]), int(str(time[0])[5:7]),\n",
    "                                    int(str(time[0])[8:10])),\n",
    "             xmax=datetime.datetime(int(str(time[-1])[0:4]), int(str(time[-1])[5:7]),\n",
    "                                    int(str(time[-1])[8:10])))\n",
    "    #ax.spines['right'].set_visible(False)\n",
    "    #ax.spines['top'].set_visible(False)\n",
    "    #ax.spines['bottom'].set_visible(False)\n",
    "    #ax.spines['left'].set_visible(False)\n",
    "    #ax.axes.get_yaxis().set_visible(False)\n",
    "    return ax\n",
    "\n",
    "d1=dist_c1[idx_date1:idx_date2] # distance au régime 1\n",
    "d2=dist_c2[idx_date1:idx_date2] # distance au régime 2\n",
    "d3=dist_c3[idx_date1:idx_date2] # distance au régime 3\n",
    "d4=dist_c4[idx_date1:idx_date2] # distance au régime 4\n",
    "\n",
    "fig=plt.figure(figsize=(20, 7))\n",
    "fig.suptitle('Regime distance from centroid', fontsize=16)\n",
    "\n",
    "ax = fig.add_subplot(4, 1, 1)\n",
    "plot_dist(ax)\n",
    "plt.scatter(time, d1, color='blue', s=200000/d1, label='Distance '+regime[0])\n",
    "plt.legend()\n",
    "\n",
    "ax = fig.add_subplot(4, 1, 2)\n",
    "plot_dist(ax)\n",
    "plt.scatter(time, d2, color='red', s=200000/d2, label='Distance '+regime[1])\n",
    "plt.legend()\n",
    "\n",
    "ax = fig.add_subplot(4, 1, 3)\n",
    "plot_dist(ax)\n",
    "plt.scatter(time, d3, color='green', s=200000/d3, label='Distance '+regime[2])\n",
    "plt.legend()\n",
    "\n",
    "ax = fig.add_subplot(4, 1, 4)\n",
    "plot_dist(ax)\n",
    "plt.scatter(time, d4, color='orange', s=200000/d4, label='Distance '+regime[3])\n",
    "plt.axhline(0, color='k')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "fig.savefig(dir_figs+varname+'_'+domain_name+'_'+season_name+\n",
    "            '_regimes-distances_'+date_str_title[0]+'-'+date_str_title[-1]+'.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>Tâches supplémentaires : </b>\n",
    "<p><b>1) </b>Consulter le suivi quotidien des régimes de temps de la DCSC (Météo-France) : http://seasonal.meteo.fr/content/suivi-clim-regimes-quot\n",
    "</p>\n",
    "<p><b>2) </b>Consulter les prévisions de régimes de temps ECMWF : https://www.ecmwf.int/en/forecasts/charts/catalogue/extended-regime-probabilities?facets=undefined&time=2021110400&forecast_from=latest\n",
    "</p>\n",
    "<p><b>3) </b>Refaire le calepin afin d’extraire les régimes de Z500 sur le Pacifique Nord pour les mois d’hiver. Retrouver les régimes Arctic High, Arctic Low, Pacific Trough et Alaskan Ridge.</p>\n",
    "<p><b>4) </b>- Refaire le calepin afin d’extraire les régimes de Pmer sur l’Atlantique Nord pour les mois d’été (juin-juillet-août-septembre) (fichier slp_1d_19480101_20191231_NCEP).</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "<b>Défi codage n°1 (*) : séquences record de régimes </b>\n",
    "<p>\n",
    "Le tableau cluster contient les numéros de régime pour chaque jour de l'étude (0 = régime 1, 1 = régime 2, 2 = régime 3, 3 = régime 4). Le tableau regime fait la correspondance entre le numéro de régime et le nom du régime. L'index de date dates2 contient les dates de l'étude.\n",
    "\n",
    "- Exploiter ces 3 tableaux pour établir le top 20 des séquences les plus longues d'un même régime en précisant pour chaque séquence le régime considéré ainsi que la date de de début et de fin de la séquence.\n",
    "\n",
    "Indication : les fonctions suivantes pourront s'avérer utiles :\n",
    "- https://docs.python.org/3/library/itertools.html#itertools.groupby\n",
    "- https://numpy.org/doc/stable/reference/generated/numpy.sort.html\n",
    "- https://numpy.org/doc/stable/reference/generated/numpy.argsort.html\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "<b>Défi codage N°2 (**) : non prise en compte des régimes non persistants : </b>\n",
    "<p>\n",
    "Le tableau cluster contient les numéros de régime pour chaque jour de l'étude (0 = régime 1, 1 = régime 2, 2 = régime 3, 3 = régime 4).\n",
    "\n",
    "- Exploiter ce tableau pour déclassifier les séquences de moins de 3 jours consécutifs d'un même régime en les attribuant à un nouveau numéro de régime (4 = classe régime \"poubelle\"). Ces séqeunces correspondent en effet à des phases de transitions entre 2 régimes.\n",
    "\n",
    "Indication : la fonction suivante pourra s'avérer utile :\n",
    "- https://docs.python.org/3/library/itertools.html#itertools.groupby\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "<b>Défi codage N°3 (**) : non prise en compte des régimes non robustes : </b>\n",
    "<p>\n",
    "Le tableau cluster contient les numéros de régime pour chaque jour de l'étude (0 = régime 1, 1 = régime 2, 2 = régime 3, 3 = régime 4). Les dataArray mean_c1_anom, mean_c2_anom, mean_c3_anom, mean_c3_anom correspondent aux composites des régimes 1 à 4. Le dataArray data_anom[varname][:,:,:]/var_div contient les champs d'anomalies sur toute la période d'étude.\n",
    "\n",
    "- Exploiter ces données pour déclassifier les régimes dont la corrélation spatiale avec le composite est inférieure à 0.25 en les attribuant à un régime 4 (classe régime \"poubelle\"). Ces séquences correspondent en effet à des régimes non robustes.\n",
    "\n",
    "Indication : les fonctions suivantes pourront s'avérer utiles :\n",
    "- https://numpy.org/doc/stable/reference/generated/numpy.corrcoef.html\n",
    "- https://numpy.org/doc/stable/reference/generated/numpy.ndarray.flatten.html (pour aplatir les tableaux 2D)\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
